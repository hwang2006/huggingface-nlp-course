{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca4a0bb-fe31-4fe1-9f2e-45ecb71bb13e",
   "metadata": {},
   "source": [
    "### 1. ê¸°ì¡´ í† í¬ë‚˜ì´ì €ì—ì„œ ìƒˆë¡œìš´ í† í¬ë‚˜ì´ì € í•™ìŠµ\n",
    "\n",
    "#### ë§ë­‰ì¹˜ ëª¨ìœ¼ê¸°\n",
    "ğŸ¤—Transformersì—ëŠ” ê¸°ì¡´ì— ì¡´ì¬í•˜ëŠ” ê²ƒë“¤ê³¼ ë™ì¼í•œ íŠ¹ì„±ì„ ê°€ì§„ ìƒˆë¡œìš´ í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•˜ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë§¤ìš° ê°„ë‹¨í•œ APIê°€ ìˆìŠµë‹ˆë‹¤. ë°”ë¡œ AutoTokenizer.train_new_from_iterator()ê°€ ê·¸ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ì‹¤ì œë¡œ ì‹¤í–‰í•´ ë³´ê¸° ìœ„í•´ GPT-2ë¥¼ ì²˜ìŒë¶€í„° ì˜ì–´ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì–¸ì–´ë¡œ í•™ìŠµí•˜ê³  ì‹¶ë‹¤ê³  ê°€ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ì‘ì—…ì€ í•´ë‹¹ ì–¸ì–´ë¡œ í‘œí˜„ëœ ëŒ€ê·œëª¨ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í•™ìŠµ ë§ë­‰ì¹˜ë¡œ êµ¬ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ëª¨ë“  ì‚¬ëŒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì˜ˆì‹œë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì—¬ê¸°ì„œëŠ” ëŸ¬ì‹œì•„ì–´ë‚˜ ì¤‘êµ­ì–´ì™€ ê°™ì€ ì–¸ì–´ê°€ ì•„ë‹ˆë¼ íŠ¹ìˆ˜í•œ ì˜ì–´ í…ìŠ¤íŠ¸ë¡œ ë³¼ ìˆ˜ ìˆëŠ” Python ì†ŒìŠ¤ì½”ë“œ ì§‘í•©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ¤—Datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” Python ì†ŒìŠ¤ì½”ë“œë¥¼ ëª¨ìœ¼ëŠ”ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°„ë‹¨í•˜ê²Œ load_dataset() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ CodeSearchNet ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ìºì‹œí•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ CodeSearchNet ì±Œë¦°ì§€ë¥¼ ìœ„í•´ ìƒì„±ë˜ì—ˆìœ¼ë©° ì—¬ëŸ¬ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ëœ GitHubì˜ ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ìˆ˜ë°±ë§Œ ê°œì˜ í•¨ìˆ˜ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ì˜ˆì‹œì—ì„œëŠ” ì´ ë°ì´í„°ì…‹ì˜ Python ë¶€ë¶„ì„ ë¡œë“œí•©ë‹ˆë‹¤:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67eecb8-7289-4abe-927f-bbde127bfc17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for code_search_net contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/code_search_net\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "# ë¡œë“œí•˜ëŠ”ë° ëª‡ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì»¤í”¼ë‚˜ ì°¨ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”.\n",
    "raw_datasets = load_dataset(\"code_search_net\", \"python\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59e123c-7624-4745-a7b5-218a1a901052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 412178\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 22176\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "        num_rows: 23107\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afcfb753-841a-476b-a3ad-2a8ee6dff7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'],\n",
       "    num_rows: 412178\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19da7073-0e2b-43cc-9521-e09693dcfd98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'func_code_string': 'def findArgs(args, prefixes):\\n'\n",
      "                     '\\t\\t\"\"\"\\n'\n",
      "                     '\\t\\tExtracts the list of arguments that start with any '\n",
      "                     'of the specified prefix values\\n'\n",
      "                     '\\t\\t\"\"\"\\n'\n",
      "                     '\\t\\treturn list([\\n'\n",
      "                     '\\t\\t\\targ for arg in args\\n'\n",
      "                     '\\t\\t\\tif len([p for p in prefixes if '\n",
      "                     'arg.lower().startswith(p.lower())]) > 0\\n'\n",
      "                     '\\t\\t])',\n",
      " 'func_code_tokens': ['def',\n",
      "                      'findArgs',\n",
      "                      '(',\n",
      "                      'args',\n",
      "                      ',',\n",
      "                      'prefixes',\n",
      "                      ')',\n",
      "                      ':',\n",
      "                      'return',\n",
      "                      'list',\n",
      "                      '(',\n",
      "                      '[',\n",
      "                      'arg',\n",
      "                      'for',\n",
      "                      'arg',\n",
      "                      'in',\n",
      "                      'args',\n",
      "                      'if',\n",
      "                      'len',\n",
      "                      '(',\n",
      "                      '[',\n",
      "                      'p',\n",
      "                      'for',\n",
      "                      'p',\n",
      "                      'in',\n",
      "                      'prefixes',\n",
      "                      'if',\n",
      "                      'arg',\n",
      "                      '.',\n",
      "                      'lower',\n",
      "                      '(',\n",
      "                      ')',\n",
      "                      '.',\n",
      "                      'startswith',\n",
      "                      '(',\n",
      "                      'p',\n",
      "                      '.',\n",
      "                      'lower',\n",
      "                      '(',\n",
      "                      ')',\n",
      "                      ')',\n",
      "                      ']',\n",
      "                      ')',\n",
      "                      '>',\n",
      "                      '0',\n",
      "                      ']',\n",
      "                      ')'],\n",
      " 'func_code_url': 'https://github.com/adamrehn/ue4cli/blob/f1c34502c96059e36757b7433da7e98760a75a6f/ue4cli/Utility.py#L86-L93',\n",
      " 'func_documentation_string': 'Extracts the list of arguments that start with '\n",
      "                              'any of the specified prefix values',\n",
      " 'func_documentation_tokens': ['Extracts',\n",
      "                               'the',\n",
      "                               'list',\n",
      "                               'of',\n",
      "                               'arguments',\n",
      "                               'that',\n",
      "                               'start',\n",
      "                               'with',\n",
      "                               'any',\n",
      "                               'of',\n",
      "                               'the',\n",
      "                               'specified',\n",
      "                               'prefix',\n",
      "                               'values'],\n",
      " 'func_name': 'Utility.findArgs',\n",
      " 'func_path_in_repository': 'ue4cli/Utility.py',\n",
      " 'language': 'python',\n",
      " 'repository_name': 'adamrehn/ue4cli',\n",
      " 'split_name': 'train',\n",
      " 'whole_func_string': 'def findArgs(args, prefixes):\\n'\n",
      "                      '\\t\\t\"\"\"\\n'\n",
      "                      '\\t\\tExtracts the list of arguments that start with any '\n",
      "                      'of the specified prefix values\\n'\n",
      "                      '\\t\\t\"\"\"\\n'\n",
      "                      '\\t\\treturn list([\\n'\n",
      "                      '\\t\\t\\targ for arg in args\\n'\n",
      "                      '\\t\\t\\tif len([p for p in prefixes if '\n",
      "                      'arg.lower().startswith(p.lower())]) > 0\\n'\n",
      "                      '\\t\\t])'}\n"
     ]
    }
   ],
   "source": [
    "pprint(raw_datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a57525-c1e4-49f4-9aec-a903dafe73e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def check_result(running, recurse=False, highstate=None):\n",
      "    '''\n",
      "    Check the total return value of the run and determine if the running\n",
      "    dict has any issues\n",
      "    '''\n",
      "    if not isinstance(running, dict):\n",
      "        return False\n",
      "\n",
      "    if not running:\n",
      "        return False\n",
      "\n",
      "    ret = True\n",
      "    for state_id, state_result in six.iteritems(running):\n",
      "        expected_type = dict\n",
      "        # The __extend__ state is a list\n",
      "        if \"__extend__\" == state_id:\n",
      "            expected_type = list\n",
      "        if not recurse and not isinstance(state_result, expected_type):\n",
      "            ret = False\n",
      "        if ret and isinstance(state_result, dict):\n",
      "            result = state_result.get('result', _empty)\n",
      "            if result is False:\n",
      "                ret = False\n",
      "            # only override return value if we are not already failed\n",
      "            elif result is _empty and isinstance(state_result, dict) and ret:\n",
      "                ret = check_result(\n",
      "                    state_result, recurse=True, highstate=highstate)\n",
      "        # if we detect a fail, check for onfail requisites\n",
      "        if not ret:\n",
      "            # ret can be None in case of no onfail reqs, recast it to bool\n",
      "            ret = bool(check_onfail_requisites(state_id, state_result,\n",
      "                                               running, highstate))\n",
      "        # return as soon as we got a failure\n",
      "        if not ret:\n",
      "            break\n",
      "    return ret\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][123456][\"whole_func_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb1121b-581f-4e98-a881-8d27a53df646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 182.55 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Process.memory_infoëŠ” ë°”ì´íŠ¸ ë‹¨ìœ„ë¡œ í‘œì‹œë˜ë¯€ë¡œ ì´ë¥¼ ë©”ê°€ë°”ì´íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "# ì—¬ê¸°ì—ì„œ rss ì†ì„±ì€ í”„ë¡œì„¸ìŠ¤ê°€ RAMì—ì„œ ì°¨ì§€í•˜ëŠ” ë©”ëª¨ë¦¬ ë¹„ìœ¨ì¸ resident set size(ìƒì£¼ ì„¸íŠ¸ í¬ê¸°)ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723e74a-eec2-4708-af15-53930c95752a",
   "metadata": {},
   "source": [
    "\n",
    "ê°€ì¥ ë¨¼ì € í•´ì•¼ í•  ì¼ì€ ë°ì´í„°ì…‹ì„ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ì˜ ì´í„°ë ˆì´í„°(iterator)ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í…ìŠ¤íŠ¸ **ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸**ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ ê°œë³„ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì”© ì²˜ë¦¬í•˜ëŠ” ëŒ€ì‹  í…ìŠ¤íŠ¸ ë°°ì¹˜(batches)ì— ëŒ€í•œ í•™ìŠµì„ í†µí•´ì„œ í† í¬ë‚˜ì´ì €ê°€ ë” ë¹¨ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë©°, ëª¨ë“  ê²ƒì„ í•œ ë²ˆì— ë©”ëª¨ë¦¬ì— ë¡œë”©í•˜ì§€ ì•Šìœ¼ë ¤ë©´ ì´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì´í„°ë ˆì´í„°(iterator)ë¡œ ë³€í™˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ë§ë­‰ì¹˜ì˜ ê·œëª¨ê°€ í¬ë‹¤ë©´ ğŸ¤—DatasetsëŠ” RAMì— ëª¨ë“  ê²ƒì„ ë¡œë“œí•˜ì§€ ì•Šê³  ë°ì´í„°ì…‹ì˜ ìš”ì†Œë¥¼ ë””ìŠ¤í¬ì— ì €ì¥í•œë‹¤ëŠ” ì‚¬ì‹¤ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒì„ ìˆ˜í–‰í•˜ë©´ ê°ê° 1,000ê°œì˜ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ê°€ ìƒì„±ë˜ì§€ë§Œ ëª¨ë“  ê²ƒì´ ë©”ëª¨ë¦¬ì— ë¡œë“œë©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1046e8f-477e-4fb2-af78-60e42aab9840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ì˜ ê·œëª¨ê°€ ì‘ì§€ ì•Šë‹¤ë©´, ë‹¤ìŒ ë¼ì¸ì˜ ì£¼ì„ì„ ì œê±°í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "#training_corpus = [raw_datasets[\"train\"][i: i + 1000][\"whole_func_string\"] for i in range(0, len(raw_datasets[\"train\"]), 1000)]\n",
    "#print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "# RAM used: 2142.84 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63ce18cf-0372-4d19-b234-3b451733428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(training_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c77028-a973-4f82-b746-e470f17a2849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_corpus[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2879e1f-f832-45bd-9482-1efaf404e3c2",
   "metadata": {},
   "source": [
    "Python ì œë„ˆë ˆì´í„°(generator)ë¥¼ ì‚¬ìš©í•˜ë©´ ì‹¤ì œë¡œ í•„ìš”í•  ë•Œê¹Œì§€ Pythonì´ ë©”ëª¨ë¦¬ì— ì•„ë¬´ ê²ƒë„ ë¡œë“œí•˜ì§€ ì•Šë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ìƒì„±ê¸°ë¥¼ ë§Œë“¤ë ¤ë©´ êº½ì‡ ê´„í˜¸(brackets)ë¥¼ ì†Œê´„í˜¸(parentheses)ë¡œ ë°”ê¾¸ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "187d54b5-7511-46ce-a745-47b75939fd64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 182.80 MB\n"
     ]
    }
   ],
   "source": [
    "training_corpus = (\n",
    "    raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "    for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    ")\n",
    "\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "# RAM used: 167.87 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5564ed8-e678-4ad3-9706-4c354ee34234",
   "metadata": {},
   "source": [
    "ìœ„ ì½”ë“œëŠ” ë°ì´í„°ì…‹ì˜ ìš”ì†Œë¥¼ ê°€ì ¸ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤. Pythonì˜ for ë£¨í”„ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê°ì²´ë¥¼ ìƒì„±í•  ë¿ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ëŠ” í•„ìš”í•  ë•Œë§Œ ë©”ëª¨ë¦¬ë¡œ ë¡œë“œë˜ë©°(ì¦‰, í•´ë‹¹ í…ìŠ¤íŠ¸ ì§‘í•©ì´ í•„ìš”í•œ for-loop ë‹¨ê³„ì— ìˆì„ ë•Œë§Œ) í•œ ë²ˆì— 1,000ê°œì˜ í…ìŠ¤íŠ¸ë§Œ ë¡œë“œë©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ê±°ëŒ€í•œ ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ë”ë¼ë„ ë©”ëª¨ë¦¬ë¥¼ ì™„ì „íˆ ì†Œì§„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "íŒŒì´ì¬ ì œë„ˆë ˆì´í„°(generator) ê°ì²´ì˜ ë¬¸ì œì ì€ ë‹¨ í•œë²ˆë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ, ì•„ë˜ ì½”ë“œì˜ ê²°ê³¼ëŠ” ìš°ë¦¬ê°€ ì˜ˆìƒí•œ ê²ƒì²˜ëŸ¼ 10ê°œì˜ ìˆ«ì ë¦¬ìŠ¤íŠ¸ë¥¼ ë‘ë²ˆ ì¶œë ¥í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "268a6cef-4461-4e6a-8417-b0a0f5d083ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "gen = (i for i in range(10))\n",
    "print(list(gen))\n",
    "print(list(gen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621607e4-e274-4dcf-ae86-7eb3e612010b",
   "metadata": {},
   "source": [
    "ì²«ë²ˆì§¸ printë¬¸ì€ 10ê°œì˜ ìˆ«ìë¥¼ ì¶œë ¥í•˜ì§€ë§Œ, ê·¸ ë‹¤ìŒì€ ë¹„ì–´ìˆëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ ì œë„ˆë ˆì´í„°(generator)ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ëŠ” ì´ìœ ì…ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcba76ee-317e-4df7-8230-96d6ba94d4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    return (\n",
    "        raw_datasets[\"train\"][i : i + 1000][\"whole_func_string\"]\n",
    "        for i in range(0, len(raw_datasets[\"train\"]), 1000)\n",
    "    )\n",
    "\n",
    "training_corpus = get_training_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020b0585-3ad0-451e-b3c5-682e8bc078ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = next(training_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6132ce82-5ca0-4e0a-8ca5-8fc6a5b6e13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb202b0-b271-48e0-b4fa-e4e42532977c",
   "metadata": {},
   "source": [
    "yield ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ for ë£¨í”„ ë‚´ì—ì„œ ì œë„ˆë ˆì´í„°(generator)ë¥¼ ì •ì˜í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ae97e6a-d4bb-47c5-8e8e-ebfcb5287aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    dataset = raw_datasets[\"train\"]\n",
    "    for start_idx in range(0, len(dataset), 1000):\n",
    "        samples = dataset[start_idx : start_idx + 1000]\n",
    "        yield samples[\"whole_func_string\"]\n",
    "        \n",
    "        \n",
    "training_corpus = get_training_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60299c9c-45be-4144-88a0-7aea786f877b",
   "metadata": {},
   "source": [
    "ì´ì „ê³¼ ë™ì¼í•œ ì œë„ˆë ˆì´í„°ë¥¼ ìƒì„±í•˜ì§€ë§Œ ë¦¬ìŠ¤íŠ¸ ë‚´í¬(list comprehension)ì—ì„œ í•  ìˆ˜ ìˆëŠ” ê²ƒë³´ë‹¤ ë” ë³µì¡í•œ ë¡œì§ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "#### ìƒˆë¡œìš´ í† í¬ë‚˜ì´ì € í•™ìŠµ\n",
    "ì´ì œ í…ìŠ¤íŠ¸ ë°°ì¹˜(batch)ì˜ ì´í„°ë ˆì´í„°(iterator) í˜•íƒœë¡œ ë§ë­‰ì¹˜ë¥¼ êµ¬ì„±í–ˆìœ¼ë¯€ë¡œ ìƒˆë¡œìš´ í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. í•™ìŠµì„ ìœ„í•´ì„œ ë¨¼ì € ëª¨ë¸ê³¼ ì¼ì¹˜ì‹œí‚¤ë ¤ëŠ” í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” GPT-2ë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5699fc15-72b6-4d62-8d9e-966e37345148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db6fd3a1-4d7e-44af-ad93-ab8ab29e2426",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b411e70-011e-4550-9cfa-b9464fdc3fb9",
   "metadata": {},
   "source": [
    "ìƒˆë¡œìš´ í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•˜ì§€ë§Œ, ì™„ì „íˆ ì²˜ìŒë¶€í„° ì‹œì‘í•˜ì§€ ì•Šë„ë¡ í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ í† í°í™” ì•Œê³ ë¦¬ì¦˜ì´ë‚˜ ì‚¬ìš©í•˜ë ¤ëŠ” íŠ¹ìˆ˜ í† í°(special tokens)ì— ëŒ€í•´ ì•„ë¬´ ê²ƒë„ ì‹ ê²½ì“°ê±°ë‚˜ ì§€ì •í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ìš°ë¦¬ì˜ ìƒˆë¡œìš´ í† í¬ë‚˜ì´ì €ëŠ” GPT-2ì™€ ì •í™•íˆ ë™ì¼í•  ê²ƒì´ë©°, ìš°ë¦¬ ë§ë­‰ì¹˜ë¥¼ ì´ìš©í•œ í•™ìŠµì„ í†µí•´ vocabularyë§Œ ë³€ê²½ë©ë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì € ì´ í† í¬ë‚˜ì´ì €ê°€ ì˜ˆì œ í•¨ìˆ˜(example function)ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8631069-fd46-4f24-915c-4e96569b9ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def',\n",
       " 'Ä add',\n",
       " '_',\n",
       " 'n',\n",
       " 'umbers',\n",
       " '(',\n",
       " 'a',\n",
       " ',',\n",
       " 'Ä b',\n",
       " '):',\n",
       " 'ÄŠ',\n",
       " 'Ä ',\n",
       " 'Ä ',\n",
       " 'Ä ',\n",
       " 'Ä \"\"\"',\n",
       " 'Add',\n",
       " 'Ä the',\n",
       " 'Ä two',\n",
       " 'Ä numbers',\n",
       " 'Ä `',\n",
       " 'a',\n",
       " '`',\n",
       " 'Ä and',\n",
       " 'Ä `',\n",
       " 'b',\n",
       " '`',\n",
       " '.\"',\n",
       " '\"\"',\n",
       " 'ÄŠ',\n",
       " 'Ä ',\n",
       " 'Ä ',\n",
       " 'Ä ',\n",
       " 'Ä return',\n",
       " 'Ä a',\n",
       " 'Ä +',\n",
       " 'Ä b']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = '''def add_numbers(a, b):\n",
    "    \"\"\"Add the two numbers `a` and `b`.\"\"\"\n",
    "    return a + b'''\n",
    "\n",
    "tokens = old_tokenizer.tokenize(example)\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5d2844e-6db8-4a24-a57e-24eb64c8bde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5d005-c438-4fd3-8f80-fb5deb02945e",
   "metadata": {},
   "source": [
    "ì´ í† í¬ë‚˜ì´ì €ëŠ” ê°ê° ê³µë°±ê³¼ ì¤„ë°”ê¿ˆì„ ë‚˜íƒ€ë‚´ëŠ” ÄŠ ë° Ä ì™€ ê°™ì€ ëª‡ê°€ì§€ íŠ¹ìˆ˜ ê¸°í˜¸ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê²°ê³¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, ì´ëŠ” íš¨ìœ¨ì ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ê°œì˜ ê³µë°±ì´ ë‚˜íƒ€ë‚  ë•Œ í† í¬ë‚˜ì´ì €ëŠ” ì´ë¥¼ ê·¸ë£¹í™”í•˜ì—¬ í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ë„ ìˆëŠ”ë°, ì—¬ê¸°ì„œëŠ” ê° ê³µë°±ì„ ê°œë³„ í† í°ìœ¼ë¡œ í‘œí˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì†ŒìŠ¤ì½”ë“œì—ì„œ 4ê°œ ë˜ëŠ” 8ê°œì˜ ê³µë°± ê·¸ë£¹ì´ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì€ ë§¤ìš° ì¼ë°˜ì ì…ë‹ˆë‹¤. ë˜í•œ _ ë¬¸ìê°€ ìˆëŠ” ë‹¨ì–´ê°€ ìµìˆ™í•˜ì§€ ì•Šì€ì§€, í•¨ìˆ˜ëª…ì„ ì•½ê°„ ì´ìƒí•˜ê²Œ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "\n",
    "ìƒˆë¡œìš´ í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•˜ê³  ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ”ì§€ ë´…ì‹œë‹¤. ì´ë¥¼ ìœ„í•´ ìš°ë¦¬ëŠ” train_new_from_iterator() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46412452-df55-477b-83fa-5bdd87bdda1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "CPU times: user 3min 17s, sys: 12 s, total: 3min 29s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37fc3c3-90e4-4143-8f0e-dd93781c2776",
   "metadata": {},
   "source": [
    "ì´ ëª…ë ¹ì€ ë§ë­‰ì¹˜ê°€ ë§¤ìš° í° ê²½ìš° ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆì§€ë§Œ 1.6GB í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ì˜ ê²½ìš°ì—ëŠ” ë§¤ìš° ë¹ ë¦…ë‹ˆë‹¤(12ì½”ì–´ê°€ ìˆëŠ” AMD Ryzen 9 3900X CPUì—ì„œ 1ë¶„ 16ì´ˆ).\n",
    "\n",
    "AutoTokenizer.train_new_from_iterator()ëŠ” ì‚¬ìš© ì¤‘ì¸ í† í¬ë‚˜ì´ì €ê°€ \"ë¹ ë¥¸(fast)\" í† í¬ë‚˜ì´ì €ì¸ ê²½ìš°ì—ë§Œ ì‘ë™í•©ë‹ˆë‹¤. ë‹¤ìŒ ì„¹ì…˜ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ğŸ¤—Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ëŠ” ë‘ ê°€ì§€ ìœ í˜•ì˜ í† í¬ë‚˜ì´ì €ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•œ ìœ í˜•ì€ ìˆœìˆ˜í•˜ê²Œ Pythonìœ¼ë¡œ ì‘ì„±ë˜ì–´ ìˆê³  ë‹¤ë¥¸ ìœ í˜•(ë¹ ë¥¸ í† í¬ë‚˜ì´ì €)ì€ ğŸ¤—Tokenizers ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë„ì›€ì„ ë°›ì•„ì„œ Rust í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ì‘ì„±ëœ í† í¬ë‚˜ì´ì €ì…ë‹ˆë‹¤. Pythonì€ ë°ì´í„° ê³¼í•™ ë° ë”¥ëŸ¬ë‹ ì‘ìš© í”„ë¡œê·¸ë¨ì— ê°€ì¥ ìì£¼ ì‚¬ìš©ë˜ëŠ” ì–¸ì–´ì´ì§€ë§Œ ë¹ ë¥¸ ë³‘ë ¬ ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš° ë‹¤ë¥¸ ì–¸ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ëª¨ë¸ ê³„ì‚°(model computation)ì˜ í•µì‹¬ì¸ í–‰ë ¬ ê³±ì…ˆ(matrix multiplication)ì€ GPUì— ìµœì í™”ëœ C ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ CUDAë¡œ ì‘ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìˆœìˆ˜í•œ Pythonìœ¼ë¡œ ìƒˆë¡œìš´ í† í¬ë‚˜ì´ì €ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì€ ì—„ì²­ë‚˜ê²Œ ëŠë¦´ ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ìš°ë¦¬ê°€ ğŸ¤—Tokenizers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°œë°œí•œ ì´ìœ ì…ë‹ˆë‹¤. GPUì— ë¡œë“œëœ ì…ë ¥ ë°°ì¹˜(input batch)ì—ì„œ ëª¨ë¸ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•´ CUDA ì–¸ì–´ë¥¼ ë°°ìš¸ í•„ìš”ê°€ ì—†ì—ˆë˜ ê²ƒì²˜ëŸ¼ ë¹ ë¥¸ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ Rustë¥¼ ë°°ìš¸ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ğŸ¤—Tokenizers ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ Rustì˜ ì¼ë¶€ ì½”ë“œë¥¼ í˜¸ì¶œí•˜ëŠ” ë§ì€ ë©”ì„œë“œì— ëŒ€í•œ Python ë°”ì¸ë”©ì„ ì œê³µí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìƒˆ í† í¬ë‚˜ì´ì €ì˜ í•™ìŠµì„ ë³‘ë ¬í™”í•˜ê±°ë‚˜ 3ì¥ì—ì„œ ë³´ì•˜ë“¯ì´ ì…ë ¥ ë°°ì¹˜(batch)ì˜ í† í°í™”ë¥¼ ë³‘ë ¬í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "ëŒ€ë¶€ë¶„ì˜ íŠ¸ëœìŠ¤í¬ë¨¸(Transformer) ëª¨ë¸ì—ëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ \"ë¹ ë¥¸(fast)\" í† í¬ë‚˜ì´ì €ê°€ ìˆìœ¼ë©°(ì—¬ê¸°ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ëª‡ ê°€ì§€ ì˜ˆì™¸ê°€ ìˆìŒ) AutoTokenizer APIëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° í•­ìƒ ë¹ ë¥¸ í† í¬ë‚˜ì´ì €ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ë‹¤ìŒ ì„¹ì…˜ì—ì„œëŠ” í† í° ë¶„ë¥˜(token classification) ë° ì§ˆì˜ ì‘ë‹µ(question answering)ê³¼ ê°™ì€ ì‘ì—…ì— ì •ë§ ìœ ìš©í•œ ë¹ ë¥¸ í† í¬ë‚˜ì´ì €ì˜ ë‹¤ë¥¸ ëª‡ ê°€ì§€ íŠ¹ìˆ˜ ê¸°ëŠ¥ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ì— ëŒ€í•´ ì•Œì•„ë³´ê¸° ì „ì— ìœ„ ì˜ˆì œì—ì„œ ìƒˆë¡œìš´ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "171c157c-4e3b-4812-86fb-c0ffce177d36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def',\n",
       " 'Ä add',\n",
       " '_',\n",
       " 'numbers',\n",
       " '(',\n",
       " 'a',\n",
       " ',',\n",
       " 'Ä b',\n",
       " '):',\n",
       " 'ÄŠÄ Ä Ä ',\n",
       " 'Ä \"\"\"',\n",
       " 'Add',\n",
       " 'Ä the',\n",
       " 'Ä two',\n",
       " 'Ä numbers',\n",
       " 'Ä `',\n",
       " 'a',\n",
       " '`',\n",
       " 'Ä and',\n",
       " 'Ä `',\n",
       " 'b',\n",
       " '`.\"\"\"',\n",
       " 'ÄŠÄ Ä Ä ',\n",
       " 'Ä return',\n",
       " 'Ä a',\n",
       " 'Ä +',\n",
       " 'Ä b']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce090018-bdc0-49ff-bc6c-12186dfb7eee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=52000, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c7852-b689-455c-9de0-b084687ce912",
   "metadata": {},
   "source": [
    "ìœ„ ê²°ê³¼ì—ì„œ ê³µë°±(space)ê³¼ ì¤„ë°”ê¿ˆ(newline)ì„ ë‚˜íƒ€ë‚´ëŠ” íŠ¹ìˆ˜ ê¸°í˜¸ ÄŠ ë° Ä ë¥¼ ë‹¤ì‹œ ë³¼ ìˆ˜ ìˆì§€ë§Œ, ìƒˆë¡­ê²Œ í•™ìŠµëœ í† í¬ë‚˜ì´ì €ëŠ” Python í•¨ìˆ˜(function) ì½”í¼ìŠ¤ì— ë§¤ìš° íŠ¹í™”ëœ ì¼ë¶€ í† í°ì„ í•™ìŠµí–ˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë“¤ì—¬ì“°ê¸°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ÄŠÄ Ä Ä  í† í°ê³¼ ë…ìŠ¤íŠ¸ë§ì„ ì‹œì‘í•˜ëŠ” ì„¸ ê°œì˜ ë”°ì˜´í‘œë¥¼ ë‚˜íƒ€ë‚´ëŠ” Ä \"\"\" í† í°ì´ ìˆìŠµë‹ˆë‹¤. í† í¬ë‚˜ì´ì €ëŠ” _ ë¬¸ìë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•¨ìˆ˜ëª…ë„ ì˜¬ë°”ë¥´ê²Œ ë¶„í• í•©ë‹ˆë‹¤. ì´ëŠ” ë§¤ìš° ê°„ê²°í•œ(compact) í‘œí˜„ì…ë‹ˆë‹¤. ì´ì— ë¹„í•´, ë™ì¼í•œ ì˜ˆì œì—ì„œ ì¼ë°˜ì ì¸ ì˜ì–´ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ê¸´ ë¬¸ì¥(í˜¹ì€ í† í° ì‹œí€€ìŠ¤)ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e75f462a-10d0-4219-a9fc-7ba8b504d13c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(old_tokenizer.tokenize(example)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d51f6ca6-7256-4308-bc10-eef8e6eac4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'Ä Linear',\n",
       " 'Layer',\n",
       " '():',\n",
       " 'ÄŠÄ Ä Ä ',\n",
       " 'Ä def',\n",
       " 'Ä __',\n",
       " 'init',\n",
       " '__(',\n",
       " 'self',\n",
       " ',',\n",
       " 'Ä input',\n",
       " '_',\n",
       " 'size',\n",
       " ',',\n",
       " 'Ä output',\n",
       " '_',\n",
       " 'size',\n",
       " '):',\n",
       " 'ÄŠÄ Ä Ä Ä Ä Ä Ä ',\n",
       " 'Ä self',\n",
       " '.',\n",
       " 'weight',\n",
       " 'Ä =',\n",
       " 'Ä torch',\n",
       " '.',\n",
       " 'randn',\n",
       " '(',\n",
       " 'input',\n",
       " '_',\n",
       " 'size',\n",
       " ',',\n",
       " 'Ä output',\n",
       " '_',\n",
       " 'size',\n",
       " ')',\n",
       " 'ÄŠÄ Ä Ä Ä Ä Ä Ä ',\n",
       " 'Ä self',\n",
       " '.',\n",
       " 'bias',\n",
       " 'Ä =',\n",
       " 'Ä torch',\n",
       " '.',\n",
       " 'zeros',\n",
       " '(',\n",
       " 'output',\n",
       " '_',\n",
       " 'size',\n",
       " ')',\n",
       " 'ÄŠÄ ÄŠÄ Ä Ä ',\n",
       " 'Ä def',\n",
       " 'Ä __',\n",
       " 'call',\n",
       " '__(',\n",
       " 'self',\n",
       " ',',\n",
       " 'Ä x',\n",
       " '):',\n",
       " 'ÄŠÄ Ä Ä Ä Ä Ä Ä ',\n",
       " 'Ä return',\n",
       " 'Ä x',\n",
       " 'Ä @',\n",
       " 'Ä self',\n",
       " '.',\n",
       " 'weights',\n",
       " 'Ä +',\n",
       " 'Ä self',\n",
       " '.',\n",
       " 'bias',\n",
       " 'ÄŠÄ Ä Ä Ä ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"\"\"class LinearLayer():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weight = torch.randn(input_size, output_size)\n",
    "        self.bias = torch.zeros(output_size)\n",
    " \n",
    "    def __call__(self, x):\n",
    "        return x @ self.weights + self.bias\n",
    "    \"\"\"\n",
    "tokenizer.tokenize(example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc94b1c-0271-47a6-aac4-d50df362c085",
   "metadata": {},
   "source": [
    "ë“¤ì—¬ì“°ê¸°ì— í•´ë‹¹í•˜ëŠ” í† í° ì™¸ì—ë„ ì—¬ê¸°ì—ì„œëŠ” ì´ì¤‘ ë“¤ì—¬ì“°ê¸°ì— ëŒ€í•œ í† í°(ÄŠÄ Ä Ä Ä Ä Ä Ä )ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. class, init, call, self, returnê³¼ ê°™ì€ íŠ¹ìˆ˜í•œ Python ë‹¨ì–´ëŠ” ê°ê° í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ í† í°í™”ë˜ë©° _ ë° . ìœ¼ë¡œ ë¶„í• ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í† í¬ë‚˜ì´ì €ëŠ” camel-cased nameë„ ì˜¬ë°”ë¥´ê²Œ ë¶„í• í•©ë‹ˆë‹¤. LinearLayerëŠ” [\"Ä Linear\", \"Layer\"]ë¡œ í† í°í™”ë©ë‹ˆë‹¤.\n",
    "\n",
    "#### í•™ìŠµëœ í† í¬ë‚˜ì´ì € ì €ì¥\n",
    "ì´ì œ ë‚˜ì¤‘ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ìƒˆ í† í¬ë‚˜ì´ì €ë¥¼ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤. ëª¨ë¸ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì´ ì‘ì—…ì€ save_pretrained() ë©”ì„œë“œë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a4765cd-84d8-48d1-a525-26df27f5307b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('code-search-net-tokenizer/tokenizer_config.json',\n",
       " 'code-search-net-tokenizer/special_tokens_map.json',\n",
       " 'code-search-net-tokenizer/vocab.json',\n",
       " 'code-search-net-tokenizer/merges.txt',\n",
       " 'code-search-net-tokenizer/added_tokens.json',\n",
       " 'code-search-net-tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"code-search-net-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f92af5a-d9c7-4372-a2e1-e7509d48238b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e5ecd288ab4267a0e46af1aabc977c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a97be9bd-3477-427d-a8a8-cfed0a78d669",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/hwang2006/code-search-net-tokenizer/commit/e8ab7fb55d2ac92ff1a090844b54cbf622e74753', commit_message='Upload tokenizer', commit_description='', oid='e8ab7fb55d2ac92ff1a090844b54cbf622e74753', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"code-search-net-tokenizer\", use_temp_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e43ca73e-5e25-4565-9b3c-4c09c329f311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ë‹¹ì‹ ì´ ì§ì ‘ ì´ ì„¹ì…˜ì—ì„œ í•™ìŠµí•œ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ,\n",
    "# ì•„ë˜ì˜ \"spasis\"ë¥¼ ë‹¹ì‹ ì˜ ì‹¤ì œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ë³€ê²½í•˜ì‹­ì‹œì˜¤.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hwang2006/code-search-net-tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f44798d-d7a4-4544-a3d9-70c9ffa63b34",
   "metadata": {},
   "source": [
    "### 2. \"ë¹ ë¥¸(fast)\" í† í¬ë‚˜ì´ì €ì˜ íŠ¹ë³„í•œ ëŠ¥ë ¥\n",
    "#### ë°°ì¹˜ ì¸ì½”ë”© (Batch encoding)\n",
    "í† í¬ë‚˜ì´ì €ì˜ ì¶œë ¥ì€ ë‹¨ìˆœí•œ Python ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì–»ëŠ” ê²ƒì€ ì‹¤ì œë¡œ íŠ¹ë³„í•œ BatchEncoding ê°ì²´ì…ë‹ˆë‹¤. ì´ê²ƒì€ ë”•ì…”ë„ˆë¦¬ì˜ í•˜ìœ„ í´ë˜ìŠ¤ì´ì§€ë§Œ(ì´ê²ƒì´ ì´ì „ì— ìš°ë¦¬ê°€ ë¬¸ì œì—†ì´ í•´ë‹¹ ê²°ê³¼ë¥¼ ìƒ‰ì¸í™”í•  ìˆ˜ ìˆì—ˆë˜ ì´ìœ ì…ë‹ˆë‹¤), ë¹ ë¥¸ í† í¬ë‚˜ì´ì €ì—ì„œ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì¶”ê°€ ë©”ì„œë“œê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë³‘ë ¬í™”(parallelization) ê¸°ëŠ¥ ì™¸ì—ë„, ë¹ ë¥¸ í† í¬ë‚˜ì´ì €ì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ìµœì¢… í† í°ì´ ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì–´ë””ì— ìœ„ì¹˜í•˜ëŠ”ì§€ ë²”ìœ„(span)ë¥¼ í•­ìƒ ì¶”ì í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ì˜¤í”„ì…‹ ë§¤í•‘(offset mapping) ì´ë¼ê³  í•©ë‹ˆë‹¤. ì´ê²ƒì€ ì°¨ë¡€ëŒ€ë¡œ ê° ë‹¨ì–´ë¥¼ ìƒì„±ëœ í† í°ì— ë§¤í•‘í•˜ê±°ë‚˜ ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ê° ë¬¸ìë¥¼ ë‚´ë¶€ í† í°ì— ë§¤í•‘í•˜ê±°ë‚˜ ê·¸ ë°˜ëŒ€ë¡œ ë§¤í•‘í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ê¸°ëŠ¥ë“¤ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e644d22e-d6a8-47f7-aa44-99ed00c8cc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1422, 1271, 1110, 156, 7777, 2497, 1394, 1105, 146, 1250, 1120, 20164, 10932, 10289, 1107, 6010, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
    "encoding = tokenizer(example)\n",
    "print(encoding)\n",
    "print(type(encoding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71616453-7efe-448a-b337-e267101064c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.is_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be1b69-c7e3-4c45-bda3-1e3f137cb8bb",
   "metadata": {},
   "source": [
    "ë¹ ë¥¸ í† í¬ë‚˜ì´ì €ë¥¼ ê°€ì§€ê³  ìš°ë¦¬ê°€ ë¬´ì—‡ì„ í•  ìˆ˜ ìˆëŠ”ì§€ ë´…ì‹œë‹¤. ì²«ì§¸, í† í° ì•„ì´ë””ë¥¼ ë‹¤ì‹œ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ì§€ ì•Šê³ ë„ í† í°ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee87061a-7229-46bc-bb91-f12b9337be5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'S',\n",
       " '##yl',\n",
       " '##va',\n",
       " '##in',\n",
       " 'and',\n",
       " 'I',\n",
       " 'work',\n",
       " 'at',\n",
       " 'Hu',\n",
       " '##gging',\n",
       " 'Face',\n",
       " 'in',\n",
       " 'Brooklyn',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3183b4a-9676-4257-9c52-26fafaf35c60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, None]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6847e2fb-2892-4386-b849-df6bc4993514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sylvain'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = encoding.word_to_chars(3)\n",
    "print(start, end)\n",
    "example[start:end]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1c1a9-1772-4d3d-9a18-5448774f1972",
   "metadata": {},
   "source": [
    "#### token-classification íŒŒì´í”„ë¼ì¸ì˜ ë‚´ë¶€ ë™ì‘\n",
    "1ì¥ì—ì„œ ìš°ë¦¬ëŠ” ğŸ¤—Transformersì˜ pipeline() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬, í…ìŠ¤íŠ¸ì˜ ì–´ëŠ ë¶€ë¶„ì´ ì‚¬ëŒ(person), ìœ„ì¹˜(location) ë˜ëŠ” ì¡°ì§(organization)ê³¼ ê°™ì€ ì—”í„°í‹°(entities)ì— í•´ë‹¹í•˜ëŠ”ì§€ ì‹ë³„í•˜ëŠ” ì‘ì—…ì¸ NERì„ ì²˜ìŒìœ¼ë¡œ ì‚´í´ë´¤ìŠµë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ 2ì¥ì—ì„œ íŒŒì´í”„ë¼ì¸ì´ ì›ì‹œ í…ìŠ¤íŠ¸ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ”ë° í•„ìš”í•œ ì„¸ ë‹¨ê³„ ì¦‰, í† í°í™”(tokenization), ëª¨ë¸ì„ í†µí•œ ì…ë ¥ ì „ë‹¬, í›„ì²˜ë¦¬(post-processing)ë¥¼ ì–´ë–»ê²Œ ê·¸ë£¹í™”í•˜ëŠ”ì§€ë¥¼ ë³´ì•˜ìŠµë‹ˆë‹¤. token-classification íŒŒì´í”„ë¼ì¸ì˜ ì²˜ìŒ ë‘ ë‹¨ê³„ëŠ” ë‹¤ë¥¸ íŒŒì´í”„ë¼ì¸ê³¼ ë™ì¼í•˜ì§€ë§Œ í›„ì²˜ë¦¬(post-processing)ëŠ” ì¡°ê¸ˆ ë” ë³µì¡í•©ë‹ˆë‹¤. í•œë²ˆ ì‚´í´ë´…ì‹œë‹¤!\n",
    "\n",
    "#### íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ê¸°ë³¸ ì‹¤í–‰ ê²°ê³¼ ë„ì¶œí•˜ê¸°\n",
    "ë¨¼ì €, ìˆ˜ì‘ì—…ìœ¼ë¡œ ë¹„êµí•  ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ token-classification íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ì€ dbmdz/bert-large-cased-finetuned-conll03-englishì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë¬¸ì¥ì— ëŒ€í•´ NERë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d456e6f2-2916-47b5-8988-c620166de362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': 0.99938285,\n",
       "  'index': 4,\n",
       "  'word': 'S',\n",
       "  'start': 11,\n",
       "  'end': 12},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99815494,\n",
       "  'index': 5,\n",
       "  'word': '##yl',\n",
       "  'start': 12,\n",
       "  'end': 14},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99590707,\n",
       "  'index': 6,\n",
       "  'word': '##va',\n",
       "  'start': 14,\n",
       "  'end': 16},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99923277,\n",
       "  'index': 7,\n",
       "  'word': '##in',\n",
       "  'start': 16,\n",
       "  'end': 18},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9738931,\n",
       "  'index': 12,\n",
       "  'word': 'Hu',\n",
       "  'start': 33,\n",
       "  'end': 35},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.976115,\n",
       "  'index': 13,\n",
       "  'word': '##gging',\n",
       "  'start': 35,\n",
       "  'end': 40},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9887976,\n",
       "  'index': 14,\n",
       "  'word': 'Face',\n",
       "  'start': 41,\n",
       "  'end': 45},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9932106,\n",
       "  'index': 16,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\")\n",
    "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7372d723-130c-4ecb-9492-b48448419ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796019,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\", aggregation_strategy=\"simple\")\n",
    "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2aa6a808-ce6e-4a5d-8520-f35c45548627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9819008,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\", aggregation_strategy=\"average\")\n",
    "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce5b6d-e45b-4e5d-ba5d-a0c1d8e527d2",
   "metadata": {},
   "source": [
    "aggregation_strategyë¥¼ ìœ„ì™€ ê°™ì´ ì§€ì •í•˜ë©´ í† í°ë“¤ì´ í•˜ë‚˜ë¡œ í•©ì³ì§„ ì—”í„°í‹°ì— ëŒ€í•´ ìƒˆë¡­ê²Œ ê³„ì‚°ëœ ìŠ¤ì½”ì–´ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. \"simple\"ì˜ ê²½ìš° ìŠ¤ì½”ì–´ëŠ” í•´ë‹¹ ê°œì²´ëª… ë‚´ì˜ ê° í† í°ì— ëŒ€í•œ ìŠ¤ì½”ì–´ì˜ í‰ê· ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, \"Sylvain\"ì˜ ìŠ¤ì½”ì–´ëŠ” ì´ì „ ì˜ˆì—ì„œ S, ##yl, ##va ë° ##in í† í°ì— ëŒ€í•´ ê³„ì‚°ëœ ìŠ¤ì½”ì–´ì˜ í‰ê· ì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ë‹¤ë¥¸ ì§€ì •ìëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "\"first\", ì—¬ê¸°ì„œ ê° ê°œì²´ëª…ì˜ ìŠ¤ì½”ì–´ëŠ” í•´ë‹¹ ê°œì²´ëª…ì˜ ì²« ë²ˆì§¸ í† í°ì˜ ìŠ¤ì½”ì–´ì…ë‹ˆë‹¤(ë”°ë¼ì„œ \"Sylvain\"ì˜ ê²½ìš° í† í° Sì˜ ì ìˆ˜ì¸ 0.993828ì´ ë¨).\n",
    "\n",
    "\"max\", ì—¬ê¸°ì„œ ê° ì—”í„°í‹°ì˜ ìŠ¤ì½”ì–´ëŠ” í•´ë‹¹ ì—”í„°í‹°ë‚´ì˜ í† í°ë“¤ ì¤‘ì˜ ìµœëŒ€ê°’ ìŠ¤ì½”ì–´ì…ë‹ˆë‹¤(\"Hugging Face\"ì˜ ê²½ìš° \"Face\"ì˜ ì ìˆ˜ëŠ” 0.98879766ì´ ë¨).\n",
    "\n",
    "\"average\", ì—¬ê¸°ì„œ ê° í•­ëª©ì˜ ìŠ¤ì½”ì–´ëŠ” í•´ë‹¹ í•­ëª©ì„ êµ¬ì„±í•˜ëŠ” ë‹¨ì–´(í† í°ì´ ì•„ë‹™ë‹ˆë‹¤) ìŠ¤ì½”ì–´ì˜ í‰ê· ì…ë‹ˆë‹¤(ë”°ë¼ì„œ \"Sylvain\"ì˜ ê²½ìš° \"simple\" ì§€ì •ìì™€ ì°¨ì´ê°€ ì—†ì§€ë§Œ \"Hugging Face\"ì˜ ì ìˆ˜ëŠ” 0.9819ì´ë©° \"Hugging\"ì€ 0.975ì´ê³  \"Face\"ëŠ” 0.98879ì…ë‹ˆë‹¤).\n",
    "\n",
    "ì´ì œ pipeline() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì´ëŸ¬í•œ ê²°ê³¼ë¥¼ ì–»ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1de42d0-8034-4113-a4f2-158c47eadc85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796019,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named Entity Recognition (NER)\n",
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\"ner\", grouped_entities=True)\n",
    "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa66f26a-6fe4-44d4-99e8-3c83759974b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "\n",
    "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
    "inputs = tokenizer(example, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7147c12f-ee8b-41f3-a6c4-5af2452fa033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 19])\n",
      "torch.Size([1, 19, 9])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"].shape)\n",
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6d50610-7778-4d0e-b434-01da51679d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'My', 'name', 'is', 'S', '##yl', '##va', '##in', 'and', 'I', 'work', 'at', 'Hu', '##gging', 'Face', 'in', 'Brooklyn', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(inputs.tokens())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86bc3c-2eb3-4acd-abd0-51362730053c",
   "metadata": {},
   "source": [
    "19ê°œì˜ í† í°ìœ¼ë¡œ êµ¬ì„±ëœ 1ê°œì˜ ì‹œí€€ìŠ¤ê°€ ìˆëŠ” ë°°ì¹˜(batch)ê°€ ìˆê³  ëª¨ë¸ì—ëŠ” 9ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ë ˆì´ë¸”ì´ ì¡´ì¬í•˜ë¯€ë¡œ ëª¨ë¸ì˜ ì¶œë ¥ì€ 1 x 19 x 9ì˜ ëª¨ì–‘ì„ ê°–ìŠµë‹ˆë‹¤. text-classification íŒŒì´í”„ë¼ì¸ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ softmax í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ logitsì„ í™•ë¥ ë¡œ ë³€í™˜í•˜ê³  argmaxë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤(softmaxëŠ” ìˆœì„œë¥¼ ë³€ê²½í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— logitsì— ëŒ€í•´ì„œ argmaxë¥¼ ì·¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7eb82774-6b1c-430c-8cad-9052100ac5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9994322657585144, 1.6470283298986033e-05, 3.4266999136889353e-05, 1.6042311472119763e-05, 8.250683458754793e-05, 2.1382273189374246e-05, 0.00015649090346414596, 1.965209776244592e-05, 0.00022089220874477178], [0.9989631175994873, 1.8515736883273348e-05, 5.240452446741983e-05, 1.253474511031527e-05, 0.0004347366339061409, 3.087432560278103e-05, 0.00031468752422370017, 2.78607003565412e-05, 0.00014510865730699152], [0.999708354473114, 8.30812678032089e-06, 2.8745640520355664e-05, 5.650358161801705e-06, 8.69486466399394e-05, 9.783458153833635e-06, 6.786145240766928e-05, 1.1793980775109958e-05, 7.241900311782956e-05], [0.9998350143432617, 5.645536475640256e-06, 1.3955165741208475e-05, 4.3133732106070966e-06, 4.017691026092507e-05, 8.123070074361749e-06, 5.6484961532987654e-05, 8.99163478607079e-06, 2.7239138944423757e-05], [0.00018333422485738993, 2.5156617994070984e-05, 4.8462032282259315e-05, 1.4900553651386872e-05, 0.9993828535079956, 1.99977403099183e-05, 0.00011153621017001569, 1.0790749911393505e-05, 0.00020288894302211702], [0.0006440270808525383, 7.437894237227738e-05, 0.00013196618237998337, 3.471966556389816e-05, 0.9981548190116882, 3.382968498044647e-05, 0.000543818052392453, 1.9978177078883164e-05, 0.0003624462988227606], [0.0016408422961831093, 9.469492943026125e-05, 0.00027364378911443055, 4.440645716385916e-05, 0.995907187461853, 5.1262213673908263e-05, 0.0012787937885150313, 3.283548358012922e-05, 0.0006763280252926052], [0.00022901801276020706, 2.518332257750444e-05, 5.7899465900845826e-05, 9.95701066131005e-06, 0.9992327690124512, 1.7655056581133977e-05, 0.00023448324645869434, 1.2356568731775042e-05, 0.0001806502405088395], [0.999804675579071, 5.465042249852559e-06, 1.2950029486091807e-05, 4.972443548467709e-06, 2.350327486055903e-05, 1.2930740012961905e-05, 9.509934898233041e-05, 8.891779543773737e-06, 3.146939707221463e-05], [0.9995046854019165, 1.4611860024160706e-05, 2.96468806482153e-05, 8.223405529861338e-06, 0.000160165160195902, 2.0456785932765342e-05, 0.0001753710093908012, 1.9349117792444304e-05, 6.74397379043512e-05], [0.9996776580810547, 7.596950126753654e-06, 1.700691063888371e-05, 3.7776110275444807e-06, 6.39606878394261e-05, 1.229785630130209e-05, 0.00018241394718643278, 7.648396604054142e-06, 2.766460966086015e-05], [0.999434769153595, 1.1278339115960989e-05, 2.8862770705018193e-05, 6.246603334147949e-06, 8.598288695793599e-05, 2.298940671607852e-05, 0.0003494526317808777, 1.3841339750797488e-05, 4.654669464798644e-05], [0.018156303092837334, 6.24591630185023e-05, 0.00026932242326438427, 4.766620259033516e-05, 0.0061346301808953285, 0.00023967465676832944, 0.9738931059837341, 7.093795284163207e-05, 0.001125914161093533], [0.014645998366177082, 0.0002047977759502828, 0.002236028900370002, 9.357065573567525e-05, 0.003731631673872471, 0.0005988667835481465, 0.9761149883270264, 0.00017609857604838908, 0.0021980972960591316], [0.0031715729273855686, 8.892173354979604e-05, 0.0015001465799286962, 7.653019565623254e-05, 0.0033575661946088076, 0.0004643830470740795, 0.9887974858283997, 0.00010871348058572039, 0.0024345973506569862], [0.9995326995849609, 6.553959792654496e-06, 2.831611709552817e-05, 6.235935870790854e-06, 3.73719994968269e-05, 2.035711077041924e-05, 0.00028727450990118086, 1.5032612282084301e-05, 6.614286394324154e-05], [0.0006589225959032774, 6.67124695610255e-05, 0.0002244396455353126, 4.190392428427003e-05, 0.00046020327135920525, 9.038783173309639e-05, 0.005088846664875746, 0.00015803218411747366, 0.99321049451828], [0.9994322657585144, 1.6470645277877338e-05, 3.426755574764684e-05, 1.6042418792494573e-05, 8.250888640759513e-05, 2.1382315026130527e-05, 0.00015649314445909113, 1.9652265109471045e-05, 0.00022089347476139665], [0.9994322657585144, 1.6470283298986033e-05, 3.426703187869862e-05, 1.6042327843024395e-05, 8.250691462308168e-05, 2.1382315026130527e-05, 0.00015649104898329824, 1.965213414223399e-05, 0.0002208926307503134]]\n",
      "[0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import torch\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].tolist()\n",
    "predictions = outputs.logits.argmax(dim=-1)[0].tolist()\n",
    "print(probabilities)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee0cea07-b3ab-4e4e-b815-e00ebb57155f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d99fc521-5205-4cd1-98a9-d0fb74a661df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9.9943e-01, 1.6470e-05, 3.4267e-05, 1.6042e-05, 8.2507e-05,\n",
       "          2.1382e-05, 1.5649e-04, 1.9652e-05, 2.2089e-04],\n",
       "         [9.9896e-01, 1.8516e-05, 5.2405e-05, 1.2535e-05, 4.3474e-04,\n",
       "          3.0874e-05, 3.1469e-04, 2.7861e-05, 1.4511e-04],\n",
       "         [9.9971e-01, 8.3081e-06, 2.8746e-05, 5.6504e-06, 8.6949e-05,\n",
       "          9.7835e-06, 6.7861e-05, 1.1794e-05, 7.2419e-05],\n",
       "         [9.9984e-01, 5.6455e-06, 1.3955e-05, 4.3134e-06, 4.0177e-05,\n",
       "          8.1231e-06, 5.6485e-05, 8.9916e-06, 2.7239e-05],\n",
       "         [1.8333e-04, 2.5157e-05, 4.8462e-05, 1.4901e-05, 9.9938e-01,\n",
       "          1.9998e-05, 1.1154e-04, 1.0791e-05, 2.0289e-04],\n",
       "         [6.4403e-04, 7.4379e-05, 1.3197e-04, 3.4720e-05, 9.9815e-01,\n",
       "          3.3830e-05, 5.4382e-04, 1.9978e-05, 3.6245e-04],\n",
       "         [1.6408e-03, 9.4695e-05, 2.7364e-04, 4.4406e-05, 9.9591e-01,\n",
       "          5.1262e-05, 1.2788e-03, 3.2835e-05, 6.7633e-04],\n",
       "         [2.2902e-04, 2.5183e-05, 5.7899e-05, 9.9570e-06, 9.9923e-01,\n",
       "          1.7655e-05, 2.3448e-04, 1.2357e-05, 1.8065e-04],\n",
       "         [9.9980e-01, 5.4650e-06, 1.2950e-05, 4.9724e-06, 2.3503e-05,\n",
       "          1.2931e-05, 9.5099e-05, 8.8918e-06, 3.1469e-05],\n",
       "         [9.9950e-01, 1.4612e-05, 2.9647e-05, 8.2234e-06, 1.6017e-04,\n",
       "          2.0457e-05, 1.7537e-04, 1.9349e-05, 6.7440e-05],\n",
       "         [9.9968e-01, 7.5970e-06, 1.7007e-05, 3.7776e-06, 6.3961e-05,\n",
       "          1.2298e-05, 1.8241e-04, 7.6484e-06, 2.7665e-05],\n",
       "         [9.9943e-01, 1.1278e-05, 2.8863e-05, 6.2466e-06, 8.5983e-05,\n",
       "          2.2989e-05, 3.4945e-04, 1.3841e-05, 4.6547e-05],\n",
       "         [1.8156e-02, 6.2459e-05, 2.6932e-04, 4.7666e-05, 6.1346e-03,\n",
       "          2.3967e-04, 9.7389e-01, 7.0938e-05, 1.1259e-03],\n",
       "         [1.4646e-02, 2.0480e-04, 2.2360e-03, 9.3571e-05, 3.7316e-03,\n",
       "          5.9887e-04, 9.7611e-01, 1.7610e-04, 2.1981e-03],\n",
       "         [3.1716e-03, 8.8922e-05, 1.5001e-03, 7.6530e-05, 3.3576e-03,\n",
       "          4.6438e-04, 9.8880e-01, 1.0871e-04, 2.4346e-03],\n",
       "         [9.9953e-01, 6.5540e-06, 2.8316e-05, 6.2359e-06, 3.7372e-05,\n",
       "          2.0357e-05, 2.8727e-04, 1.5033e-05, 6.6143e-05],\n",
       "         [6.5892e-04, 6.6712e-05, 2.2444e-04, 4.1904e-05, 4.6020e-04,\n",
       "          9.0388e-05, 5.0888e-03, 1.5803e-04, 9.9321e-01],\n",
       "         [9.9943e-01, 1.6471e-05, 3.4268e-05, 1.6042e-05, 8.2509e-05,\n",
       "          2.1382e-05, 1.5649e-04, 1.9652e-05, 2.2089e-04],\n",
       "         [9.9943e-01, 1.6470e-05, 3.4267e-05, 1.6042e-05, 8.2507e-05,\n",
       "          2.1382e-05, 1.5649e-04, 1.9652e-05, 2.2089e-04]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(outputs.logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4916c79f-3ffa-4c1f-81c5-984ac9a8cf74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
       "  \"_num_labels\": 9,\n",
       "  \"architectures\": [\n",
       "    \"BertForTokenClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"O\",\n",
       "    \"1\": \"B-MISC\",\n",
       "    \"2\": \"I-MISC\",\n",
       "    \"3\": \"B-PER\",\n",
       "    \"4\": \"I-PER\",\n",
       "    \"5\": \"B-ORG\",\n",
       "    \"6\": \"I-ORG\",\n",
       "    \"7\": \"B-LOC\",\n",
       "    \"8\": \"I-LOC\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"label2id\": {\n",
       "    \"B-LOC\": 7,\n",
       "    \"B-MISC\": 1,\n",
       "    \"B-ORG\": 5,\n",
       "    \"B-PER\": 3,\n",
       "    \"I-LOC\": 8,\n",
       "    \"I-MISC\": 2,\n",
       "    \"I-ORG\": 6,\n",
       "    \"I-PER\": 4,\n",
       "    \"O\": 0\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.39.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 28996\n",
       "}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d97cfb41-c83a-44ba-911f-edac9f877f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
    "inputs = tokenizer(example, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f650cfca-265f-40a8-8c61-dd77b7eae2bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'My', 'name', 'is', 'S', '##yl', '##va', '##in', 'and', 'I', 'work', 'at', 'Hu', '##gging', 'Face', 'in', 'Brooklyn', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(inputs.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a46dbc4c-0b4b-449a-b94f-a152839d2dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'I-PER', 'score': 0.9993828535079956, 'word': 'S'},\n",
      " {'entity': 'I-PER', 'score': 0.9981548190116882, 'word': '##yl'},\n",
      " {'entity': 'I-PER', 'score': 0.995907187461853, 'word': '##va'},\n",
      " {'entity': 'I-PER', 'score': 0.9992327690124512, 'word': '##in'},\n",
      " {'entity': 'I-ORG', 'score': 0.9738931059837341, 'word': 'Hu'},\n",
      " {'entity': 'I-ORG', 'score': 0.9761149883270264, 'word': '##gging'},\n",
      " {'entity': 'I-ORG', 'score': 0.9887974858283997, 'word': 'Face'},\n",
      " {'entity': 'I-LOC', 'score': 0.99321049451828, 'word': 'Brooklyn'}]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "tokens = inputs.tokens()\n",
    "\n",
    "# predictions: [0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]\n",
    "# probabilities.shape = [19, 9]\n",
    "for idx, pred in enumerate(predictions):\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != \"O\":\n",
    "        results.append(\n",
    "            {\"entity\": label, \"score\": probabilities[idx][pred], \"word\": tokens[idx]}\n",
    "        )\n",
    "\n",
    "pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b61f7e9-d511-48d6-9af9-340fc7b8884e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 2),\n",
       " (3, 7),\n",
       " (8, 10),\n",
       " (11, 12),\n",
       " (12, 14),\n",
       " (14, 16),\n",
       " (16, 18),\n",
       " (19, 22),\n",
       " (23, 24),\n",
       " (25, 29),\n",
       " (30, 32),\n",
       " (33, 35),\n",
       " (35, 40),\n",
       " (41, 45),\n",
       " (46, 48),\n",
       " (49, 57),\n",
       " (57, 58),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
    "inputs_with_offsets[\"offset_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce2193c6-d8f9-4315-865b-55fcd533bca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yl'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d9ef623-d78e-4ace-a60a-6da5e82e3774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'end': 12,\n",
      "  'entity': 'I-PER',\n",
      "  'score': 0.9993828535079956,\n",
      "  'start': 11,\n",
      "  'word': 'S'},\n",
      " {'end': 14,\n",
      "  'entity': 'I-PER',\n",
      "  'score': 0.9981548190116882,\n",
      "  'start': 12,\n",
      "  'word': '##yl'},\n",
      " {'end': 16,\n",
      "  'entity': 'I-PER',\n",
      "  'score': 0.995907187461853,\n",
      "  'start': 14,\n",
      "  'word': '##va'},\n",
      " {'end': 18,\n",
      "  'entity': 'I-PER',\n",
      "  'score': 0.9992327690124512,\n",
      "  'start': 16,\n",
      "  'word': '##in'},\n",
      " {'end': 35,\n",
      "  'entity': 'I-ORG',\n",
      "  'score': 0.9738931059837341,\n",
      "  'start': 33,\n",
      "  'word': 'Hu'},\n",
      " {'end': 40,\n",
      "  'entity': 'I-ORG',\n",
      "  'score': 0.9761149883270264,\n",
      "  'start': 35,\n",
      "  'word': '##gging'},\n",
      " {'end': 45,\n",
      "  'entity': 'I-ORG',\n",
      "  'score': 0.9887974858283997,\n",
      "  'start': 41,\n",
      "  'word': 'Face'},\n",
      " {'end': 57,\n",
      "  'entity': 'I-LOC',\n",
      "  'score': 0.99321049451828,\n",
      "  'start': 49,\n",
      "  'word': 'Brooklyn'}]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
    "tokens = inputs_with_offsets.tokens()\n",
    "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
    "\n",
    "# prediction : [0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]\n",
    "for idx, pred in enumerate(predictions): \n",
    "    label = model.config.id2label[pred]\n",
    "    if label != 'O':\n",
    "        start, end = offsets[idx]\n",
    "        results.append(\n",
    "            {\n",
    "                \"entity\": label,\n",
    "                \"score\": probabilities[idx][pred],\n",
    "                \"word\": tokens[idx],\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "            }\n",
    "        )\n",
    "\n",
    "pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0c7f4e7-0173-4b29-b570-c70777c7c551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hugging Face'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[33:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c268bfd2-4af4-423e-bb4e-e3f6e37faa77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'end': 18,\n",
      "  'entity_group': 'PER',\n",
      "  'score': 0.998169407248497,\n",
      "  'start': 11,\n",
      "  'word': 'Sylvain'},\n",
      " {'end': 45,\n",
      "  'entity_group': 'ORG',\n",
      "  'score': 0.9796018600463867,\n",
      "  'start': 33,\n",
      "  'word': 'Hugging Face'},\n",
      " {'end': 57,\n",
      "  'entity_group': 'LOC',\n",
      "  'score': 0.99321049451828,\n",
      "  'start': 49,\n",
      "  'word': 'Brooklyn'}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True)\n",
    "tokens = inputs_with_offsets.tokens()\n",
    "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
    "\n",
    "idx = 0\n",
    "while idx < len(predictions):\n",
    "    pred = predictions[idx]\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != \"O\":\n",
    "        # Remove the B- or I-\n",
    "        label = label[2:]\n",
    "        start, _ = offsets[idx]\n",
    "\n",
    "        # Grab all the tokens labeled with I-label\n",
    "        all_scores = []\n",
    "        while (\n",
    "            idx < len(predictions)\n",
    "            and model.config.id2label[predictions[idx]] == f\"I-{label}\"\n",
    "        ):\n",
    "            all_scores.append(probabilities[idx][pred])\n",
    "            _, end = offsets[idx]\n",
    "            idx += 1\n",
    "\n",
    "        # The score is the mean of all the scores of the tokens in that grouped entity\n",
    "        score = np.mean(all_scores).item()\n",
    "        word = example[start:end]\n",
    "        results.append(\n",
    "            {\n",
    "                \"entity_group\": label,\n",
    "                \"score\": score,\n",
    "                \"word\": word,\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "            }\n",
    "        )\n",
    "    idx += 1\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e0768-1c96-4ff5-8fa2-47067fa8d0dd",
   "metadata": {},
   "source": [
    "### 3. QA íŒŒì´í”„ë¼ì¸ì—ì„œì˜ \"ë¹ ë¥¸(fast)\" í† í¬ë‚˜ì´ì €\n",
    "#### question-answering íŒŒì´í”„ë¼ì¸ ì‚¬ìš©í•˜ê¸°\n",
    "1ì¥ì—ì„œ ë³´ì•˜ë“¯ì´ ìš°ë¦¬ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì–»ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ question-answering íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3816ca4-d6b6-499a-ab95-b478f7043e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9802603125572205,\n",
       " 'start': 78,\n",
       " 'end': 106,\n",
       " 'answer': 'Jax, PyTorch, and TensorFlow'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "context = \"\"\"\n",
    "ğŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch, and TensorFlow â€” with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\"\n",
    "question = \"Which deep learning libraries back ğŸ¤— Transformers?\"\n",
    "question_answerer(question=question, context=context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01308437-4e97-44e7-b1d5-32ace7957cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9714871048927307,\n",
       " 'start': 1892,\n",
       " 'end': 1919,\n",
       " 'answer': 'Jax, PyTorch and TensorFlow'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_context = \"\"\"\n",
    "ğŸ¤— Transformers: State of the Art NLP\n",
    "\n",
    "ğŸ¤— Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,\n",
    "question answering, summarization, translation, text generation and more in over 100 languages.\n",
    "Its aim is to make cutting-edge NLP easier to use for everyone.\n",
    "\n",
    "ğŸ¤— Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and\n",
    "then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and\n",
    "can be modified to enable quick research experiments.\n",
    "\n",
    "Why should I use transformers?\n",
    "\n",
    "1. Easy-to-use state-of-the-art models:\n",
    "  - High performance on NLU and NLG tasks.\n",
    "  - Low barrier to entry for educators and practitioners.\n",
    "  - Few user-facing abstractions with just three classes to learn.\n",
    "  - A unified API for using all our pretrained models.\n",
    "  - Lower compute costs, smaller carbon footprint:\n",
    "\n",
    "2. Researchers can share trained models instead of always retraining.\n",
    "  - Practitioners can reduce compute time and production costs.\n",
    "  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.\n",
    "\n",
    "3. Choose the right framework for every part of a model's lifetime:\n",
    "  - Train state-of-the-art models in 3 lines of code.\n",
    "  - Move a single model between TF2.0/PyTorch frameworks at will.\n",
    "  - Seamlessly pick the right framework for training, evaluation and production.\n",
    "\n",
    "4. Easily customize a model or an example to your needs:\n",
    "  - We provide examples for each architecture to reproduce the results published by its original authors.\n",
    "  - Model internals are exposed as consistently as possible.\n",
    "  - Model files can be used independently of the library for quick experiments.\n",
    "\n",
    "ğŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\"\n",
    "question_answerer(question=question, context=long_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e302d4f0-9ca6-400c-9674-53526fb96719",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.question_answering.QuestionAnsweringPipeline at 0x2b02c825cac0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "379553f4-7e7b-4813-a4b9-f53a85dd1b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "model_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e63eaa5-ba17-44c4-b9b6-6a0ff20d821d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
      " 'input_ids': tensor([[  101,  5979,  1996,  3776,  9818,  1171,   100, 25267,   136,   102,\n",
      "           100, 25267,  1110,  5534,  1118,  1103,  1210,  1211,  1927,  1996,\n",
      "          3776,  9818,   783, 13612,   117,   153,  1183,  1942,  1766,  1732,\n",
      "           117,  1105,  5157, 21484,  2271,  6737,   783,  1114,   170,  2343,\n",
      "          1306,  2008,  9111,  1206,  1172,   119,  1135,   112,   188, 21546,\n",
      "          1106,  2669,  1240,  3584,  1114,  1141,  1196, 10745,  1172,  1111,\n",
      "          1107, 16792,  1114,  1103,  1168,   119,   102]])}\n"
     ]
    }
   ],
   "source": [
    "pprint(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1430f7eb-5479-43c9-a018-7d21232f55c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "['[CLS]', 'Which', 'deep', 'learning', 'libraries', 'back', '[UNK]', 'Transformers', '?', '[SEP]', '[UNK]', 'Transformers', 'is', 'backed', 'by', 'the', 'three', 'most', 'popular', 'deep', 'learning', 'libraries', 'â€”', 'Jax', ',', 'P', '##y', '##T', '##or', '##ch', ',', 'and', 'Ten', '##sor', '##F', '##low', 'â€”', 'with', 'a', 'sea', '##m', '##less', 'integration', 'between', 'them', '.', 'It', \"'\", 's', 'straightforward', 'to', 'train', 'your', 'models', 'with', 'one', 'before', 'loading', 'them', 'for', 'in', '##ference', 'with', 'the', 'other', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(len(inputs.tokens()))\n",
    "print(inputs.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "961acae1-9a75-45bb-ac4a-9aa9640747f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-4.4952, -6.4454, -4.7115, -7.0968, -7.0726, -7.4981, -5.5397, -4.1368,\n",
       "         -5.9199, -5.4193, -1.5920, -1.0857, -5.0981, -2.9331, -3.4070,  2.2467,\n",
       "          5.1563, -1.3602, -2.2209, -0.9686, -4.8112, -2.2527,  1.4383, 10.1211,\n",
       "         -1.5311,  2.2685, -1.8951, -2.2108, -4.2142, -2.5571, -2.3252, -2.6046,\n",
       "          1.7047, -1.9867, -1.7211, -0.5415, -2.0239, -4.4246, -5.1012, -4.4966,\n",
       "         -7.8940, -6.7200, -4.6759, -6.3278, -4.8339, -5.1839, -3.3724, -7.4120,\n",
       "         -8.1542, -4.4871, -7.4659, -4.3293, -4.2293, -3.1903, -7.9467, -5.2665,\n",
       "         -7.5902, -5.0570, -7.4476, -7.9083, -6.5951, -7.4061, -8.8821, -7.6749,\n",
       "         -6.9879, -7.0466, -5.4193]], grad_fn=<CloneBackward0>), end_logits=tensor([[-2.3958e+00, -7.0978e+00, -7.0745e+00, -6.3676e+00, -5.9532e+00,\n",
       "         -7.9585e+00, -7.1869e+00, -3.6494e+00, -6.9677e+00, -5.1421e+00,\n",
       "         -3.1757e+00, -1.1649e+00, -7.0748e+00, -5.2875e+00, -6.8611e+00,\n",
       "         -5.1769e+00,  3.7892e+00, -4.4408e+00, -7.6688e-01, -3.9180e+00,\n",
       "         -2.1634e+00,  1.8116e+00, -1.4678e+00,  2.0508e+00,  1.5437e-03,\n",
       "         -1.5531e+00, -6.9469e-01, -1.3466e+00, -1.6879e+00,  4.0826e+00,\n",
       "          1.1467e+00, -3.7881e-01,  6.0774e-01,  1.2281e+00,  5.8202e-01,\n",
       "          1.0657e+01,  5.8794e+00, -5.7342e+00, -7.0719e+00, -6.8077e+00,\n",
       "         -7.1513e+00, -5.3228e+00, -3.4305e+00, -4.2575e+00,  2.2268e+00,\n",
       "         -4.1297e-01, -6.8944e+00, -7.9381e+00, -8.3298e+00, -5.6078e+00,\n",
       "         -8.9589e+00, -5.5772e+00, -5.7309e+00, -1.9592e+00, -7.8078e+00,\n",
       "         -2.3823e+00, -7.2457e+00, -6.1642e+00, -4.2830e+00, -8.0948e+00,\n",
       "         -8.0364e+00, -4.5566e+00, -7.6585e+00, -7.3241e+00, -2.2402e+00,\n",
       "         -1.8462e+00, -5.1420e+00]], grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0294cc8-d350-43a8-9213-321713bb0c87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 67]) torch.Size([1, 67])\n"
     ]
    }
   ],
   "source": [
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "print(start_logits.shape, end_logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16bff6da-9c78-419f-b3d5-fefea3a85c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuestionAnsweringModelOutput(loss=None,\n",
      "                             start_logits=tensor([[-4.4952, -6.4454, -4.7115, -7.0968, -7.0726, -7.4981, -5.5397, -4.1368,\n",
      "         -5.9199, -5.4193, -1.5920, -1.0857, -5.0981, -2.9331, -3.4070,  2.2467,\n",
      "          5.1563, -1.3602, -2.2209, -0.9686, -4.8112, -2.2527,  1.4383, 10.1211,\n",
      "         -1.5311,  2.2685, -1.8951, -2.2108, -4.2142, -2.5571, -2.3252, -2.6046,\n",
      "          1.7047, -1.9867, -1.7211, -0.5415, -2.0239, -4.4246, -5.1012, -4.4966,\n",
      "         -7.8940, -6.7200, -4.6759, -6.3278, -4.8339, -5.1839, -3.3724, -7.4120,\n",
      "         -8.1542, -4.4871, -7.4659, -4.3293, -4.2293, -3.1903, -7.9467, -5.2665,\n",
      "         -7.5902, -5.0570, -7.4476, -7.9083, -6.5951, -7.4061, -8.8821, -7.6749,\n",
      "         -6.9879, -7.0466, -5.4193]], grad_fn=<CloneBackward0>),\n",
      "                             end_logits=tensor([[-2.3958e+00, -7.0978e+00, -7.0745e+00, -6.3676e+00, -5.9532e+00,\n",
      "         -7.9585e+00, -7.1869e+00, -3.6494e+00, -6.9677e+00, -5.1421e+00,\n",
      "         -3.1757e+00, -1.1649e+00, -7.0748e+00, -5.2875e+00, -6.8611e+00,\n",
      "         -5.1769e+00,  3.7892e+00, -4.4408e+00, -7.6688e-01, -3.9180e+00,\n",
      "         -2.1634e+00,  1.8116e+00, -1.4678e+00,  2.0508e+00,  1.5437e-03,\n",
      "         -1.5531e+00, -6.9469e-01, -1.3466e+00, -1.6879e+00,  4.0826e+00,\n",
      "          1.1467e+00, -3.7881e-01,  6.0774e-01,  1.2281e+00,  5.8202e-01,\n",
      "          1.0657e+01,  5.8794e+00, -5.7342e+00, -7.0719e+00, -6.8077e+00,\n",
      "         -7.1513e+00, -5.3228e+00, -3.4305e+00, -4.2575e+00,  2.2268e+00,\n",
      "         -4.1297e-01, -6.8944e+00, -7.9381e+00, -8.3298e+00, -5.6078e+00,\n",
      "         -8.9589e+00, -5.5772e+00, -5.7309e+00, -1.9592e+00, -7.8078e+00,\n",
      "         -2.3823e+00, -7.2457e+00, -6.1642e+00, -4.2830e+00, -8.0948e+00,\n",
      "         -8.0364e+00, -4.5566e+00, -7.6585e+00, -7.3241e+00, -2.2402e+00,\n",
      "         -1.8462e+00, -5.1420e+00]], grad_fn=<CloneBackward0>),\n",
      "                             hidden_states=None,\n",
      "                             attentions=None)\n"
     ]
    }
   ],
   "source": [
    "pprint(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "802f77e4-e0e4-439a-bb97-48888d8745bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([23])\n",
      "torch.Size([1])\n",
      "<class 'torch.Tensor'>\n",
      "tensor(35)\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(start_logits.argmax(dim=-1))\n",
    "print(start_logits.argmax(dim=-1).shape)\n",
    "print(type(start_logits.argmax(dim=-1)))\n",
    "print(end_logits.argmax(dim=-1)[0])\n",
    "print(end_logits.argmax(dim=-1)[0].shape)\n",
    "print(type(end_logits.argmax(dim=-1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf13a535-884c-471c-bf14-a652f0040dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Which', 'deep', 'learning', 'libraries', 'back', '[UNK]', 'Transformers', '?', '[SEP]', '[UNK]', 'Transformers', 'is', 'backed', 'by', 'the', 'three', 'most', 'popular', 'deep', 'learning', 'libraries', 'â€”', 'Jax', ',', 'P', '##y', '##T', '##or', '##ch', ',', 'and', 'Ten', '##sor', '##F', '##low', 'â€”', 'with', 'a', 'sea', '##m', '##less', 'integration', 'between', 'them', '.', 'It', \"'\", 's', 'straightforward', 'to', 'train', 'your', 'models', 'with', 'one', 'before', 'loading', 'them', 'for', 'in', '##ference', 'with', 'the', 'other', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(inputs.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7add8c57-d1cc-4ca5-abb4-96bd0fdc984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Which', 'deep']\n"
     ]
    }
   ],
   "source": [
    "print(inputs.tokens()[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "538736a0-c192-40ab-aa81-7f4a1ab85a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'Which', 'deep']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = (inputs.tokens())[0:3]\n",
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1be42a41-8a4f-43b0-9e8b-1fe806875976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax\n",
      "##low\n",
      "['Jax', ',', 'P', '##y', '##T', '##or', '##ch', ',', 'and', 'Ten', '##sor', '##F', '##low']\n"
     ]
    }
   ],
   "source": [
    "print((inputs.tokens())[23])\n",
    "print((inputs.tokens())[35])\n",
    "selected_elements = (inputs.tokens())[23:36]\n",
    "print(selected_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01098e93-3477-434c-a644-8fbc635429f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "print(inputs.sequence_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03f83abd-ea69-4283-9ac8-fa96a2edffff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  5979,  1996,  3776,  9818,  1171,   100, 25267,   136,   102,\n",
       "           100, 25267,  1110,  5534,  1118,  1103,  1210,  1211,  1927,  1996,\n",
       "          3776,  9818,   783, 13612,   117,   153,  1183,  1942,  1766,  1732,\n",
       "           117,  1105,  5157, 21484,  2271,  6737,   783,  1114,   170,  2343,\n",
       "          1306,  2008,  9111,  1206,  1172,   119,  1135,   112,   188, 21546,\n",
       "          1106,  2669,  1240,  3584,  1114,  1141,  1196, 10745,  1172,  1111,\n",
       "          1107, 16792,  1114,  1103,  1168,   119,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f095df4-3062-44b1-a2c4-47afaff69c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n",
      "[False, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "mask = [i != 1 for i in inputs.sequence_ids()]\n",
    "print(mask)\n",
    "mask[0] = False\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6092de6-ecdd-45d5-96fc-1aab57b8ecb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True])\n",
      "torch.Size([1, 67])\n",
      "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.tensor(mask))\n",
    "print(torch.tensor(mask)[None].shape) \n",
    "print(torch.tensor([mask]))\n",
    "#print(torch.tensor([1, 2, 3], [3, 4, 5])[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0a92e2d-6aa9-4418-903a-07cff2b7c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.tensor([1, 2, 3], [3, 4, 5])[None])\n",
    "# TypeError: tensor() takes 1 positional argument but 2 were given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "23d90484-be43-430c-a709-87127218b874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([[1, 2, 3], [3, 4, 5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea8c42ca-bff4-4382-a14e-349d0ce76e59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4952, -6.4454, -4.7115, -7.0968, -7.0726, -7.4981, -5.5397, -4.1368,\n",
       "         -5.9199, -5.4193, -1.5920, -1.0857, -5.0981, -2.9331, -3.4070,  2.2467,\n",
       "          5.1563, -1.3602, -2.2209, -0.9686, -4.8112, -2.2527,  1.4383, 10.1211,\n",
       "         -1.5311,  2.2685, -1.8951, -2.2108, -4.2142, -2.5571, -2.3252, -2.6046,\n",
       "          1.7047, -1.9867, -1.7211, -0.5415, -2.0239, -4.4246, -5.1012, -4.4966,\n",
       "         -7.8940, -6.7200, -4.6759, -6.3278, -4.8339, -5.1839, -3.3724, -7.4120,\n",
       "         -8.1542, -4.4871, -7.4659, -4.3293, -4.2293, -3.1903, -7.9467, -5.2665,\n",
       "         -7.5902, -5.0570, -7.4476, -7.9083, -6.5951, -7.4061, -8.8821, -7.6749,\n",
       "         -6.9879, -7.0466, -5.4193]], grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "460e6ba0-8695-4eec-b9c0-e67a362bbbb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sequence_ids = inputs.sequence_ids()\n",
    "# ì»¨í…ìŠ¤íŠ¸ í† í°ë“¤ì„ ì œì™¸í•˜ê³ ëŠ” ëª¨ë‘ ë§ˆìŠ¤í‚¹í•œë‹¤.\n",
    "mask = [i != 1 for i in sequence_ids]\n",
    "# [CLS] í† í°ì€ ë§ˆìŠ¤í‚¹í•˜ì§€ ì•ŠëŠ”ë‹¤.\n",
    "mask[0] = False\n",
    "# adds another dimension using [None] to make it a 2D tensor.\n",
    "mask = torch.tensor(mask)[None] # torch.tensor([mask]) \n",
    "\n",
    "start_logits[mask] = -10000\n",
    "end_logits[mask] = -10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45f4c6c7-f957-41cd-b6c2-28651a722b59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4952e+00, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
       "         -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
       "         -1.5920e+00, -1.0857e+00, -5.0981e+00, -2.9331e+00, -3.4070e+00,\n",
       "          2.2467e+00,  5.1563e+00, -1.3602e+00, -2.2209e+00, -9.6861e-01,\n",
       "         -4.8112e+00, -2.2527e+00,  1.4383e+00,  1.0121e+01, -1.5311e+00,\n",
       "          2.2685e+00, -1.8951e+00, -2.2108e+00, -4.2142e+00, -2.5571e+00,\n",
       "         -2.3252e+00, -2.6046e+00,  1.7047e+00, -1.9867e+00, -1.7211e+00,\n",
       "         -5.4148e-01, -2.0239e+00, -4.4246e+00, -5.1012e+00, -4.4966e+00,\n",
       "         -7.8940e+00, -6.7200e+00, -4.6759e+00, -6.3278e+00, -4.8339e+00,\n",
       "         -5.1839e+00, -3.3724e+00, -7.4120e+00, -8.1542e+00, -4.4871e+00,\n",
       "         -7.4659e+00, -4.3293e+00, -4.2293e+00, -3.1903e+00, -7.9467e+00,\n",
       "         -5.2665e+00, -7.5902e+00, -5.0570e+00, -7.4476e+00, -7.9083e+00,\n",
       "         -6.5951e+00, -7.4061e+00, -8.8821e+00, -7.6749e+00, -6.9879e+00,\n",
       "         -7.0466e+00, -1.0000e+04]], grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d477eb9b-92a5-408b-831e-dfc9df28c02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.4531e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1185e-06, 1.3470e-05,\n",
       "        2.4368e-07, 2.1236e-06, 1.3220e-06, 3.7722e-04, 6.9219e-03, 1.0237e-05,\n",
       "        4.3289e-06, 1.5143e-05, 3.2463e-07, 4.1933e-06, 1.6808e-04, 9.9179e-01,\n",
       "        8.6288e-06, 3.8557e-04, 5.9956e-06, 4.3725e-06, 5.8977e-07, 3.0929e-06,\n",
       "        3.8998e-06, 2.9493e-06, 2.1940e-04, 5.4713e-06, 7.1354e-06, 2.3212e-05,\n",
       "        5.2711e-06, 4.7788e-07, 2.4291e-07, 4.4467e-07, 1.4879e-08, 4.8133e-08,\n",
       "        3.7169e-07, 7.1242e-08, 3.1735e-07, 2.2365e-07, 1.3685e-06, 2.4093e-08,\n",
       "        1.1470e-08, 4.4891e-07, 2.2828e-08, 5.2562e-07, 5.8092e-07, 1.6419e-06,\n",
       "        1.4114e-08, 2.0591e-07, 2.0161e-08, 2.5390e-07, 2.3251e-08, 1.4667e-08,\n",
       "        5.4533e-08, 2.4235e-08, 5.5390e-09, 1.8524e-08, 3.6818e-08, 3.4721e-08,\n",
       "        0.0000e+00], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(start_logits[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc7319f1-a57c-4ef0-b450-17c300ca82c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)[0]\n",
    "end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aaffa2fb-e268-4b7e-b99d-3d875054ade1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67])\n",
      "tensor([4.4531e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1185e-06, 1.3470e-05,\n",
      "        2.4368e-07, 2.1236e-06, 1.3220e-06, 3.7722e-04, 6.9219e-03, 1.0237e-05,\n",
      "        4.3289e-06, 1.5143e-05, 3.2463e-07, 4.1933e-06, 1.6808e-04, 9.9179e-01,\n",
      "        8.6288e-06, 3.8557e-04, 5.9956e-06, 4.3725e-06, 5.8977e-07, 3.0929e-06,\n",
      "        3.8998e-06, 2.9493e-06, 2.1940e-04, 5.4713e-06, 7.1354e-06, 2.3212e-05,\n",
      "        5.2711e-06, 4.7788e-07, 2.4291e-07, 4.4467e-07, 1.4879e-08, 4.8133e-08,\n",
      "        3.7169e-07, 7.1242e-08, 3.1735e-07, 2.2365e-07, 1.3685e-06, 2.4093e-08,\n",
      "        1.1470e-08, 4.4891e-07, 2.2828e-08, 5.2562e-07, 5.8092e-07, 1.6419e-06,\n",
      "        1.4114e-08, 2.0591e-07, 2.0161e-08, 2.5390e-07, 2.3251e-08, 1.4667e-08,\n",
      "        5.4533e-08, 2.4235e-08, 5.5390e-09, 1.8524e-08, 3.6818e-08, 3.4721e-08,\n",
      "        0.0000e+00], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(start_probabilities.shape)\n",
    "print(start_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "500b0265-6c9e-48c7-93ba-8de1040883a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "\n",
    "b = a.view(a.shape[0], -1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e580ad4-e69a-4687-bf90-8671af433f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67, 1])\n",
      "torch.Size([1, 67])\n"
     ]
    }
   ],
   "source": [
    "print(start_probabilities[:, None].shape)\n",
    "print(end_probabilities[None, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "128fcab9-c381-4cac-91cd-0f66ede23a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67, 1])\n",
      "torch.Size([1, 67])\n"
     ]
    }
   ],
   "source": [
    "print(start_probabilities.view(start_probabilities.shape[0],-1).shape)\n",
    "print(end_probabilities.view(-1, end_probabilities.shape[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dcf3f150-aaae-4835-99a1-068ff776b9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = start_probabilities[:, None] * end_probabilities[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd5b171e-16b2-41e5-a8fc-ddd0cc471d87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 67])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "77053198-3c8b-426b-b377-da16ef40fa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [0., 1., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3, 3).triu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e3ef6dc-9027-4f08-aa94-e97e1b8f7f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = torch.triu(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9a0a05bd-aad1-4695-b251-b46a86011650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 67])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "54f54af7-ca96-4ce6-9bdc-f0d88c0f746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1576)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1576"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(scores.argmax())\n",
    "scores.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "41c86879-a452-42e6-af3a-54c0f500113f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 67])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "749e3650-e542-4407-b877-1cb204212033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9803, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "max_index = scores.argmax().item()\n",
    "start_index = max_index // scores.shape[1]\n",
    "end_index = max_index % scores.shape[1]\n",
    "print(scores[start_index, end_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1a73cf98-2479-4993-9fae-440e2bd9164e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "print(scores.argmax().item() // 67)\n",
    "print(scores.argmax().item() % 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "673cb160-8b40-475a-9532-cf4d0e9c5178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9803, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[23,35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f10ebc1a-d448-4d7f-83ff-e613ffc992c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs_with_offsets = tokenizer(question, context, return_offsets_mapping=True)\n",
    "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
    "\n",
    "start_char, _ = offsets[start_index]\n",
    "_, end_char = offsets[end_index]\n",
    "answer = context[start_char:end_char]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "44f3d9c1-2300-4b8b-9522-28ae8a3a2bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Jax, PyTorch, and TensorFlow', 'start': 78, 'end': 106, 'score': tensor(0.9803, grad_fn=<SelectBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "result = {\n",
    "    \"answer\": answer,\n",
    "    \"start\": start_char,\n",
    "    \"end\": end_char,\n",
    "    \"score\": scores[start_index, end_index]\n",
    "}\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8cd8a91c-18a2-4968-9ff4-6ace0b41b558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax\n",
      "##low\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'Which',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'libraries',\n",
       " 'back',\n",
       " '[UNK]',\n",
       " 'Transformers',\n",
       " '?',\n",
       " '[SEP]',\n",
       " '[UNK]',\n",
       " 'Transformers',\n",
       " 'is',\n",
       " 'backed',\n",
       " 'by',\n",
       " 'the',\n",
       " 'three',\n",
       " 'most',\n",
       " 'popular',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'libraries',\n",
       " 'â€”',\n",
       " 'Jax',\n",
       " ',',\n",
       " 'P',\n",
       " '##y',\n",
       " '##T',\n",
       " '##or',\n",
       " '##ch',\n",
       " ',',\n",
       " 'and',\n",
       " 'Ten',\n",
       " '##sor',\n",
       " '##F',\n",
       " '##low',\n",
       " 'â€”',\n",
       " 'with',\n",
       " 'a',\n",
       " 'sea',\n",
       " '##m',\n",
       " '##less',\n",
       " 'integration',\n",
       " 'between',\n",
       " 'them',\n",
       " '.',\n",
       " 'It',\n",
       " \"'\",\n",
       " 's',\n",
       " 'straightforward',\n",
       " 'to',\n",
       " 'train',\n",
       " 'your',\n",
       " 'models',\n",
       " 'with',\n",
       " 'one',\n",
       " 'before',\n",
       " 'loading',\n",
       " 'them',\n",
       " 'for',\n",
       " 'in',\n",
       " '##ference',\n",
       " 'with',\n",
       " 'the',\n",
       " 'other',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs_with_offsets.tokens()[start_index]) #23\n",
    "print(inputs_with_offsets.tokens()[end_index]) #35\n",
    "inputs_with_offsets.tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84888759-9482-440e-af3a-512b2a25a633",
   "metadata": {},
   "source": [
    "#### Try it out with top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "219578c5-0319-4b8f-be25-8f9bcc57914a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9802603125572205,\n",
       "  'start': 78,\n",
       "  'end': 106,\n",
       "  'answer': 'Jax, PyTorch, and TensorFlow'},\n",
       " {'score': 0.008247792720794678,\n",
       "  'start': 78,\n",
       "  'end': 108,\n",
       "  'answer': 'Jax, PyTorch, and TensorFlow â€”'},\n",
       " {'score': 0.0013677021488547325,\n",
       "  'start': 78,\n",
       "  'end': 90,\n",
       "  'answer': 'Jax, PyTorch'},\n",
       " {'score': 0.00038108628359623253,\n",
       "  'start': 83,\n",
       "  'end': 106,\n",
       "  'answer': 'PyTorch, and TensorFlow'},\n",
       " {'score': 0.000216845452087, 'start': 96, 'end': 106, 'answer': 'TensorFlow'}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "context = \"\"\"\n",
    "ğŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch, and TensorFlow â€” with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\"\n",
    "question = \"Which deep learning libraries back ğŸ¤— Transformers?\"\n",
    "question_answerer(question=question, context=context, top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ae25281-c103-41b4-9b48-66672b99c4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([9.8026e-01, 8.2478e-03, 6.8414e-03, 1.3677e-03, 3.8109e-04],\n",
       "       grad_fn=<TopkBackward0>),\n",
       "indices=tensor([1576, 1577, 1107, 1570, 1710]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(scores.flatten(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "58762095-40d1-4acf-8c34-d66225eab621",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer': 'Jax, PyTorch, and TensorFlow',\n",
      "  'end': 106,\n",
      "  'score': 0.9802601933479309,\n",
      "  'start': 78},\n",
      " {'answer': 'Jax, PyTorch, and TensorFlow â€”',\n",
      "  'end': 108,\n",
      "  'score': 0.008247792720794678,\n",
      "  'start': 78},\n",
      " {'answer': 'three most popular deep learning libraries â€” Jax, PyTorch, and '\n",
      "            'TensorFlow',\n",
      "  'end': 106,\n",
      "  'score': 0.006841439288109541,\n",
      "  'start': 33},\n",
      " {'answer': 'Jax, PyTorch',\n",
      "  'end': 90,\n",
      "  'score': 0.0013677021488547325,\n",
      "  'start': 78},\n",
      " {'answer': 'PyTorch, and TensorFlow',\n",
      "  'end': 106,\n",
      "  'score': 0.0003810862544924021,\n",
      "  'start': 83}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "value_5, index_5 = torch.topk(scores.flatten(), 5)\n",
    "top5_indexes = [((i//scores.shape[1]).item(), (i%scores.shape[1]).item()) for i in index_5]\n",
    "\n",
    "results = []\n",
    "for s_i, e_i in top5_indexes:\n",
    "     start_char, _ = offsets[s_i]\n",
    "     _, end_char = offsets[e_i]\n",
    "     result = {\n",
    "         \"answer\": context[start_char:end_char],\n",
    "         \"start\": start_char,\n",
    "         \"end\": end_char,\n",
    "         \"score\": scores[s_i, e_i].item()\n",
    "     }\n",
    "     results.append(result)\n",
    "pprint(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787af9a3-07d0-48ea-8369-3eef84f025b0",
   "metadata": {},
   "source": [
    "#### ê¸¸ì´ê°€ ê¸´ ì»¨í…ìŠ¤íŠ¸ ë‹¤ë£¨ê¸°\n",
    "ìœ„ì—ì„œ ì˜ˆì œë¡œ ì‚¬ìš©í•œ ì§ˆë¬¸ ë° ê¸¸ì´ê°€ ê¸´ ì»¨í…ìŠ¤íŠ¸ë¥¼ í† í°í™” í•´ë³´ë©´ question-answering íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©ëœ ìµœëŒ€ ê¸¸ì´(384)ë³´ë‹¤ ë” ë§ì€ í† í°ë“¤ì´ ì¶œë ¥ë©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be993665-f132-4fe9-b70e-fdccb8e2ad57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(question, long_context)\n",
    "print(len(inputs[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bc2a3305-7c50-4054-9177-5cd9ae5ae4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert-base-cased-distilled-squad', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "944e8e5e-2738-4e48-9ada-cc6e15ab2f63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Which deep learning libraries back [UNK] Transformers? [SEP] [UNK] Transformers : State of the Art NLP [UNK] Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation and more in over 100 languages. Its aim is to make cutting - edge NLP easier to use for everyone. [UNK] Transformers provides APIs to quickly download and use those pretrained models on a given text, fine - tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments. Why should I use transformers? 1. Easy - to - use state - of - the - art models : - High performance on NLU and NLG tasks. - Low barrier to entry for educators and practitioners. - Few user - facing abstractions with just three classes to learn. - A unified API for using all our pretrained models. - Lower compute costs, smaller carbon footprint : 2. Researchers can share trained models instead of always retraining. - Practitioners can reduce compute time and production costs. - Dozens of architectures with over 10, 000 pretrained models, some in more than 100 languages. 3. Choose the right framework for every part of a model's lifetime : - Train state - of - the - art models in 3 lines of code. - Move a single model between TF2. 0 / PyTorch frameworks at will. - Seamlessly pick the right framework for training, evaluation and production. 4. Easily customize a model or an example to your needs : - We provide examples for each architecture to reproduce the results published by its original authors. - Model internal [SEP]\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(question, long_context, max_length=384, truncation=\"only_second\")\n",
    "print(tokenizer.decode(inputs[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8bdca9f8-3362-466c-9b43-6a366ab63dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "print(len(inputs[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "058062bf-98ce-448e-b693-f095f6c6a547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1],\n",
      "                    [1, 1, 1, 1, 1, 1, 1, 1],\n",
      "                    [1, 1, 1, 1, 1, 1, 1, 1],\n",
      "                    [1, 1, 1, 1, 1]],\n",
      " 'input_ids': [[101, 1188, 5650, 1110, 1136, 1315, 1263, 102],\n",
      "               [101, 1315, 1263, 1133, 1195, 1132, 1280, 102],\n",
      "               [101, 1132, 1280, 1106, 3325, 1122, 4050, 102],\n",
      "               [101, 1122, 4050, 119, 102]],\n",
      " 'overflow_to_sample_mapping': [0, 0, 0, 0]}\n",
      "[CLS] This sentence is not too long [SEP]\n",
      "[CLS] too long but we are going [SEP]\n",
      "[CLS] are going to split it anyway [SEP]\n",
      "[CLS] it anyway. [SEP]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This sentence is not too long but we are going to split it anyway.\"\n",
    "inputs = tokenizer(\n",
    "    sentence, truncation=True, return_overflowing_tokens=True, max_length=8, stride=2\n",
    ")\n",
    "pprint(inputs)\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "    print(tokenizer.decode(ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7bc9959c-cd00-414c-a898-84bb1f077cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'overflow_to_sample_mapping'])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f221edf6-5ce5-4d27-bb94-eb1971948977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"overflow_to_sample_mapping\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "577937c0-f192-411c-b3d9-1d5f30742714",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "{'input_ids': [[101, 1188, 5650, 1110, 1136, 102], [101, 1110, 1136, 1315, 1263, 102], [101, 1315, 1263, 1133, 1195, 102], [101, 1133, 1195, 1132, 1280, 102], [101, 1132, 1280, 1106, 3325, 102], [101, 1106, 3325, 1122, 4050, 102], [101, 1122, 4050, 119, 102], [101, 1188, 5650, 1110, 7681, 102], [101, 1110, 7681, 1133, 1209, 102], [101, 1133, 1209, 1253, 1243, 102], [101, 1253, 1243, 3325, 119, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]], 'overflow_to_sample_mapping': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"This sentence is not too long but we are going to split it anyway.\",\n",
    "    \"This sentence is shorter but will still get split.\",\n",
    "]\n",
    "inputs = tokenizer(\n",
    "    sentences, truncation=True, return_overflowing_tokens=True, max_length=6, stride=2\n",
    ")\n",
    "\n",
    "print(inputs[\"overflow_to_sample_mapping\"])\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bd63bdb6-d3a6-45ef-92a1-a5204e7e14ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 0, 0, 0, None]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.sequence_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "84c9c04f-a936-4a09-9ae7-5650c1906c35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Which deep learning libraries back [UNK] Transformers? [SEP] [UNK] Transformers : State of the Art NLP [UNK] Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation and more in over 100 languages. Its aim is to make cutting - edge NLP easier to use for everyone. [UNK] Transformers provides APIs to quickly download and use those pretrained models on a given text, fine - tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments. Why should I use transformers? 1. Easy - to - use state - of - the - art models : - High performance on NLU and NLG tasks. - Low barrier to entry for educators and practitioners. - Few user - facing abstractions with just three classes to [SEP]\n",
      "\n",
      "\n",
      "[CLS] Which deep learning libraries back [UNK] Transformers? [SEP] quick research experiments. Why should I use transformers? 1. Easy - to - use state - of - the - art models : - High performance on NLU and NLG tasks. - Low barrier to entry for educators and practitioners. - Few user - facing abstractions with just three classes to learn. - A unified API for using all our pretrained models. - Lower compute costs, smaller carbon footprint : 2. Researchers can share trained models instead of always retraining. - Practitioners can reduce compute time and production costs. - Dozens of architectures with over 10, 000 pretrained models, some in more than 100 languages. 3. Choose the right framework for every part of a model's lifetime : - Train state - of - the - art models in 3 lines of code. - Move a single model between TF2. 0 / PyTorch [SEP]\n",
      "\n",
      "\n",
      "[CLS] Which deep learning libraries back [UNK] Transformers? [SEP]ined models, some in more than 100 languages. 3. Choose the right framework for every part of a model's lifetime : - Train state - of - the - art models in 3 lines of code. - Move a single model between TF2. 0 / PyTorch frameworks at will. - Seamlessly pick the right framework for training, evaluation and production. 4. Easily customize a model or an example to your needs : - We provide examples for each architecture to reproduce the results published by its original authors. - Model internals are exposed as consistently as possible. - Model files can be used independently of the library for quick experiments. [UNK] Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with [SEP]\n",
      "\n",
      "\n",
      "[CLS] Which deep learning libraries back [UNK] Transformers? [SEP] independently of the library for quick experiments. [UNK] Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    long_context,\n",
    "    stride=60,\n",
    "    max_length=200,\n",
    "    padding=\"longest\",\n",
    "    #truncation=True,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "    print(tokenizer.decode(ids))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "efa23798-6173-460f-8212-37b79e814dec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0]\n",
      "[CLS] Which deep learning libraries back [UNK] Transformers? [SEP] [UNK] Transformers : State of the Art NLP [UNK] Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation and more in over 100 languages. Its aim is to make cutting - edge NLP easier to use for everyone. [UNK] Transformers provides APIs to quickly download and use those pretrained models on a given text, fine - tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments. Why should I use transformers? 1. Easy - to - use state - of - the - art models : - High performance on NLU and NLG tasks. - Low barrier to entry for educators and practitioners. - Few user - facing abstractions with just three classes to [SEP]\n",
      "\n",
      "\n",
      "[CLS] Which deep learning libraries back [UNK] Transformers? [SEP] quick research experiments. Why should I use transformers? 1. Easy - to - use state - of - the - art models : - High performance on NLU and NLG tasks. - Low barrier to entry for educators and practitioners. - Few user - facing abstractions with just three classes to learn. - A unified API for using all our pretrained models. - Lower compute costs, smaller carbon footprint : 2. Researchers can share trained models instead of always retraining. - Practitioners can reduce compute time and production costs. - Dozens of architectures with over 10, 000 pretrained models, some in more than 100 languages. 3. Choose the right framework for every part of a model's lifetime : - Train state - of - the - art models in 3 lines of code. - Move a single model between TF2. 0 / PyTorch [SEP]\n",
      "\n",
      "\n",
      "[CLS] Which deep learning libraries back [UNK] Transformers? [SEP]ined models, some in more than 100 languages. 3. Choose the right framework for every part of a model's lifetime : - Train state - of - the - art models in 3 lines of code. - Move a single model between TF2. 0 / PyTorch frameworks at will. - Seamlessly pick the right framework for training, evaluation and production. 4. Easily customize a model or an example to your needs : - We provide examples for each architecture to reproduce the results published by its original authors. - Model internals are exposed as consistently as possible. - Model files can be used independently of the library for quick experiments. [UNK] Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with [SEP]\n",
      "\n",
      "\n",
      "[CLS] Which deep learning libraries back [UNK] Transformers? [SEP] independently of the library for quick experiments. [UNK] Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    long_context,\n",
    "    stride=60,\n",
    "    max_length=200,\n",
    "    padding=\"longest\",\n",
    "    truncation=True,\n",
    "    #truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "\n",
    "print(inputs[\"overflow_to_sample_mapping\"])\n",
    "\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "    print(tokenizer.decode(ids))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "22cca719-52c9-4db1-865b-911ffcd1696e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e81971f7-44ff-4c60-aa2e-3d157ec98774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs.sequence_ids())\n",
    "len(inputs.sequence_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "71d3b145-ba0a-4554-9f27-2357e503312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 5979, 1996, 3776, 9818, 1171, 100, 25267, 136, 102, 100, 25267, 131, 1426, 1104, 1103, 2051, 21239, 2101, 100, 25267, 2790, 4674, 1104, 3073, 4487, 9044, 3584, 1106, 3870, 8249, 1113, 6685, 1216, 1112, 5393, 117, 1869, 16026, 117, 2304, 10937, 117, 7584, 7317, 2734, 117, 5179, 117, 3087, 3964, 1105, 1167, 1107, 1166, 1620, 3483, 119, 2098, 6457, 1110, 1106, 1294, 5910, 118, 2652, 21239, 2101, 5477, 1106, 1329, 1111, 2490, 119, 100, 25267, 2790, 20480, 1116, 1106, 1976, 9133, 1105, 1329, 1343, 3073, 4487, 9044, 3584, 1113, 170, 1549, 3087, 117, 2503, 118, 9253, 1172, 1113, 1240, 1319, 2233, 27948, 1105, 1173, 2934, 1172, 1114, 1103, 1661, 1113, 1412, 2235, 10960, 119, 1335, 1103, 1269, 1159, 117, 1296, 185, 25669, 8613, 13196, 13682, 1126, 4220, 1110, 3106, 2484, 20717, 1673, 1105, 1169, 1129, 5847, 1106, 9396, 3613, 1844, 7857, 119, 2009, 1431, 146, 1329, 11303, 1468, 136, 122, 119, 12167, 118, 1106, 118, 1329, 1352, 118, 1104, 118, 1103, 118, 1893, 3584, 131, 118, 1693, 2099, 1113, 21239, 2591, 1105, 21239, 2349, 8249, 119, 118, 8274, 9391, 1106, 3990, 1111, 24937, 1105, 16681, 119, 118, 17751, 4795, 118, 4749, 11108, 5266, 1114, 1198, 1210, 3553, 1106, 3858, 119, 118, 138, 13943, 20480, 1111, 1606, 1155, 1412, 3073, 4487, 9044, 3584, 119, 118, 5738, 3254, 22662, 4692, 117, 2964, 6302, 2555, 10988, 131, 123, 119, 26982, 1169, 2934, 3972, 3584, 1939, 1104, 1579, 1231, 4487, 16534, 119, 118, 153, 19366, 3121, 2116, 1468, 1169, 4851, 3254, 22662, 1159, 1105, 1707, 4692, 119, 118, 2091, 10947, 1116, 1104, 4220, 1116, 1114, 1166, 1275, 117, 1288, 3073, 4487, 9044, 3584, 117, 1199, 1107, 1167, 1190, 1620, 3483, 119, 124, 119, 22964, 6787, 1103, 1268, 8297, 1111, 1451, 1226, 1104, 170, 2235, 112, 188, 7218, 131, 118, 9791, 1352, 118, 1104, 118, 1103, 118, 1893, 3584, 1107, 124, 2442, 1104, 3463, 119, 118, 15729, 170, 1423, 2235, 1206, 157, 2271, 1477, 119, 121, 120, 153, 1183, 1942, 1766, 1732, 8297, 1116, 1120, 1209, 119, 118, 3017, 1306, 8709, 3368, 1103, 1268, 8297, 1111, 2013, 117, 10540, 1105, 1707, 119, 125, 119, 142, 20158, 8156, 3708, 170, 2235, 1137, 1126, 1859, 1106, 1240, 2993, 131, 118, 1284, 2194, 5136, 1111, 1296, 4220, 1106, 23577, 1103, 2686, 1502, 1118, 1157, 1560, 5752, 119, 118, 6747, 4422, 102], [101, 5979, 1996, 3776, 9818, 1171, 100, 25267, 136, 102, 2091, 10947, 1116, 1104, 4220, 1116, 1114, 1166, 1275, 117, 1288, 3073, 4487, 9044, 3584, 117, 1199, 1107, 1167, 1190, 1620, 3483, 119, 124, 119, 22964, 6787, 1103, 1268, 8297, 1111, 1451, 1226, 1104, 170, 2235, 112, 188, 7218, 131, 118, 9791, 1352, 118, 1104, 118, 1103, 118, 1893, 3584, 1107, 124, 2442, 1104, 3463, 119, 118, 15729, 170, 1423, 2235, 1206, 157, 2271, 1477, 119, 121, 120, 153, 1183, 1942, 1766, 1732, 8297, 1116, 1120, 1209, 119, 118, 3017, 1306, 8709, 3368, 1103, 1268, 8297, 1111, 2013, 117, 10540, 1105, 1707, 119, 125, 119, 142, 20158, 8156, 3708, 170, 2235, 1137, 1126, 1859, 1106, 1240, 2993, 131, 118, 1284, 2194, 5136, 1111, 1296, 4220, 1106, 23577, 1103, 2686, 1502, 1118, 1157, 1560, 5752, 119, 118, 6747, 4422, 1116, 1132, 5490, 1112, 10887, 1112, 1936, 119, 118, 6747, 7004, 1169, 1129, 1215, 8942, 1104, 1103, 3340, 1111, 3613, 7857, 119, 100, 25267, 1110, 5534, 1118, 1103, 1210, 1211, 1927, 1996, 3776, 9818, 783, 13612, 117, 153, 1183, 1942, 1766, 1732, 1105, 5157, 21484, 2271, 6737, 783, 1114, 170, 2343, 1306, 2008, 9111, 1206, 1172, 119, 1135, 112, 188, 21546, 1106, 2669, 1240, 3584, 1114, 1141, 1196, 10745, 1172, 1111, 1107, 16792, 1114, 1103, 1168, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'offset_mapping': [[(0, 0), (0, 5), (6, 10), (11, 19), (20, 29), (30, 34), (35, 36), (37, 49), (49, 50), (0, 0), (1, 2), (3, 15), (15, 16), (17, 22), (23, 25), (26, 29), (30, 33), (34, 36), (36, 37), (39, 40), (41, 53), (54, 62), (63, 72), (73, 75), (76, 79), (79, 82), (82, 86), (87, 93), (94, 96), (97, 104), (105, 110), (111, 113), (114, 119), (120, 124), (125, 127), (128, 142), (142, 143), (144, 155), (156, 166), (166, 167), (168, 176), (177, 186), (186, 187), (188, 191), (191, 194), (194, 201), (201, 202), (203, 214), (214, 215), (216, 220), (221, 231), (232, 235), (236, 240), (241, 243), (244, 248), (249, 252), (253, 262), (262, 263), (264, 267), (268, 271), (272, 274), (275, 277), (278, 282), (283, 290), (290, 291), (291, 295), (296, 298), (298, 299), (300, 306), (307, 309), (310, 313), (314, 317), (318, 326), (326, 327), (329, 330), (331, 343), (344, 352), (353, 356), (356, 357), (358, 360), (361, 368), (369, 377), (378, 381), (382, 385), (386, 391), (392, 395), (395, 398), (398, 402), (403, 409), (410, 412), (413, 414), (415, 420), (421, 425), (425, 426), (427, 431), (431, 432), (432, 436), (437, 441), (442, 444), (445, 449), (450, 453), (454, 458), (458, 462), (463, 466), (467, 471), (472, 477), (478, 482), (483, 487), (488, 491), (492, 501), (502, 504), (505, 508), (509, 514), (515, 518), (518, 519), (520, 522), (523, 526), (527, 531), (532, 536), (536, 537), (538, 542), (543, 544), (544, 546), (546, 549), (550, 556), (557, 565), (566, 568), (569, 581), (582, 584), (585, 590), (591, 596), (596, 599), (599, 601), (602, 605), (606, 609), (610, 612), (613, 621), (622, 624), (625, 631), (632, 637), (638, 646), (647, 658), (658, 659), (661, 664), (665, 671), (672, 673), (674, 677), (678, 687), (687, 690), (690, 691), (693, 694), (694, 695), (696, 700), (700, 701), (701, 703), (703, 704), (704, 707), (708, 713), (713, 714), (714, 716), (716, 717), (717, 720), (720, 721), (721, 724), (725, 731), (731, 732), (735, 736), (737, 741), (742, 753), (754, 756), (757, 759), (759, 760), (761, 764), (765, 767), (767, 768), (769, 774), (774, 775), (778, 779), (780, 783), (784, 791), (792, 794), (795, 800), (801, 804), (805, 814), (815, 818), (819, 832), (832, 833), (836, 837), (838, 841), (842, 846), (846, 847), (847, 853), (854, 862), (862, 866), (867, 871), (872, 876), (877, 882), (883, 890), (891, 893), (894, 899), (899, 900), (903, 904), (905, 906), (907, 914), (915, 918), (919, 922), (923, 928), (929, 932), (933, 936), (937, 940), (940, 943), (943, 947), (948, 954), (954, 955), (958, 959), (960, 965), (966, 969), (969, 973), (974, 979), (979, 980), (981, 988), (989, 995), (996, 1000), (1000, 1005), (1005, 1006), (1008, 1009), (1009, 1010), (1011, 1022), (1023, 1026), (1027, 1032), (1033, 1040), (1041, 1047), (1048, 1055), (1056, 1058), (1059, 1065), (1066, 1068), (1068, 1071), (1071, 1076), (1076, 1077), (1080, 1081), (1082, 1083), (1083, 1086), (1086, 1088), (1088, 1092), (1092, 1095), (1096, 1099), (1100, 1106), (1107, 1110), (1110, 1114), (1115, 1119), (1120, 1123), (1124, 1134), (1135, 1140), (1140, 1141), (1144, 1145), (1146, 1148), (1148, 1151), (1151, 1152), (1153, 1155), (1156, 1168), (1168, 1169), (1170, 1174), (1175, 1179), (1180, 1182), (1182, 1183), (1183, 1186), (1187, 1190), (1190, 1193), (1193, 1197), (1198, 1204), (1204, 1205), (1206, 1210), (1211, 1213), (1214, 1218), (1219, 1223), (1224, 1227), (1228, 1237), (1237, 1238), (1240, 1241), (1241, 1242), (1243, 1246), (1246, 1249), (1250, 1253), (1254, 1259), (1260, 1269), (1270, 1273), (1274, 1279), (1280, 1284), (1285, 1287), (1288, 1289), (1290, 1295), (1295, 1296), (1296, 1297), (1298, 1306), (1306, 1307), (1310, 1311), (1312, 1317), (1318, 1323), (1323, 1324), (1324, 1326), (1326, 1327), (1327, 1330), (1330, 1331), (1331, 1334), (1335, 1341), (1342, 1344), (1345, 1346), (1347, 1352), (1353, 1355), (1356, 1360), (1360, 1361), (1364, 1365), (1366, 1370), (1371, 1372), (1373, 1379), (1380, 1385), (1386, 1393), (1394, 1395), (1395, 1396), (1396, 1397), (1397, 1398), (1398, 1399), (1399, 1400), (1400, 1401), (1401, 1402), (1402, 1403), (1403, 1405), (1405, 1407), (1408, 1417), (1417, 1418), (1419, 1421), (1422, 1426), (1426, 1427), (1430, 1431), (1432, 1435), (1435, 1436), (1436, 1442), (1443, 1447), (1448, 1451), (1452, 1457), (1458, 1467), (1468, 1471), (1472, 1480), (1480, 1481), (1482, 1492), (1493, 1496), (1497, 1507), (1507, 1508), (1510, 1511), (1511, 1512), (1513, 1514), (1514, 1519), (1520, 1526), (1526, 1529), (1530, 1531), (1532, 1537), (1538, 1540), (1541, 1543), (1544, 1551), (1552, 1554), (1555, 1559), (1560, 1565), (1565, 1566), (1569, 1570), (1571, 1573), (1574, 1581), (1582, 1590), (1591, 1594), (1595, 1599), (1600, 1612), (1613, 1615), (1616, 1625), (1626, 1629), (1630, 1637), (1638, 1647), (1648, 1650), (1651, 1654), (1655, 1663), (1664, 1671), (1671, 1672), (1675, 1676), (1677, 1682), (1683, 1691), (0, 0)], [(0, 0), (0, 5), (6, 10), (11, 19), (20, 29), (30, 34), (35, 36), (37, 49), (49, 50), (0, 0), (1146, 1148), (1148, 1151), (1151, 1152), (1153, 1155), (1156, 1168), (1168, 1169), (1170, 1174), (1175, 1179), (1180, 1182), (1182, 1183), (1183, 1186), (1187, 1190), (1190, 1193), (1193, 1197), (1198, 1204), (1204, 1205), (1206, 1210), (1211, 1213), (1214, 1218), (1219, 1223), (1224, 1227), (1228, 1237), (1237, 1238), (1240, 1241), (1241, 1242), (1243, 1246), (1246, 1249), (1250, 1253), (1254, 1259), (1260, 1269), (1270, 1273), (1274, 1279), (1280, 1284), (1285, 1287), (1288, 1289), (1290, 1295), (1295, 1296), (1296, 1297), (1298, 1306), (1306, 1307), (1310, 1311), (1312, 1317), (1318, 1323), (1323, 1324), (1324, 1326), (1326, 1327), (1327, 1330), (1330, 1331), (1331, 1334), (1335, 1341), (1342, 1344), (1345, 1346), (1347, 1352), (1353, 1355), (1356, 1360), (1360, 1361), (1364, 1365), (1366, 1370), (1371, 1372), (1373, 1379), (1380, 1385), (1386, 1393), (1394, 1395), (1395, 1396), (1396, 1397), (1397, 1398), (1398, 1399), (1399, 1400), (1400, 1401), (1401, 1402), (1402, 1403), (1403, 1405), (1405, 1407), (1408, 1417), (1417, 1418), (1419, 1421), (1422, 1426), (1426, 1427), (1430, 1431), (1432, 1435), (1435, 1436), (1436, 1442), (1443, 1447), (1448, 1451), (1452, 1457), (1458, 1467), (1468, 1471), (1472, 1480), (1480, 1481), (1482, 1492), (1493, 1496), (1497, 1507), (1507, 1508), (1510, 1511), (1511, 1512), (1513, 1514), (1514, 1519), (1520, 1526), (1526, 1529), (1530, 1531), (1532, 1537), (1538, 1540), (1541, 1543), (1544, 1551), (1552, 1554), (1555, 1559), (1560, 1565), (1565, 1566), (1569, 1570), (1571, 1573), (1574, 1581), (1582, 1590), (1591, 1594), (1595, 1599), (1600, 1612), (1613, 1615), (1616, 1625), (1626, 1629), (1630, 1637), (1638, 1647), (1648, 1650), (1651, 1654), (1655, 1663), (1664, 1671), (1671, 1672), (1675, 1676), (1677, 1682), (1683, 1691), (1691, 1692), (1693, 1696), (1697, 1704), (1705, 1707), (1708, 1720), (1721, 1723), (1724, 1732), (1732, 1733), (1736, 1737), (1738, 1743), (1744, 1749), (1750, 1753), (1754, 1756), (1757, 1761), (1762, 1775), (1776, 1778), (1779, 1782), (1783, 1790), (1791, 1794), (1795, 1800), (1801, 1812), (1812, 1813), (1815, 1816), (1817, 1829), (1830, 1832), (1833, 1839), (1840, 1842), (1843, 1846), (1847, 1852), (1853, 1857), (1858, 1865), (1866, 1870), (1871, 1879), (1880, 1889), (1890, 1891), (1892, 1895), (1895, 1896), (1897, 1898), (1898, 1899), (1899, 1900), (1900, 1902), (1902, 1904), (1905, 1908), (1909, 1912), (1912, 1915), (1915, 1916), (1916, 1919), (1920, 1921), (1922, 1926), (1927, 1928), (1929, 1932), (1932, 1933), (1933, 1937), (1938, 1949), (1950, 1957), (1958, 1962), (1962, 1963), (1964, 1966), (1966, 1967), (1967, 1968), (1969, 1984), (1985, 1987), (1988, 1993), (1994, 1998), (1999, 2005), (2006, 2010), (2011, 2014), (2015, 2021), (2022, 2029), (2030, 2034), (2035, 2038), (2039, 2041), (2041, 2048), (2049, 2053), (2054, 2057), (2058, 2063), (2063, 2064), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]], 'overflow_to_sample_mapping': [0, 0]}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    long_context,\n",
    "    stride=128,\n",
    "    max_length=384,\n",
    "    padding=\"longest\",\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6db2c02a-40bd-4be4-ae3b-dad403a2905e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 384])\n"
     ]
    }
   ],
   "source": [
    "_ = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "offsets = inputs.pop(\"offset_mapping\")\n",
    "\n",
    "inputs = inputs.convert_to_tensors(\"pt\")\n",
    "print(inputs[\"input_ids\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b897f33a-ab80-4d4b-924d-45b44d632291",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 384]) torch.Size([2, 384])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "print(start_logits.shape, end_logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5dd5cb41-b27d-4a09-8f80-d19908c9340f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  5979,  1996,  3776,  9818,  1171,   100, 25267,   136,   102,\n",
       "           100, 25267,   131,  1426,  1104,  1103,  2051, 21239,  2101,   100,\n",
       "         25267,  2790,  4674,  1104,  3073,  4487,  9044,  3584,  1106,  3870,\n",
       "          8249,  1113,  6685,  1216,  1112,  5393,   117,  1869, 16026,   117,\n",
       "          2304, 10937,   117,  7584,  7317,  2734,   117,  5179,   117,  3087,\n",
       "          3964,  1105,  1167,  1107,  1166,  1620,  3483,   119,  2098,  6457,\n",
       "          1110,  1106,  1294,  5910,   118,  2652, 21239,  2101,  5477,  1106,\n",
       "          1329,  1111,  2490,   119,   100, 25267,  2790, 20480,  1116,  1106,\n",
       "          1976,  9133,  1105,  1329,  1343,  3073,  4487,  9044,  3584,  1113,\n",
       "           170,  1549,  3087,   117,  2503,   118,  9253,  1172,  1113,  1240,\n",
       "          1319,  2233, 27948,  1105,  1173,  2934,  1172,  1114,  1103,  1661,\n",
       "          1113,  1412,  2235, 10960,   119,  1335,  1103,  1269,  1159,   117,\n",
       "          1296,   185, 25669,  8613, 13196, 13682,  1126,  4220,  1110,  3106,\n",
       "          2484, 20717,  1673,  1105,  1169,  1129,  5847,  1106,  9396,  3613,\n",
       "          1844,  7857,   119,  2009,  1431,   146,  1329, 11303,  1468,   136,\n",
       "           122,   119, 12167,   118,  1106,   118,  1329,  1352,   118,  1104,\n",
       "           118,  1103,   118,  1893,  3584,   131,   118,  1693,  2099,  1113,\n",
       "         21239,  2591,  1105, 21239,  2349,  8249,   119,   118,  8274,  9391,\n",
       "          1106,  3990,  1111, 24937,  1105, 16681,   119,   118, 17751,  4795,\n",
       "           118,  4749, 11108,  5266,  1114,  1198,  1210,  3553,  1106,  3858,\n",
       "           119,   118,   138, 13943, 20480,  1111,  1606,  1155,  1412,  3073,\n",
       "          4487,  9044,  3584,   119,   118,  5738,  3254, 22662,  4692,   117,\n",
       "          2964,  6302,  2555, 10988,   131,   123,   119, 26982,  1169,  2934,\n",
       "          3972,  3584,  1939,  1104,  1579,  1231,  4487, 16534,   119,   118,\n",
       "           153, 19366,  3121,  2116,  1468,  1169,  4851,  3254, 22662,  1159,\n",
       "          1105,  1707,  4692,   119,   118,  2091, 10947,  1116,  1104,  4220,\n",
       "          1116,  1114,  1166,  1275,   117,  1288,  3073,  4487,  9044,  3584,\n",
       "           117,  1199,  1107,  1167,  1190,  1620,  3483,   119,   124,   119,\n",
       "         22964,  6787,  1103,  1268,  8297,  1111,  1451,  1226,  1104,   170,\n",
       "          2235,   112,   188,  7218,   131,   118,  9791,  1352,   118,  1104,\n",
       "           118,  1103,   118,  1893,  3584,  1107,   124,  2442,  1104,  3463,\n",
       "           119,   118, 15729,   170,  1423,  2235,  1206,   157,  2271,  1477,\n",
       "           119,   121,   120,   153,  1183,  1942,  1766,  1732,  8297,  1116,\n",
       "          1120,  1209,   119,   118,  3017,  1306,  8709,  3368,  1103,  1268,\n",
       "          8297,  1111,  2013,   117, 10540,  1105,  1707,   119,   125,   119,\n",
       "           142, 20158,  8156,  3708,   170,  2235,  1137,  1126,  1859,  1106,\n",
       "          1240,  2993,   131,   118,  1284,  2194,  5136,  1111,  1296,  4220,\n",
       "          1106, 23577,  1103,  2686,  1502,  1118,  1157,  1560,  5752,   119,\n",
       "           118,  6747,  4422,   102],\n",
       "        [  101,  5979,  1996,  3776,  9818,  1171,   100, 25267,   136,   102,\n",
       "          2091, 10947,  1116,  1104,  4220,  1116,  1114,  1166,  1275,   117,\n",
       "          1288,  3073,  4487,  9044,  3584,   117,  1199,  1107,  1167,  1190,\n",
       "          1620,  3483,   119,   124,   119, 22964,  6787,  1103,  1268,  8297,\n",
       "          1111,  1451,  1226,  1104,   170,  2235,   112,   188,  7218,   131,\n",
       "           118,  9791,  1352,   118,  1104,   118,  1103,   118,  1893,  3584,\n",
       "          1107,   124,  2442,  1104,  3463,   119,   118, 15729,   170,  1423,\n",
       "          2235,  1206,   157,  2271,  1477,   119,   121,   120,   153,  1183,\n",
       "          1942,  1766,  1732,  8297,  1116,  1120,  1209,   119,   118,  3017,\n",
       "          1306,  8709,  3368,  1103,  1268,  8297,  1111,  2013,   117, 10540,\n",
       "          1105,  1707,   119,   125,   119,   142, 20158,  8156,  3708,   170,\n",
       "          2235,  1137,  1126,  1859,  1106,  1240,  2993,   131,   118,  1284,\n",
       "          2194,  5136,  1111,  1296,  4220,  1106, 23577,  1103,  2686,  1502,\n",
       "          1118,  1157,  1560,  5752,   119,   118,  6747,  4422,  1116,  1132,\n",
       "          5490,  1112, 10887,  1112,  1936,   119,   118,  6747,  7004,  1169,\n",
       "          1129,  1215,  8942,  1104,  1103,  3340,  1111,  3613,  7857,   119,\n",
       "           100, 25267,  1110,  5534,  1118,  1103,  1210,  1211,  1927,  1996,\n",
       "          3776,  9818,   783, 13612,   117,   153,  1183,  1942,  1766,  1732,\n",
       "          1105,  5157, 21484,  2271,  6737,   783,  1114,   170,  2343,  1306,\n",
       "          2008,  9111,  1206,  1172,   119,  1135,   112,   188, 21546,  1106,\n",
       "          2669,  1240,  3584,  1114,  1141,  1196, 10745,  1172,  1111,  1107,\n",
       "         16792,  1114,  1103,  1168,   119,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a41b6744-c38b-48b1-9dd1-6c5eccc6fc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 384])\n",
      "384\n",
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"].shape)\n",
    "print(len(inputs.sequence_ids()))\n",
    "print(inputs.sequence_ids()) # the sequence_ids is applied to every chuck, the first and the second chunks in this case  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "22c5f3dd-c10b-468f-a727-3faac93ace04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "print(inputs.sequence_ids(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "554ef561-c349-42f3-9348-369653cbd0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print(inputs.sequence_ids(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "791f750e-b0d6-45dc-b7ce-f022dcc11995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384]) torch.Size([2, 384])\n",
      "torch.Size([2, 384])\n",
      "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True],\n",
      "        [False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "sequence_ids = inputs.sequence_ids()\n",
    "# Mask everything apart from the tokens of the context\n",
    "mask = [i != 1 for i in sequence_ids]\n",
    "# Unmask the [CLS] token\n",
    "mask[0] = False\n",
    "# Mask all the [PAD] tokens\n",
    "print(torch.tensor(mask)[None].shape, inputs[\"attention_mask\"].shape)\n",
    "mask = torch.logical_or(torch.tensor(mask)[None], (inputs[\"attention_mask\"] == 0))\n",
    "print(mask.shape)\n",
    "print(mask)\n",
    "start_logits[mask] = -10000\n",
    "end_logits[mask] = -10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "98f90683-8da5-45c6-b1ef-c631707ef1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cfa3123e-d2e0-427c-bd83-359250d922da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 384])\n",
      "tensor([[6.0396e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1519e-02, 1.8898e-02,\n",
      "         2.3307e-03, 2.6660e-01, 3.3987e-04, 5.7259e-03, 8.8251e-03, 2.4441e-02,\n",
      "         1.1653e-03, 1.6499e-02, 4.2213e-03, 2.5967e-04, 5.1531e-04, 4.8240e-05,\n",
      "         1.0526e-03, 3.3808e-05, 4.8656e-05, 3.3979e-04, 7.6070e-05, 8.2786e-05,\n",
      "         2.0089e-04, 3.7564e-05, 3.8198e-04, 2.2247e-05, 1.9128e-05, 3.1091e-04,\n",
      "         2.6787e-05, 2.9143e-04, 5.4116e-05, 2.5045e-05, 2.0686e-04, 5.5922e-05,\n",
      "         3.0922e-05, 1.8686e-04, 3.0462e-05, 3.8663e-05, 3.2295e-05, 2.6850e-04,\n",
      "         3.2148e-05, 5.0713e-04, 7.8036e-05, 2.6229e-05, 2.1632e-04, 1.0072e-04,\n",
      "         2.8341e-04, 2.6911e-04, 1.7327e-04, 6.4009e-05, 4.9601e-04, 1.2098e-04,\n",
      "         4.9918e-05, 2.3866e-04, 2.2675e-04, 7.6235e-04, 5.3037e-05, 6.1205e-05,\n",
      "         2.1717e-03, 6.1977e-05, 8.0132e-05, 3.5199e-05, 3.8517e-05, 1.9568e-05,\n",
      "         3.2789e-05, 8.4875e-05, 1.1264e-03, 1.1658e-03, 9.1064e-05, 4.2216e-04,\n",
      "         2.4844e-05, 4.7227e-05, 1.0703e-04, 2.7814e-04, 9.0607e-06, 5.7355e-05,\n",
      "         3.1021e-05, 1.4257e-04, 1.6705e-05, 1.8516e-05, 3.1405e-05, 1.3833e-05,\n",
      "         4.3620e-05, 3.9557e-05, 3.6288e-05, 1.0668e-05, 2.3371e-04, 1.8859e-05,\n",
      "         4.0527e-05, 3.2564e-05, 1.7001e-05, 5.2079e-05, 5.3438e-05, 6.8894e-05,\n",
      "         9.4097e-06, 5.4008e-06, 5.1005e-05, 1.7664e-04, 3.1185e-05, 2.7753e-05,\n",
      "         7.6582e-05, 1.0711e-04, 2.4014e-05, 1.3228e-04, 2.2080e-04, 5.1977e-05,\n",
      "         3.1118e-05, 8.0990e-05, 2.6433e-05, 3.6156e-05, 2.9454e-05, 3.4986e-05,\n",
      "         1.6331e-04, 1.9274e-04, 2.1196e-05, 2.4516e-05, 4.6693e-05, 4.4601e-05,\n",
      "         3.1723e-05, 5.3226e-05, 2.1222e-05, 7.3337e-05, 9.1684e-05, 1.3768e-05,\n",
      "         1.9348e-05, 1.1236e-05, 4.2474e-05, 1.7870e-05, 4.7483e-05, 3.5773e-05,\n",
      "         4.6925e-05, 8.1235e-05, 7.9116e-05, 5.4204e-05, 2.5807e-05, 9.0443e-05,\n",
      "         2.8478e-05, 6.4565e-05, 3.6055e-05, 1.4395e-04, 1.5277e-05, 6.1496e-05,\n",
      "         1.4717e-04, 2.4373e-05, 3.9865e-04, 3.3044e-05, 4.8797e-05, 2.5091e-05,\n",
      "         5.5642e-05, 2.8450e-04, 2.8919e-05, 3.4556e-05, 2.2984e-05, 3.6495e-05,\n",
      "         1.6050e-05, 4.6959e-05, 5.8836e-05, 2.1062e-05, 6.8295e-05, 1.7455e-04,\n",
      "         4.2067e-05, 2.5771e-05, 9.0461e-04, 3.4682e-05, 2.2831e-05, 7.0017e-04,\n",
      "         2.5974e-05, 3.3501e-05, 2.3248e-05, 6.1960e-05, 2.0418e-04, 7.1498e-05,\n",
      "         2.8672e-05, 6.8584e-05, 1.5240e-05, 2.9584e-03, 1.9563e-05, 8.2177e-05,\n",
      "         3.0757e-05, 8.0593e-05, 9.2864e-05, 1.1457e-04, 1.3182e-05, 2.9157e-05,\n",
      "         4.4604e-05, 5.8819e-06, 1.6354e-05, 2.6683e-05, 4.4594e-05, 1.7754e-05,\n",
      "         1.2513e-05, 1.7692e-05, 1.2350e-05, 3.8307e-05, 5.4325e-05, 8.5396e-05,\n",
      "         2.5757e-05, 1.1572e-05, 3.0818e-05, 2.6117e-05, 2.2340e-05, 8.0805e-05,\n",
      "         1.6667e-05, 1.3175e-05, 1.8923e-05, 1.1987e-05, 4.5682e-05, 8.2841e-05,\n",
      "         5.7296e-05, 2.6128e-05, 4.1435e-05, 1.3660e-05, 7.4009e-05, 6.9716e-05,\n",
      "         3.5102e-05, 2.9658e-05, 2.5441e-05, 4.9155e-05, 1.0304e-05, 2.7758e-04,\n",
      "         1.5747e-05, 3.6439e-05, 5.2869e-05, 2.6449e-05, 2.0917e-05, 2.1051e-05,\n",
      "         2.8080e-05, 6.2091e-05, 1.5358e-05, 1.2988e-05, 1.7279e-05, 7.9639e-05,\n",
      "         1.7420e-04, 2.1415e-05, 2.3101e-05, 2.7047e-05, 1.5998e-05, 2.5636e-05,\n",
      "         3.8288e-05, 7.8743e-05, 2.3411e-05, 3.8740e-05, 1.8684e-05, 5.8870e-05,\n",
      "         2.8242e-05, 3.7386e-05, 9.4584e-05, 3.3563e-04, 4.2749e-05, 3.2027e-05,\n",
      "         1.8438e-05, 1.5639e-04, 9.2072e-06, 2.6871e-05, 5.0628e-05, 6.6634e-05,\n",
      "         1.7043e-05, 1.8963e-05, 1.0072e-04, 1.7822e-05, 1.5416e-05, 3.5239e-05,\n",
      "         1.5112e-05, 8.0784e-05, 2.8089e-05, 8.6342e-05, 2.1300e-05, 5.9262e-05,\n",
      "         7.2382e-05, 2.3301e-05, 1.4347e-04, 9.3701e-06, 1.4267e-04, 3.0287e-05,\n",
      "         5.5216e-05, 8.5921e-05, 5.5442e-05, 3.4037e-05, 4.3847e-05, 2.7366e-05,\n",
      "         2.6062e-05, 2.8268e-05, 3.3615e-05, 1.9389e-05, 1.7744e-05, 6.4289e-05,\n",
      "         3.7703e-05, 8.7453e-05, 1.2262e-04, 7.8571e-05, 1.8368e-05, 2.9913e-05,\n",
      "         1.3881e-05, 2.9113e-05, 1.3188e-05, 2.8436e-05, 3.6310e-05, 2.5213e-05,\n",
      "         5.4479e-05, 2.3161e-05, 2.2188e-05, 5.3402e-05, 3.3268e-05, 9.5148e-05,\n",
      "         1.5824e-04, 4.0980e-05, 6.4439e-05, 4.2738e-05, 4.3797e-05, 3.6252e-04,\n",
      "         2.9179e-05, 2.9772e-05, 2.4612e-05, 5.0071e-05, 1.9387e-05, 2.4742e-04,\n",
      "         5.0116e-05, 3.6276e-05, 1.6146e-05, 1.4490e-05, 5.9163e-05, 9.6002e-06,\n",
      "         3.0809e-05, 3.4815e-05, 2.1627e-05, 7.6142e-05, 1.4263e-04, 2.4654e-05,\n",
      "         3.9240e-05, 1.2094e-04, 5.3953e-05, 8.1789e-05, 3.9092e-05, 2.6804e-05,\n",
      "         2.2500e-04, 1.7146e-05, 1.4356e-04, 2.0048e-05, 4.8189e-05, 2.8893e-05,\n",
      "         1.5475e-04, 1.2219e-05, 1.6598e-04, 4.1446e-05, 1.9321e-04, 3.1978e-05,\n",
      "         3.7745e-05, 6.2245e-05, 1.3202e-05, 4.2301e-05, 4.2694e-05, 4.4277e-05,\n",
      "         4.8065e-05, 4.4595e-05, 2.4264e-05, 7.9127e-05, 1.4261e-04, 5.8166e-05,\n",
      "         8.0192e-05, 2.8839e-05, 5.9347e-05, 5.9969e-05, 5.1162e-05, 6.3475e-05,\n",
      "         4.5755e-05, 6.8251e-05, 4.7683e-05, 2.7384e-05, 4.3412e-05, 6.5305e-05,\n",
      "         4.7019e-05, 2.1791e-05, 1.2243e-04, 8.8607e-05, 9.0091e-05, 0.0000e+00],\n",
      "        [1.1368e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2314e-07, 5.9025e-08,\n",
      "         6.2459e-08, 2.3798e-08, 2.2705e-07, 3.0308e-08, 1.8969e-08, 2.1334e-07,\n",
      "         4.0238e-07, 2.4029e-08, 7.1910e-08, 6.4756e-08, 8.9087e-09, 1.3505e-08,\n",
      "         5.6688e-08, 1.3920e-08, 6.3992e-08, 1.5222e-08, 1.2033e-07, 1.2319e-08,\n",
      "         1.9396e-07, 4.8797e-08, 2.0268e-08, 4.0331e-07, 1.4179e-08, 1.1957e-07,\n",
      "         1.3498e-08, 3.1293e-08, 9.4422e-08, 4.4795e-08, 1.3279e-08, 7.7697e-08,\n",
      "         3.0483e-08, 1.0293e-08, 3.6512e-08, 5.6327e-08, 9.5182e-09, 1.2713e-08,\n",
      "         5.6483e-08, 1.9430e-08, 6.3572e-08, 1.0990e-07, 4.3279e-08, 9.5519e-09,\n",
      "         7.5802e-09, 8.8012e-09, 1.2954e-08, 7.8799e-09, 1.8946e-08, 3.2146e-08,\n",
      "         1.1211e-08, 2.2150e-07, 1.6858e-08, 6.0710e-09, 2.6907e-08, 2.2479e-08,\n",
      "         3.9411e-08, 4.5914e-08, 1.6407e-08, 3.0637e-08, 1.7782e-08, 2.0490e-08,\n",
      "         4.6370e-07, 3.9837e-08, 5.4038e-08, 1.6316e-08, 5.9424e-08, 6.4794e-08,\n",
      "         3.3809e-06, 2.5210e-07, 1.5108e-07, 3.5514e-08, 2.0449e-07, 9.1037e-08,\n",
      "         1.2905e-08, 7.7222e-09, 2.8369e-08, 1.2272e-08, 5.5504e-08, 7.0431e-08,\n",
      "         9.3695e-09, 1.6006e-08, 2.2205e-08, 1.6542e-08, 6.6328e-08, 3.9618e-08,\n",
      "         5.6273e-09, 1.1277e-07, 7.6991e-09, 6.0051e-08, 6.9510e-09, 3.0206e-08,\n",
      "         1.3110e-08, 2.5250e-07, 1.1995e-08, 9.7927e-08, 1.3093e-08, 1.7087e-07,\n",
      "         1.0297e-08, 2.4735e-08, 6.2069e-08, 4.7821e-09, 1.6018e-08, 2.2945e-08,\n",
      "         5.0551e-09, 1.8481e-08, 3.2550e-08, 1.3735e-08, 6.3496e-08, 5.8157e-08,\n",
      "         2.3714e-08, 2.7957e-08, 8.0293e-09, 5.9257e-08, 4.8374e-08, 1.2007e-08,\n",
      "         3.5277e-08, 1.6356e-08, 2.8144e-08, 2.0316e-08, 9.4891e-09, 3.8508e-08,\n",
      "         5.0658e-08, 4.3834e-08, 2.9351e-08, 1.4243e-07, 5.1797e-07, 5.7161e-08,\n",
      "         1.5481e-08, 7.2372e-09, 3.2087e-08, 1.5419e-08, 1.9990e-08, 9.9486e-09,\n",
      "         2.8079e-08, 6.0376e-08, 3.8895e-07, 1.2782e-06, 1.0835e-07, 2.9641e-08,\n",
      "         9.2210e-09, 2.9912e-08, 1.7717e-07, 1.4182e-08, 7.7738e-08, 1.0693e-07,\n",
      "         2.5558e-08, 1.4011e-07, 8.3328e-08, 1.4974e-06, 1.8472e-04, 3.9754e-05,\n",
      "         3.9864e-06, 2.1657e-05, 4.6537e-06, 4.3566e-04, 7.3081e-03, 3.6535e-05,\n",
      "         1.6967e-05, 1.5730e-05, 4.3978e-07, 5.8429e-06, 4.4758e-04, 9.9120e-01,\n",
      "         7.0922e-06, 1.4898e-04, 8.5743e-06, 8.5240e-06, 1.8337e-06, 3.5312e-06,\n",
      "         4.2669e-06, 4.5402e-05, 5.4259e-06, 3.6447e-06, 9.6407e-06, 2.7798e-06,\n",
      "         7.6299e-07, 5.5816e-07, 1.4856e-06, 4.0436e-08, 7.5785e-08, 8.0974e-07,\n",
      "         6.6366e-08, 3.1352e-07, 1.6462e-07, 2.3133e-06, 5.3338e-08, 3.1590e-08,\n",
      "         4.9209e-07, 4.1981e-08, 3.9056e-07, 1.5715e-07, 2.8285e-07, 1.9840e-08,\n",
      "         1.5615e-07, 3.9218e-08, 2.6883e-07, 4.2738e-08, 1.8187e-08, 5.4750e-08,\n",
      "         4.1528e-08, 1.0004e-08, 2.4393e-08, 6.5669e-08, 7.0237e-08, 7.2691e-08,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "start_probabilities = torch.nn.functional.softmax(start_logits, dim=-1)\n",
    "end_probabilities = torch.nn.functional.softmax(end_logits, dim=-1)\n",
    "print(start_probabilities.shape)\n",
    "print(start_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2cc43c09-6e8f-497f-831a-93687b51f3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6040], grad_fn=<TopkBackward0>) tensor([0])\n",
      "tensor([0.5608], grad_fn=<TopkBackward0>) tensor([18])\n",
      "tensor([0.3387], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "v0, i = torch.topk(start_probabilities[0], 1)\n",
    "print(v0, i)\n",
    "\n",
    "import torch\n",
    "v, j = torch.topk(end_probabilities[0], 1)\n",
    "print(v, j)\n",
    "print(v0*v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cf957278-3ab9-4c4c-8ff4-d27b63bdf628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¤— Transformers: State of the Art NLP\n"
     ]
    }
   ],
   "source": [
    "start_index, _ = offsets[0][i.item()]\n",
    "_, end_index = offsets[0][j.item()]\n",
    "print(long_context[start_index:end_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3f5b761e-905f-4ef8-b0c2-72a2ac736841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9912], grad_fn=<TopkBackward0>) tensor([173])\n",
      "tensor([0.9801], grad_fn=<TopkBackward0>) tensor([184])\n",
      "tensor([0.9715], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "v0, i = torch.topk(start_probabilities[1], 1)\n",
    "print(v0, i)\n",
    "\n",
    "import torch\n",
    "v, j = torch.topk(end_probabilities[1], 1)\n",
    "print(v, j)\n",
    "print(v0*v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7c94d9cf-c52a-47e5-ba60-9488b4e42327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax, PyTorch and TensorFlow\n"
     ]
    }
   ],
   "source": [
    "start_index, _ = offsets[1][i.item()]\n",
    "_, end_index = offsets[1][j.item()]\n",
    "print(long_context[start_index:end_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5214ea68-a81c-4a6c-96b0-14346a8fa20b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 18, 0.33867067098617554), (173, 184, 0.9714868664741516)]\n"
     ]
    }
   ],
   "source": [
    "candidates = []\n",
    "for start_probs, end_probs in zip(start_probabilities, end_probabilities):\n",
    "    scores = start_probs[:, None] * end_probs[None, :]\n",
    "    idx = torch.triu(scores).argmax().item()\n",
    "\n",
    "    start_idx = idx // scores.shape[0]\n",
    "    end_idx = idx % scores.shape[0]\n",
    "    score = scores[start_idx, end_idx].item()\n",
    "    candidates.append((start_idx, end_idx, score))\n",
    "\n",
    "print(candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f6c8742f-ec67-4303-866e-7ffaf92ade1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': '\\nğŸ¤— Transformers: State of the Art NLP', 'start': 0, 'end': 37, 'score': 0.33867067098617554}\n",
      "{'answer': 'Jax, PyTorch and TensorFlow', 'start': 1892, 'end': 1919, 'score': 0.9714868664741516}\n"
     ]
    }
   ],
   "source": [
    "for candidate, offset in zip(candidates, offsets):\n",
    "    start_token, end_token, score = candidate\n",
    "    start_char, _ = offset[start_token]\n",
    "    _, end_char = offset[end_token]\n",
    "    answer = long_context[start_char:end_char]\n",
    "    result = {\"answer\": answer, \"start\":start_char, \"end\":end_char, \"score\":score}\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7941ab-cdbf-4658-b3f7-d0c4a161e452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
