{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db4f4d5-ce95-4eb0-8cba-63397323bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#spanish_dataset = load_dataset(\"amazon_reviews_multi\", \"es\")\n",
    "#english_dataset = load_dataset(\"amazon_reviews_multi\", \"en\")\n",
    "#spanish_dataset = load_dataset(\"mteb/amazon_reviews_multi\", \"es\")\n",
    "#english_dataset = load_dataset(\"mteb/amazon_reviews_multi\", \"en\")\n",
    "#english_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018790f-1987-46cd-a256-9d0ddc8a0609",
   "metadata": {},
   "source": [
    "#### Amazon Reviews Multi datasets Kaggle site\n",
    "https://www.kaggle.com/datasets/mexwell/amazon-reviews-multi/data\n",
    "\n",
    "download train.csv.zip, validation.csv.zip and test.csv.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059f2b27-212b-4cbe-acac-0bc95fb0fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train\": \"amazon_reviews-multi/train.csv.zip\",\n",
    "    \"validation\": \"amazon_reviews-multi/validation.csv.zip\",\n",
    "    \"test\": \"amazon_reviews-multi/test.csv.zip\",\n",
    "}\n",
    "\n",
    "amazon_reviews_multi_datasets = load_dataset(\"csv\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54a692f-29b5-48b9-9810-7e8abdf335c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 1200000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews_multi_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4fc75dc-1ee0-4e10-a952-2a26cdab33a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 200000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_dataset = amazon_reviews_multi_datasets.filter(lambda x: x[\"language\"] == \"es\")\n",
    "english_dataset = amazon_reviews_multi_datasets.filter(lambda x: x[\"language\"] == \"en\")\n",
    "english_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dbd1bdd-3868-4e0e-ba96-4e3bcec1d6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 200000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanish_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f07b53cb-88d0-4b7b-ba69-4f8d5df65437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: Worked in front position, not rear'\n",
      "'>> Review: 3 stars because these are not rear brakes as stated in the item description. At least the mount adapter only worked on the front fork of the bike that I got it for.'\n",
      "\n",
      "'>> Title: meh'\n",
      "'>> Review: Does it’s job and it’s gorgeous but mine is falling apart, I had to basically put it together again with hot glue'\n",
      "\n",
      "'>> Title: Can't beat these for the money'\n",
      "'>> Review: Bought this for handling miscellaneous aircraft parts and hanger \"stuff\" that I needed to organize; it really fit the bill. The unit arrived quickly, was well packaged and arrived intact (always a good sign). There are five wall mounts-- three on the top and two on the bottom. I wanted to mount it on the wall, so all I had to do was to remove the top two layers of plastic drawers, as well as the bottom corner drawers, place it when I wanted and mark it; I then used some of the new plastic screw in wall anchors (the 50 pound variety) and it easily mounted to the wall. Some have remarked that they wanted dividers for the drawers, and that they made those. Good idea. My application was that I needed something that I can see the contents at about eye level, so I wanted the fuller-sized drawers. I also like that these are the new plastic that doesn't get brittle and split like my older plastic drawers did. I like the all-plastic construction. It's heavy duty enough to hold metal parts, but being made of plastic it's not as heavy as a metal frame, so you can easily mount it to the wall and still load it up with heavy stuff, or light stuff. No problem there. For the money, you can't beat it. Best one of these I've bought to date-- and I've been using some version of these for over forty years.'\n"
     ]
    }
   ],
   "source": [
    "def show_samples(dataset, num_samples=3, seed=42):\n",
    "    sample = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
    "    for example in sample:\n",
    "        print(f\"\\n'>> Title: {example['review_title']}'\")\n",
    "        print(f\"'>> Review: {example['review_body']}'\")\n",
    "\n",
    "show_samples(english_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13994fd-c971-418b-86e7-74af09812d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: .'\n",
      "'>> Review: La montarlo se rompió una rueda debido a materiales débiles, pero al arreglarla funciona correctamente.'\n",
      "\n",
      "'>> Title: Primeras impresiones'\n",
      "'>> Review: El servicio ha sido muy bueno, me ha llegado 2 días antes de lo previsto. En cuanto al producto no es que me haya dado muy buenas primeras impresiones. El borde del protector es de plástico y lo único que hay de cristal es la pantalla. Además el plástico es muy fino. A nivel estético queda muy bien y se ajusta perfectamente, la única queja que tengo es eso, que no sea todo de cristal y que para mi gusto es demasiado fino. De la resistencia no tengo ni idea ya que es el primer día que lo llevo. No creo que sea mal producto del todo si no que depende del gusto y el cuidado que tenga cada uno de su móvil. Personalmente creo que por el mismo precio hay otros productos que si que son enteros de cristal y más gordos que por lo menos a mí me generan más confianza.'\n",
      "\n",
      "'>> Title: .'\n",
      "'>> Review: Funciona genial y la llevo conmigo en todas las ocasiones importantes. Estoy muy muy contenta con esta compra, la verdad.'\n"
     ]
    }
   ],
   "source": [
    "show_samples(spanish_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecdee706-728a-4206-b16f-6b395285dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_dataset.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3a98325-a7e9-4aef-938f-872625d8f780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>en_0964290</td>\n",
       "      <td>product_en_0740675</td>\n",
       "      <td>reviewer_en_0342986</td>\n",
       "      <td>1</td>\n",
       "      <td>Arrived broken. Manufacturer defect. Two of th...</td>\n",
       "      <td>I'll spend twice the amount of time boxing up ...</td>\n",
       "      <td>en</td>\n",
       "      <td>furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>en_0690095</td>\n",
       "      <td>product_en_0440378</td>\n",
       "      <td>reviewer_en_0133349</td>\n",
       "      <td>1</td>\n",
       "      <td>the cabinet dot were all detached from backing...</td>\n",
       "      <td>Not use able</td>\n",
       "      <td>en</td>\n",
       "      <td>home_improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>en_0311558</td>\n",
       "      <td>product_en_0399702</td>\n",
       "      <td>reviewer_en_0152034</td>\n",
       "      <td>1</td>\n",
       "      <td>I received my first order of this product and ...</td>\n",
       "      <td>The product is junk.</td>\n",
       "      <td>en</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>en_0044972</td>\n",
       "      <td>product_en_0444063</td>\n",
       "      <td>reviewer_en_0656967</td>\n",
       "      <td>1</td>\n",
       "      <td>This product is a piece of shit. Do not buy. D...</td>\n",
       "      <td>Fucking waste of money</td>\n",
       "      <td>en</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>en_0784379</td>\n",
       "      <td>product_en_0139353</td>\n",
       "      <td>reviewer_en_0757638</td>\n",
       "      <td>1</td>\n",
       "      <td>went through 3 in one day doesn't fit correct ...</td>\n",
       "      <td>bubble</td>\n",
       "      <td>en</td>\n",
       "      <td>pc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>399995</td>\n",
       "      <td>en_0046316</td>\n",
       "      <td>product_en_0980158</td>\n",
       "      <td>reviewer_en_0629807</td>\n",
       "      <td>5</td>\n",
       "      <td>Cute slippers, my MIL loved them.</td>\n",
       "      <td>Nice and fit as advertised</td>\n",
       "      <td>en</td>\n",
       "      <td>shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>399996</td>\n",
       "      <td>en_0956024</td>\n",
       "      <td>product_en_0954574</td>\n",
       "      <td>reviewer_en_0459072</td>\n",
       "      <td>5</td>\n",
       "      <td>My 6 year old likes this and keeps him engaged...</td>\n",
       "      <td>good to keep the kids engaged</td>\n",
       "      <td>en</td>\n",
       "      <td>toy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>399997</td>\n",
       "      <td>en_0589358</td>\n",
       "      <td>product_en_0402982</td>\n",
       "      <td>reviewer_en_0199163</td>\n",
       "      <td>5</td>\n",
       "      <td>Replaced my battery with it. Works like new.</td>\n",
       "      <td>This works</td>\n",
       "      <td>en</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>399998</td>\n",
       "      <td>en_0970602</td>\n",
       "      <td>product_en_0873374</td>\n",
       "      <td>reviewer_en_0590563</td>\n",
       "      <td>5</td>\n",
       "      <td>I like them, holding up well.</td>\n",
       "      <td>Well made.</td>\n",
       "      <td>en</td>\n",
       "      <td>industrial_supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>399999</td>\n",
       "      <td>en_0750030</td>\n",
       "      <td>product_en_0843981</td>\n",
       "      <td>reviewer_en_0775729</td>\n",
       "      <td>5</td>\n",
       "      <td>Very good for my village lights are bright I l...</td>\n",
       "      <td>Very good for my village lights are bright I l...</td>\n",
       "      <td>en</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0   review_id          product_id          reviewer_id  \\\n",
       "0           200000  en_0964290  product_en_0740675  reviewer_en_0342986   \n",
       "1           200001  en_0690095  product_en_0440378  reviewer_en_0133349   \n",
       "2           200002  en_0311558  product_en_0399702  reviewer_en_0152034   \n",
       "3           200003  en_0044972  product_en_0444063  reviewer_en_0656967   \n",
       "4           200004  en_0784379  product_en_0139353  reviewer_en_0757638   \n",
       "...            ...         ...                 ...                  ...   \n",
       "199995      399995  en_0046316  product_en_0980158  reviewer_en_0629807   \n",
       "199996      399996  en_0956024  product_en_0954574  reviewer_en_0459072   \n",
       "199997      399997  en_0589358  product_en_0402982  reviewer_en_0199163   \n",
       "199998      399998  en_0970602  product_en_0873374  reviewer_en_0590563   \n",
       "199999      399999  en_0750030  product_en_0843981  reviewer_en_0775729   \n",
       "\n",
       "        stars                                        review_body  \\\n",
       "0           1  Arrived broken. Manufacturer defect. Two of th...   \n",
       "1           1  the cabinet dot were all detached from backing...   \n",
       "2           1  I received my first order of this product and ...   \n",
       "3           1  This product is a piece of shit. Do not buy. D...   \n",
       "4           1  went through 3 in one day doesn't fit correct ...   \n",
       "...       ...                                                ...   \n",
       "199995      5                  Cute slippers, my MIL loved them.   \n",
       "199996      5  My 6 year old likes this and keeps him engaged...   \n",
       "199997      5       Replaced my battery with it. Works like new.   \n",
       "199998      5                      I like them, holding up well.   \n",
       "199999      5  Very good for my village lights are bright I l...   \n",
       "\n",
       "                                             review_title language  \\\n",
       "0       I'll spend twice the amount of time boxing up ...       en   \n",
       "1                                            Not use able       en   \n",
       "2                                    The product is junk.       en   \n",
       "3                                  Fucking waste of money       en   \n",
       "4                                                  bubble       en   \n",
       "...                                                   ...      ...   \n",
       "199995                         Nice and fit as advertised       en   \n",
       "199996                      good to keep the kids engaged       en   \n",
       "199997                                         This works       en   \n",
       "199998                                         Well made.       en   \n",
       "199999  Very good for my village lights are bright I l...       en   \n",
       "\n",
       "           product_category  \n",
       "0                 furniture  \n",
       "1          home_improvement  \n",
       "2                      home  \n",
       "3                  wireless  \n",
       "4                        pc  \n",
       "...                     ...  \n",
       "199995                shoes  \n",
       "199996                  toy  \n",
       "199997             wireless  \n",
       "199998  industrial_supplies  \n",
       "199999                 home  \n",
       "\n",
       "[200000 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_dataset[\"train\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f76a74a-390c-4caf-82b3-a8715405f4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_category\n",
       "home                        17679\n",
       "apparel                     15951\n",
       "wireless                    15717\n",
       "other                       13418\n",
       "beauty                      12091\n",
       "drugstore                   11730\n",
       "kitchen                     10382\n",
       "toy                          8745\n",
       "sports                       8277\n",
       "automotive                   7506\n",
       "lawn_and_garden              7327\n",
       "home_improvement             7136\n",
       "pet_products                 7082\n",
       "digital_ebook_purchase       6749\n",
       "pc                           6401\n",
       "electronics                  6186\n",
       "office_product               5521\n",
       "shoes                        5197\n",
       "grocery                      4730\n",
       "book                         3756\n",
       "baby_product                 3150\n",
       "furniture                    2984\n",
       "jewelry                      2747\n",
       "camera                       2139\n",
       "industrial_supplies          1994\n",
       "digital_video_download       1364\n",
       "luggage                      1328\n",
       "musical_instruments          1102\n",
       "video_games                   775\n",
       "watch                         761\n",
       "personal_care_appliances       75\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#english_dataset.set_format(\"pandas\")\n",
    "english_df = english_dataset[\"train\"][:]\n",
    "# 최상위 20개의 상품에 대한 개수 보여주기...\n",
    "#english_df[\"product_category\"].value_counts()[:20]\n",
    "english_df[\"product_category\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9c657e-5c08-4caf-814f-3919ea64d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_books(example):\n",
    "    return (\n",
    "        example[\"product_category\"] == \"book\"\n",
    "        or example[\"product_category\"] == \"digital_ebook_purchase\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1bde241-ec7b-4983-83c6-a245a9c6958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d593ef43-ac70-4684-80ec-2c24b3ea8e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: I'm dissapointed.'\n",
      "'>> Review: I guess I had higher expectations for this book from the reviews. I really thought I'd at least like it. The plot idea was great. I loved Ash but, it just didnt go anywhere. Most of the book was about their radio show and talking to callers. I wanted the author to dig deeper so we could really get to know the characters. All we know about Grace is that she is attractive looking, Latino and is kind of a brat. I'm dissapointed.'\n",
      "\n",
      "'>> Title: Good art, good price, poor design'\n",
      "'>> Review: I had gotten the DC Vintage calendar the past two years, but it was on backorder forever this year and I saw they had shrunk the dimensions for no good reason. This one has good art choices but the design has the fold going through the picture, so it's less aesthetically pleasing, especially if you want to keep a picture to hang. For the price, a good calendar'\n",
      "\n",
      "'>> Title: Helpful'\n",
      "'>> Review: Nearly all the tips useful and. I consider myself an intermediate to advanced user of OneNote. I would highly recommend.'\n"
     ]
    }
   ],
   "source": [
    "spanish_books = spanish_dataset.filter(filter_books)\n",
    "english_books = english_dataset.filter(filter_books)\n",
    "show_samples(english_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383abd2c-905f-416b-b2e4-87f2e133259f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 200000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation', 'test'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(english_dataset)\n",
    "english_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0592529-af0a-4bb2-bdfa-8da2100c1114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation', 'test'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_books.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb6cc89c-e473-4721-bd1d-2d46d1d79f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': [599935, 599940, 599943, 599993],\n",
       " 'review_id': ['es_0007904', 'es_0283367', 'es_0621841', 'es_0950799'],\n",
       " 'product_id': ['product_es_0426043',\n",
       "  'product_es_0068739',\n",
       "  'product_es_0929985',\n",
       "  'product_es_0712641'],\n",
       " 'reviewer_id': ['reviewer_es_0527698',\n",
       "  'reviewer_es_0518482',\n",
       "  'reviewer_es_0696435',\n",
       "  'reviewer_es_0827348'],\n",
       " 'stars': [5, 5, 5, 5],\n",
       " 'review_body': ['Muy buena novela, bien escrita y muy entretenida desde el principio hasta el final, el hilo de la historia muy bien hilvanado',\n",
       "  'Y le ha encantado. Un regalo un poco más original de lo que estamos acostumbrados, aparte el libro tiene buena calidad, buenas fotos y explicación, etc. Para 8 años en adelante está muy bien. Bueno, según habilidad del niño claro. Yo también he hecho algunas figuritas. Interesante.',\n",
       "  'Simplemente maravilloso, esta autora tiene una facilidad increíble para escribir y hacerte sentir con cada palabra que empiezas a leer. Espero que nunca se canse de dejarnos un poquito de ella en cada libro que saca. GRACIAS.',\n",
       "  'Si la primera parte me gustó, el desenlace me ha maravillado; he sentido tantas cosas, me he emocionado, he llorado.......... Es increíble como este libro me ha llegado muy adentro, quizá porque he identificado situaciones como personales. Enhorabuena Anny Peterson por estas maravillosas historias llenas de sentimiento.'],\n",
       " 'review_title': ['Buena Novela',\n",
       "  'Ha sido para un regalo para mi sobrino',\n",
       "  'No deja de sorprender',\n",
       "  'La droga +dura 2'],\n",
       " 'language': ['es', 'es', 'es', 'es'],\n",
       " 'product_category': ['digital_ebook_purchase',\n",
       "  'book',\n",
       "  'digital_ebook_purchase',\n",
       "  'digital_ebook_purchase']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, DatasetDict\n",
    "\n",
    "books_dataset = DatasetDict()\n",
    "\n",
    "for split in english_books.keys():\n",
    "    books_dataset[split] = concatenate_datasets(\n",
    "        [english_books[split], spanish_books[split]]\n",
    "    )\n",
    "books_dataset[\"train\"][-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e06c8f3e-3192-4108-b112-e841e8795a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: Easy to follow!!!!'\n",
      "'>> Review: I loved The dash diet weight loss Solution. Never hungry. I would recommend this diet. Also the menus are well rounded. Try it. Has lots of the information need thanks.'\n",
      "\n",
      "'>> Title: PARCIALMENTE DAÑADO'\n",
      "'>> Review: Me llegó el día que tocaba, junto a otros libros que pedí, pero la caja llegó en mal estado lo cual dañó las esquinas de los libros porque venían sin protección (forro).'\n",
      "\n",
      "'>> Title: no lo he podido descargar'\n",
      "'>> Review: igual que el anterior'\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, DatasetDict\n",
    "\n",
    "books_dataset = DatasetDict()\n",
    "\n",
    "for split in english_books.keys():\n",
    "    books_dataset[split] = concatenate_datasets(\n",
    "        [english_books[split], spanish_books[split]]\n",
    "    )\n",
    "    books_dataset[split] = books_dataset[split].shuffle(seed=42)\n",
    "\n",
    "# 몇 개의 샘플을 선택합니다.\n",
    "show_samples(books_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e5da3e6-8cfc-49b6-89b0-01ef65bf2529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': [323267, 395015, 349166, 472025],\n",
       " 'review_id': ['en_0178460', 'en_0854914', 'en_0220240', 'es_0008529'],\n",
       " 'product_id': ['product_en_0808042',\n",
       "  'product_en_0309796',\n",
       "  'product_en_0857771',\n",
       "  'product_es_0184753'],\n",
       " 'reviewer_id': ['reviewer_en_0173650',\n",
       "  'reviewer_en_0113252',\n",
       "  'reviewer_en_0001189',\n",
       "  'reviewer_es_0276151'],\n",
       " 'stars': [4, 5, 4, 2],\n",
       " 'review_body': [\"I gave it 4 stars because I felt the beginning chapter was a bit uneven, but as I got into the story, it gripped me. The characters, location, and the twists kept me reading well into the night. After posting this review, I'm going back to purchase the next book in the series.\",\n",
       "  'Good book to read for business students',\n",
       "  'Enjoyable read will more than likely purchase other books by this author.',\n",
       "  'No está mal, pero más para niños de 9 años'],\n",
       " 'review_title': [\"I'm hooked!\",\n",
       "  'Readable,',\n",
       "  'Enjoyable',\n",
       "  'A partir de 9 años'],\n",
       " 'language': ['en', 'en', 'en', 'es'],\n",
       " 'product_category': ['digital_ebook_purchase',\n",
       "  'digital_ebook_purchase',\n",
       "  'digital_ebook_purchase',\n",
       "  'book']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset[\"train\"][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0719e6db-f30a-4995-8319-04c1736feda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 17612\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 424\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 442\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63d6d3c4-fb1f-4ecc-aa2c-8cd2472d96eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>323267</td>\n",
       "      <td>en_0178460</td>\n",
       "      <td>product_en_0808042</td>\n",
       "      <td>reviewer_en_0173650</td>\n",
       "      <td>4</td>\n",
       "      <td>I gave it 4 stars because I felt the beginning...</td>\n",
       "      <td>I'm hooked!</td>\n",
       "      <td>en</td>\n",
       "      <td>digital_ebook_purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>395015</td>\n",
       "      <td>en_0854914</td>\n",
       "      <td>product_en_0309796</td>\n",
       "      <td>reviewer_en_0113252</td>\n",
       "      <td>5</td>\n",
       "      <td>Good book to read for business students</td>\n",
       "      <td>Readable,</td>\n",
       "      <td>en</td>\n",
       "      <td>digital_ebook_purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>349166</td>\n",
       "      <td>en_0220240</td>\n",
       "      <td>product_en_0857771</td>\n",
       "      <td>reviewer_en_0001189</td>\n",
       "      <td>4</td>\n",
       "      <td>Enjoyable read will more than likely purchase ...</td>\n",
       "      <td>Enjoyable</td>\n",
       "      <td>en</td>\n",
       "      <td>digital_ebook_purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>472025</td>\n",
       "      <td>es_0008529</td>\n",
       "      <td>product_es_0184753</td>\n",
       "      <td>reviewer_es_0276151</td>\n",
       "      <td>2</td>\n",
       "      <td>No está mal, pero más para niños de 9 años</td>\n",
       "      <td>A partir de 9 años</td>\n",
       "      <td>es</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>344418</td>\n",
       "      <td>en_0887613</td>\n",
       "      <td>product_en_0173743</td>\n",
       "      <td>reviewer_en_0635017</td>\n",
       "      <td>4</td>\n",
       "      <td>I grew up reading Koontz, and years ago, I sto...</td>\n",
       "      <td>A study of nature?</td>\n",
       "      <td>en</td>\n",
       "      <td>digital_ebook_purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17607</th>\n",
       "      <td>515375</td>\n",
       "      <td>es_0953460</td>\n",
       "      <td>product_es_0803643</td>\n",
       "      <td>reviewer_es_0927474</td>\n",
       "      <td>3</td>\n",
       "      <td>Me compre este libro en un principio por que f...</td>\n",
       "      <td>El libro esta bien, dependiendo desde que punt...</td>\n",
       "      <td>es</td>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17608</th>\n",
       "      <td>278653</td>\n",
       "      <td>en_0494679</td>\n",
       "      <td>product_en_0254302</td>\n",
       "      <td>reviewer_en_0961739</td>\n",
       "      <td>2</td>\n",
       "      <td>I have read a few of her books and this was no...</td>\n",
       "      <td>Not my favorite</td>\n",
       "      <td>en</td>\n",
       "      <td>digital_ebook_purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17609</th>\n",
       "      <td>324944</td>\n",
       "      <td>en_0182400</td>\n",
       "      <td>product_en_0828506</td>\n",
       "      <td>reviewer_en_0340449</td>\n",
       "      <td>4</td>\n",
       "      <td>I enjoyed this book very much. It is full of v...</td>\n",
       "      <td>Good</td>\n",
       "      <td>en</td>\n",
       "      <td>digital_ebook_purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17610</th>\n",
       "      <td>335053</td>\n",
       "      <td>en_0165528</td>\n",
       "      <td>product_en_0247902</td>\n",
       "      <td>reviewer_en_0303937</td>\n",
       "      <td>4</td>\n",
       "      <td>Another solid entry into a great series. Maddo...</td>\n",
       "      <td>The Story continues</td>\n",
       "      <td>en</td>\n",
       "      <td>digital_ebook_purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17611</th>\n",
       "      <td>390720</td>\n",
       "      <td>en_0701553</td>\n",
       "      <td>product_en_0766236</td>\n",
       "      <td>reviewer_en_0835871</td>\n",
       "      <td>5</td>\n",
       "      <td>What a ride I enjoyed this book// its been a w...</td>\n",
       "      <td>Wow</td>\n",
       "      <td>en</td>\n",
       "      <td>digital_ebook_purchase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17612 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   review_id          product_id          reviewer_id  stars  \\\n",
       "0          323267  en_0178460  product_en_0808042  reviewer_en_0173650      4   \n",
       "1          395015  en_0854914  product_en_0309796  reviewer_en_0113252      5   \n",
       "2          349166  en_0220240  product_en_0857771  reviewer_en_0001189      4   \n",
       "3          472025  es_0008529  product_es_0184753  reviewer_es_0276151      2   \n",
       "4          344418  en_0887613  product_en_0173743  reviewer_en_0635017      4   \n",
       "...           ...         ...                 ...                  ...    ...   \n",
       "17607      515375  es_0953460  product_es_0803643  reviewer_es_0927474      3   \n",
       "17608      278653  en_0494679  product_en_0254302  reviewer_en_0961739      2   \n",
       "17609      324944  en_0182400  product_en_0828506  reviewer_en_0340449      4   \n",
       "17610      335053  en_0165528  product_en_0247902  reviewer_en_0303937      4   \n",
       "17611      390720  en_0701553  product_en_0766236  reviewer_en_0835871      5   \n",
       "\n",
       "                                             review_body  \\\n",
       "0      I gave it 4 stars because I felt the beginning...   \n",
       "1                Good book to read for business students   \n",
       "2      Enjoyable read will more than likely purchase ...   \n",
       "3             No está mal, pero más para niños de 9 años   \n",
       "4      I grew up reading Koontz, and years ago, I sto...   \n",
       "...                                                  ...   \n",
       "17607  Me compre este libro en un principio por que f...   \n",
       "17608  I have read a few of her books and this was no...   \n",
       "17609  I enjoyed this book very much. It is full of v...   \n",
       "17610  Another solid entry into a great series. Maddo...   \n",
       "17611  What a ride I enjoyed this book// its been a w...   \n",
       "\n",
       "                                            review_title language  \\\n",
       "0                                            I'm hooked!       en   \n",
       "1                                              Readable,       en   \n",
       "2                                              Enjoyable       en   \n",
       "3                                     A partir de 9 años       es   \n",
       "4                                     A study of nature?       en   \n",
       "...                                                  ...      ...   \n",
       "17607  El libro esta bien, dependiendo desde que punt...       es   \n",
       "17608                                    Not my favorite       en   \n",
       "17609                                               Good       en   \n",
       "17610                                The Story continues       en   \n",
       "17611                                                Wow       en   \n",
       "\n",
       "             product_category  \n",
       "0      digital_ebook_purchase  \n",
       "1      digital_ebook_purchase  \n",
       "2      digital_ebook_purchase  \n",
       "3                        book  \n",
       "4      digital_ebook_purchase  \n",
       "...                       ...  \n",
       "17607                    book  \n",
       "17608  digital_ebook_purchase  \n",
       "17609  digital_ebook_purchase  \n",
       "17610  digital_ebook_purchase  \n",
       "17611  digital_ebook_purchase  \n",
       "\n",
       "[17612 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset.set_format(\"pandas\")\n",
    "train_df = books_dataset[\"train\"][:]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2545665f-6db6-4a0a-b5cd-a9ac09eb77a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13313,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"review_title\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8299498f-758f-4b90-b29b-01469decb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a24358ef-a6a5-4ecc-8174-476b954b79ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='language'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['language'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "634862eb-6dbe-4efe-9ade-6e6003096d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of samples')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(review.split()) for review in train_df[\"review_title\"]], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d2c3a43-6735-44a0-87ab-47a93cc588d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of samples')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(review.split()) for review in train_df[\"review_body\"]], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e5c65d0-93d4-4d65-bd02-ac10a8589d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d216ea22-945d-40a7-b18a-b14b4a923e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 17612\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 424\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 442\n",
      "    })\n",
      "})\n",
      "after filtering the length of review_title > 2 : DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 9672\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 238\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
      "        num_rows: 245\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(books_dataset)\n",
    "books_dataset = books_dataset.filter(lambda x: len(x[\"review_title\"].split()) > 2)\n",
    "print(f\"after filtering the length of review_title > 2 : {books_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d9da1a0-5b1b-43df-8bf6-b2a8146320bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A partir de 9 años',\n",
       " 'A study of nature?',\n",
       " 'This was the last book by this author. I use to by every book she wrote.',\n",
       " 'Entretenido para adolescentes',\n",
       " 'Un clásico moderno']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset[\"train\"][\"review_title\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "625d6adc-c839-4755-abc5-56e81f95ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0e56248-a77a-4936-a41a-4cc83832a3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "803b9d0b-1fed-44d0-929c-d10b132f16a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [336, 259, 28387, 11807, 287, 62893, 295, 12507, 309, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"I loved reading the Hunger Games!\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9787db33-e652-4087-bffd-88856cecfce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ca103fd-c5d7-4c8b-918c-a1b46c31ee3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 2, 3, 4, 4, 5, 5, None]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ce840bd-d2bb-4bb4-bf33-7efed12aecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁I', '▁', 'loved', '▁reading', '▁the', '▁Hung', 'er', '▁Games', '!', '</s>']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c77e0d8-70c7-49a6-bb77-c009ea61a3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁I', '▁', 'loved', '▁reading', '▁the', '▁Hung', 'er', '▁Games', '!', '</s>']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542b7aa-60b8-41be-8263-c79b63524697",
   "metadata": {},
   "source": [
    "#### The special Unicode character ▁ and end-of-sequence token </s> indicate that we’re dealing with the SentencePiece tokenizer, which is based on the Unigram segmentation algorithm discussed in Chapter 6. Unigram is especially useful for multilingual corpora since it allows SentencePiece to be agnostic about accents, punctuation, and the fact that many languages, like Japanese, do not have whitespace characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64b9278e-dce2-4b12-9ff5-589ed28152d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[336, 259, 28387, 11807, 287, 62893, 295, 12507, 309, 1]\n",
      "[336, 259, 28387, 11807, 287, 62893, 295, 12507, 309, 1]\n"
     ]
    }
   ],
   "source": [
    "print(inputs.input_ids)\n",
    "print(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a3ea82c-bb66-49a8-83d0-601bf7e8809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 512\n",
    "max_target_length = 30\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"review_body\"], max_length=max_input_length, truncation=True\n",
    "    )\n",
    "    # 타겟을 위한 토크나이저 설정\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"review_title\"], max_length=max_target_length, truncation=True\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3de47558-eddf-4ca4-b253-0504aea83239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e59803cceb0449eba1426dc5256d24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/238 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3935: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = books_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4946ce8-e2f9-4c10-acc3-e039e3232be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9672\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 238\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a646169f-1fab-44bb-9aaf-d915d7f95cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summary = \"I absolutely loved reading the Hunger Games\"\n",
    "reference_summary = \"I loved reading the Hunger Games\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31c3502e-2460-4a60-a544-8a511df9d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27b19f21-102d-4ea5-9ab6-9baba867178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10464/54150397.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge_score = load_metric(\"rouge\")\n",
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "rouge_score = load_metric(\"rouge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bda836f1-17db-47f4-b1fd-b55d9d308981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), mid=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), high=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.6666666666666666, recall=0.8, fmeasure=0.7272727272727272), mid=Score(precision=0.6666666666666666, recall=0.8, fmeasure=0.7272727272727272), high=Score(precision=0.6666666666666666, recall=0.8, fmeasure=0.7272727272727272)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), mid=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), high=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), mid=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), high=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923))}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = rouge_score.compute(\n",
    "    predictions=[generated_summary], references=[reference_summary]\n",
    ")\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2cd0c92a-ef59-4ab6-8aee-777e0316737f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[\"rouge1\"].mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2d667fe-6c60-461b-9d9a-ea09e8082799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip show nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b246d0e6-68fb-4951-b1ab-47aabc75a8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home01/qualis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7521fb6-541e-4cc6-a539-de3043a36b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I grew up reading Koontz, and years ago, I stopped,convinced i had \"outgrown\" him. Still,when a friend was looking for something suspenseful too read, I suggested Koontz. She found Strangers. The excitement art how good it was startled me. I was sure i had recommended something else. I ordered a copy for myself. This was a great reintroduction to an old favorite writer -- a novel full of fully developed characters that are totally relatable. People you could care about with full back stories. A mystery that had to be solved. I expected it to be the book I read every few weeks, only on flights. Instead, I\\'ve ignored everything and everybody to finish this. Definitely a must read.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset[\"train\"][\"review_body\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97b578d5-a137-4ab7-8c45-1ff325c8ab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I grew up reading Koontz, and years ago, I stopped,convinced i had \"outgrown\" him.', 'Still,when a friend was looking for something suspenseful too read, I suggested Koontz.', 'She found Strangers.', 'The excitement art how good it was startled me.', 'I was sure i had recommended something else.', 'I ordered a copy for myself.', 'This was a great reintroduction to an old favorite writer -- a novel full of fully developed characters that are totally relatable.', 'People you could care about with full back stories.', 'A mystery that had to be solved.', 'I expected it to be the book I read every few weeks, only on flights.', \"Instead, I've ignored everything and everybody to finish this.\", 'Definitely a must read.']\n",
      "I grew up reading Koontz, and years ago, I stopped,convinced i had \"outgrown\" him.\n",
      "Still,when a friend was looking for something suspenseful too read, I suggested Koontz.\n",
      "She found Strangers.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "\n",
    "print(sent_tokenize(books_dataset[\"train\"][\"review_body\"][1]))\n",
    "print(three_sentence_summary(books_dataset[\"train\"][\"review_body\"][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0ea2650-c87c-4b7b-8845-ba8ee19e1806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': [472025, 344418],\n",
       " 'review_id': ['es_0008529', 'en_0887613'],\n",
       " 'product_id': ['product_es_0184753', 'product_en_0173743'],\n",
       " 'reviewer_id': ['reviewer_es_0276151', 'reviewer_en_0635017'],\n",
       " 'stars': [2, 4],\n",
       " 'review_body': ['No está mal, pero más para niños de 9 años',\n",
       "  'I grew up reading Koontz, and years ago, I stopped,convinced i had \"outgrown\" him. Still,when a friend was looking for something suspenseful too read, I suggested Koontz. She found Strangers. The excitement art how good it was startled me. I was sure i had recommended something else. I ordered a copy for myself. This was a great reintroduction to an old favorite writer -- a novel full of fully developed characters that are totally relatable. People you could care about with full back stories. A mystery that had to be solved. I expected it to be the book I read every few weeks, only on flights. Instead, I\\'ve ignored everything and everybody to finish this. Definitely a must read.'],\n",
       " 'review_title': ['A partir de 9 años', 'A study of nature?'],\n",
       " 'language': ['es', 'en'],\n",
       " 'product_category': ['book', 'digital_ebook_purchase']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset[\"train\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9221dc7c-d1ba-402b-9a41-9b5182a1b715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I grew up reading Koontz, and years ago, I stopped,convinced i had \"outgrown\" him.',\n",
       " 'Still,when a friend was looking for something suspenseful too read, I suggested Koontz.',\n",
       " 'She found Strangers.',\n",
       " 'The excitement art how good it was startled me.',\n",
       " 'I was sure i had recommended something else.',\n",
       " 'I ordered a copy for myself.',\n",
       " 'This was a great reintroduction to an old favorite writer -- a novel full of fully developed characters that are totally relatable.',\n",
       " 'People you could care about with full back stories.',\n",
       " 'A mystery that had to be solved.',\n",
       " 'I expected it to be the book I read every few weeks, only on flights.',\n",
       " \"Instead, I've ignored everything and everybody to finish this.\",\n",
       " 'Definitely a must read.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(books_dataset[\"train\"][1][\"review_body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b024387-1af2-461f-84f3-669f41f40c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "    num_rows: 238\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5dc0d59b-c86f-40cb-81b9-d78ab223a769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Great book. Terrible delivery. Came out of the package mangled. Not cool Amazon',\n",
       " \"This is most definitely a young adult book. The main character, Ivy, is a psychic detective who can read the past of a person or thing by touching the object in question. Her reaction to horrifying things discovered this way is to cry, scream, pass out for days at a time, etc. Kinda silly.... In this book she sets out to rescue a fae king and save her city from an invasion by the same nasty characters that kidnapped the fae king. I thought this was an adequate story but don't need to read any more of the series.\",\n",
       " 'Una historia muy bonita que rompe con las ideas preconcebidas de edad en la pareja.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset[\"validation\"][\"review_body\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "20529e51-c5af-4d6c-bcb9-476df92ece0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 9672\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 238\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0400e21f-0d83-4d01-b364-15b58a638923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Great book. Terrible delivery. Came out of the package mangled. Not cool Amazon\n",
      "1 : This is most definitely a young adult book. The main character, Ivy, is a psychic detective who can read the past of a person or thing by touching the object in question. Her reaction to horrifying things discovered this way is to cry, scream, pass out for days at a time, etc. Kinda silly.... In this book she sets out to rescue a fae king and save her city from an invasion by the same nasty characters that kidnapped the fae king. I thought this was an adequate story but don't need to read any more of the series.\n",
      "2 : Una historia muy bonita que rompe con las ideas preconcebidas de edad en la pareja.\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(books_dataset[\"validation\"][\"review_body\"][:3]):\n",
    "    print(i, \":\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "06ae0522-fe15-4b54-b9c1-a23f5f068ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [Great book.\n",
      "Terrible delivery.\n",
      "Came out of the package mangled.]\n",
      "1: [This is most definitely a young adult book.\n",
      "The main character, Ivy, is a psychic detective who can read the past of a person or thing by touching the object in question.\n",
      "Her reaction to horrifying things discovered this way is to cry, scream, pass out for days at a time, etc.]\n",
      "2: [Una historia muy bonita que rompe con las ideas preconcebidas de edad en la pareja.]\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(books_dataset[\"validation\"][\"review_body\"][:3]):\n",
    "    print(f\"{i}: [{three_sentence_summary(text)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82d53f7e-1432-43e2-9ad6-603632118fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una historia muy bonita que rompe con las ideas preconcebidas de edad en la pareja.\n"
     ]
    }
   ],
   "source": [
    "print(three_sentence_summary(books_dataset[\"validation\"][2][\"review_body\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6fb09f33-a3ee-4b36-9093-1ea6f100c6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Great book.\\nTerrible delivery.\\nCame out of the package mangled.',\n",
       " 'This is most definitely a young adult book.\\nThe main character, Ivy, is a psychic detective who can read the past of a person or thing by touching the object in question.\\nHer reaction to horrifying things discovered this way is to cry, scream, pass out for days at a time, etc.',\n",
       " 'Una historia muy bonita que rompe con las ideas preconcebidas de edad en la pareja.',\n",
       " 'Este libro aporta un poco más que la mayoría de sus contemporáneos de suspense, trabaja y profundiza bien en el personaje principal y Es original el enclave geográfico en el que transcurre.\\nEs bastante mejor que los libros anglosajones que están tan de moda tipo la Chica del tren, nada que ver, este libro es para gente que le gusta leer más, lo recomiendo aunque tampoco deslumbra',\n",
       " 'Interesting details about making wine in France.\\nSometimes the story and characters sounded a bit tired.',\n",
       " 'Me encanta!\\nLo uso mucho en clase de inglés con 1° cuando tratamos el tema de las familias, sobre todo para hacer hincapié en la diversidad familiar.\\nLos dibujos son muy coloridos y atraen su atención.',\n",
       " 'No es lo que me esperaba, pensaba que habría más variedad de tipografías, pero no está mal.\\nCabe mencionar que se necesitan bolígrafos específicos.',\n",
       " 'El pedido aparece como entregado pero realmente no ha sido entregado.\\nSigo a la espera.\\nRuego aclaración por parte de Amazon.',\n",
       " \"But maybe that's just me.\\nI had hoped for a grand summation of the trilogy.\\nI read somewhat silly dialogues especially when the Russians were involved.\",\n",
       " 'This book had me smiling almost the entire time.\\nBodie... well...\\nHe is certainly up there with the best book boys ever.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_sample = [three_sentence_summary(text) for text in books_dataset[\"validation\"][\"review_body\"][:10]]\n",
    "summaries_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c44f1106-bbb7-4a22-a687-33b91bfe4112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Terrible delivery condition',\n",
       " 'A little too cute for me',\n",
       " 'Una historia preciosa',\n",
       " 'Es un libro correcto',\n",
       " 'Wine And Sighs',\n",
       " 'Bonito y necesario libro',\n",
       " 'No está mal',\n",
       " 'No entregado aunque aparece como entregado',\n",
       " 'Not what I expected',\n",
       " 'Lovable, Fun, Steamy Story! <3']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_title_sample = books_dataset[\"validation\"][\"review_title\"][:10]\n",
    "review_title_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0bf69e76-dd3a-44a0-9f05-d0fa763feced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.05096937274569631, recall=0.35, fmeasure=0.08728096877692004), mid=Score(precision=0.09279167493528678, recall=0.55, fmeasure=0.15397848395806654), high=Score(precision=0.14047691219515174, recall=0.725, fmeasure=0.22600059553608998)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.007142857142857143, recall=0.05, fmeasure=0.013333333333333332), mid=Score(precision=0.03492063492063492, recall=0.24, fmeasure=0.05856643356643356), high=Score(precision=0.06190476190476189, recall=0.45, fmeasure=0.1062121212121212)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.04648723267139814, recall=0.30812500000000015, fmeasure=0.07919069370513959), mid=Score(precision=0.0818836794553735, recall=0.4833333333333333, fmeasure=0.13668310171442308), high=Score(precision=0.12151808173849976, recall=0.65, fmeasure=0.19891784714697414)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.04219431504935291, recall=0.29166666666666663, fmeasure=0.07211942991178695), mid=Score(precision=0.07931835728388695, recall=0.4666666666666666, fmeasure=0.1319211272565877), high=Score(precision=0.1188921607733435, recall=0.6416666666666667, fmeasure=0.1944962802242089))}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_score.compute(predictions=summaries_sample, references=review_title_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "68325968-a503-4182-92d1-903eb47f9e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.35, recall=0.05096937274569631, fmeasure=0.08728096877692004), mid=Score(precision=0.55, recall=0.09279167493528678, fmeasure=0.15397848395806654), high=Score(precision=0.725, recall=0.14047691219515174, fmeasure=0.22600059553608998)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.05, recall=0.007142857142857143, fmeasure=0.013333333333333332), mid=Score(precision=0.24, recall=0.03492063492063492, fmeasure=0.05856643356643356), high=Score(precision=0.45, recall=0.06190476190476189, fmeasure=0.1062121212121212)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.30812500000000015, recall=0.04648723267139814, fmeasure=0.07919069370513959), mid=Score(precision=0.4833333333333333, recall=0.0818836794553735, fmeasure=0.13668310171442308), high=Score(precision=0.65, recall=0.12151808173849976, fmeasure=0.19891784714697414)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.31666666666666665, recall=0.04499292974624254, fmeasure=0.07710275824918923), mid=Score(precision=0.4833333333333333, recall=0.08101056831229866, fmeasure=0.13472174755069494), high=Score(precision=0.6416666666666667, recall=0.11979928658002613, fmeasure=0.19486023402884609))}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_score.compute(predictions=review_title_sample, references=summaries_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27f94863-4d84-4327-b146-57bf969b0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_baseline(dataset, metric):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[\"review_body\"]]\n",
    "    return metric.compute(predictions=summaries, references=dataset[\"review_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aa498575-1f45-472b-b9d7-bd4b3a17d0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 16.87, 'rouge2': 8.83, 'rougeL': 15.53, 'rougeLsum': 15.9}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary Operation https://dojang.io/mod/page/view.php?id=2213\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "score = evaluate_baseline(books_dataset[\"validation\"], rouge_score)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "#rouge_dict = dict((rn, round(score[rn].mid.fmeasure * 100, 2)) for rn in rouge_names)\n",
    "rouge_dict = dict([(rn, round(score[rn].mid.fmeasure * 100, 2)) for rn in rouge_names])\n",
    "rouge_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8c5984a3-131b-4996-b548-cd26cb52d2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rouge1', 16.87), ('rouge2', 8.83), ('rougeL', 15.53), ('rougeLsum', 15.9)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(rn, round(score[rn].mid.fmeasure * 100, 2)) for rn in rouge_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "85c4b81d-0a0c-44bf-883c-0b6de2a52a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 16.87, 'rouge2': 8.83, 'rougeL': 15.53, 'rougeLsum': 15.9}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((rn, round(score[rn].mid.fmeasure * 100, 2)) for rn in rouge_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fff99c0c-a4b4-48bc-b76d-dcef07817aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b27eb543934fd38b76fcca219ab543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ab8dd1292a46649695609557abd2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e610d060-5a47-430d-9045-6de9334a0d60",
   "metadata": {},
   "source": [
    "💡 다운스트림 작업에서 모델 미세 조정에 대한 경고가 표시되지 않는데 그 이유는 sequence-to-sequence 작업의 경우 네트워크의 모든 가중치를 유지하기 때문입니다. 이것을 3장의 텍스트 분류 모델과 비교해보세요. 여기서 사전 학습된 모델의 헤드(head)는 무작위로 초기화된 네트워크로 대체되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1ef72698-efb1-4edd-828e-3603d49cee5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2f0db3d4774ac48aa4bd43ad0524b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ae45940-775c-4050-9857-b932a224a156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 9672\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 238\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a6fc1c97-5c28-4fc0-9f6f-5f636777ce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "num_train_epochs = 8\n",
    "# 매 에포크마다 training loss를 보여준다.\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-amazon-reviews-en-es\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=logging_steps,\n",
    "   #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6669bd0-ed8e-4b28-88ab-58713979718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # 생성된 요약을 텍스트로 디코딩\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # 레이블 내의 -100을 교체한다.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # 레퍼런스 요약을 텍스트로 디코딩\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # ROUGE는 각 문장 다음에 개행문자를 요구한다.\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # ROUGE 점수 계산\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # 중간 점수(median scores) 추출\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f60b4a6f-6385-4304-9c84-51c7490fa448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c577b98e-d682-4bd0-9470-6305f42a52d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'review_id',\n",
       " 'product_id',\n",
       " 'reviewer_id',\n",
       " 'stars',\n",
       " 'review_body',\n",
       " 'review_title',\n",
       " 'language',\n",
       " 'product_category']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_dataset[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0453116b-39f4-4fe1-b01a-df73d581665f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9672\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 238\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39d3aa2f-b552-412e-9ee9-12c7b9dbed60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9672\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 238\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "    books_dataset[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2f36d1f6-a8e3-4e30-accb-f63fcdf9e579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[653, 1957, 1314, 261, 2757, 1280, 435, 259, 29166, 263, 269, 774, 5547, 1], [336, 6998, 481, 1150, 11807, 1590, 16339, 360, 261, 305, 3127, 2780, 261, 336, 35042, 345, 261, 3141, 136052, 285, 259, 266, 1425, 313, 2983, 106419, 272, 311, 4065, 260, 36874, 261, 1909, 259, 262, 22163, 639, 259, 7505, 332, 9066, 88398, 265, 5105, 6320, 4906, 261, 336, 21847, 345, 1590, 16339, 360, 260, 4630, 5897, 320, 146261, 260, 486, 21101, 1998, 3684, 2606, 2316, 609, 639, 3014, 11665, 416, 260, 336, 639, 7779, 259, 266, 1425, 57512, 9066, 5401, 260, 336, 259, 91451, 259, 262, 27613, 332, 259, 34779, 260, 1494, 639, 259, 262, 3005, 584, 62351, 288, 461, 6801, 22590, 62799, 3093, 259, 262, 20233, 3622, 304, 259, 11994, 259, 36260, 48971, 533, 418, 2725, 484, 27067, 1059, 260, 18646, 521, 259, 3659, 1063, 1388, 514, 3622, 3004, 26222, 260, 298, 109508, 276, 533, 1425, 288, 390, 259, 131690, 260, 336, 259, 25505, 609, 288, 390, 287, 3435, 336, 4906, 6338, 259, 6924, 259, 29426, 261, 2469, 351, 259, 109933, 260, 563, 15129, 261, 336, 277, 857, 36975, 345, 14355, 305, 259, 265, 111962, 288, 27039, 714, 260, 459, 25640, 259, 262, 5150, 4906, 260, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[298, 259, 5994, 269, 774, 5547, 1], [298, 10380, 304, 13992, 291, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets[\"train\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8332cff4-3c88-42aa-b80a-08a67da7b496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   653,   1957,   1314,    261,   2757,   1280,    435,    259,  29166,\n",
       "            263,    269,    774,   5547,      1,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0],\n",
       "        [   336,   6998,    481,   1150,  11807,   1590,  16339,    360,    261,\n",
       "            305,   3127,   2780,    261,    336,  35042,    345,    261,   3141,\n",
       "         136052,    285,    259,    266,   1425,    313,   2983, 106419,    272,\n",
       "            311,   4065,    260,  36874,    261,   1909,    259,    262,  22163,\n",
       "            639,    259,   7505,    332,   9066,  88398,    265,   5105,   6320,\n",
       "           4906,    261,    336,  21847,    345,   1590,  16339,    360,    260,\n",
       "           4630,   5897,    320, 146261,    260,    486,  21101,   1998,   3684,\n",
       "           2606,   2316,    609,    639,   3014,  11665,    416,    260,    336,\n",
       "            639,   7779,    259,    266,   1425,  57512,   9066,   5401,    260,\n",
       "            336,    259,  91451,    259,    262,  27613,    332,    259,  34779,\n",
       "            260,   1494,    639,    259,    262,   3005,    584,  62351,    288,\n",
       "            461,   6801,  22590,  62799,   3093,    259,    262,  20233,   3622,\n",
       "            304,    259,  11994,    259,  36260,  48971,    533,    418,   2725,\n",
       "            484,  27067,   1059,    260,  18646,    521,    259,   3659,   1063,\n",
       "           1388,    514,   3622,   3004,  26222,    260,    298, 109508,    276,\n",
       "            533,   1425,    288,    390,    259, 131690,    260,    336,    259,\n",
       "          25505,    609,    288,    390,    287,   3435,    336,   4906,   6338,\n",
       "            259,   6924,    259,  29426,    261,   2469,    351,    259, 109933,\n",
       "            260,    563,  15129,    261,    336,    277,    857,  36975,    345,\n",
       "          14355,    305,    259,    265, 111962,    288,  27039,    714,    260,\n",
       "            459,  25640,    259,    262,   5150,   4906,    260,      1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  298,   259,  5994,   269,   774,  5547,     1],\n",
       "        [  298, 10380,   304, 13992,   291,     1,  -100]]), 'decoder_input_ids': tensor([[    0,   298,   259,  5994,   269,   774,  5547],\n",
       "        [    0,   298, 10380,   304, 13992,   291,     1]])}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [tokenized_datasets[\"train\"][i] for i in range(2)]\n",
    "data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c2a41ce-1e0d-4025-8cfa-850ac1ddd12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "WARNING:accelerate.utils.other:Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "87e8d6fc-c160-409c-ad2e-ea1c712f6c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9672' max='9672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9672/9672 12:47, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.308100</td>\n",
       "      <td>3.313007</td>\n",
       "      <td>14.107500</td>\n",
       "      <td>5.821700</td>\n",
       "      <td>13.625600</td>\n",
       "      <td>13.529800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.933000</td>\n",
       "      <td>3.186826</td>\n",
       "      <td>15.978800</td>\n",
       "      <td>7.700500</td>\n",
       "      <td>15.613100</td>\n",
       "      <td>15.334800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.599700</td>\n",
       "      <td>3.121789</td>\n",
       "      <td>17.480400</td>\n",
       "      <td>8.372500</td>\n",
       "      <td>16.920600</td>\n",
       "      <td>16.851600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.423500</td>\n",
       "      <td>3.071767</td>\n",
       "      <td>17.620800</td>\n",
       "      <td>8.709600</td>\n",
       "      <td>17.110200</td>\n",
       "      <td>16.881600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.315800</td>\n",
       "      <td>3.048693</td>\n",
       "      <td>16.446400</td>\n",
       "      <td>7.738000</td>\n",
       "      <td>15.914600</td>\n",
       "      <td>15.763600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.256800</td>\n",
       "      <td>3.040009</td>\n",
       "      <td>17.384000</td>\n",
       "      <td>8.538100</td>\n",
       "      <td>16.939100</td>\n",
       "      <td>16.738500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.207000</td>\n",
       "      <td>3.028080</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.081700</td>\n",
       "      <td>16.596500</td>\n",
       "      <td>16.353300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.177900</td>\n",
       "      <td>3.031225</td>\n",
       "      <td>17.604000</td>\n",
       "      <td>8.627200</td>\n",
       "      <td>17.179600</td>\n",
       "      <td>16.945400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/scratch/qualis/miniconda3/envs/transformer/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9672, training_loss=3.9027171549075295, metrics={'train_runtime': 773.7644, 'train_samples_per_second': 99.999, 'train_steps_per_second': 12.5, 'total_flos': 1.187112454422528e+16, 'train_loss': 3.9027171549075295, 'epoch': 8.0})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e99c2e02-d215-410b-8e99-36a5bdbfd10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.0312254428863525,\n",
       " 'eval_rouge1': 17.604,\n",
       " 'eval_rouge2': 8.6272,\n",
       " 'eval_rougeL': 17.1796,\n",
       " 'eval_rougeLsum': 16.9454,\n",
       " 'eval_runtime': 5.4304,\n",
       " 'eval_samples_per_second': 43.828,\n",
       " 'eval_steps_per_second': 5.524,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdb7dad-cd3e-4926-acfd-8a1e9327d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training complete\", tags=\"summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d2e625-7909-4141-b9cb-9164868cbda6",
   "metadata": {},
   "source": [
    "이제 이 섹션을 마무리하기 전에, 🤗Accelerate에서 제공하는 저수준 기능을 사용하여 mT5를 미세 조정할 수 있는 방법을 살펴보겠습니다.\r\n",
    "#### \r\n",
    "🤗Accelerate를 이용한 mT5 미세조정\r\n",
    "🤗Accelerate로 모델을 미세 조정하는 것은 3장에서 본 텍스트 분류 예제와 매우 유사합니다. 주요 차이점은 학습 중에 요약을 명시적으로 생성하고 ROUGE 점수를 계산하는 방법을 정의해야 한다는 것입니다. Seq2SeqTrainer가 생성 과정을 처리했음을 기억하십시오. 🤗Accelerate에서 이 두 가지 요구 사항을 구현하는 방법을 살펴보겠습니다.\r\n",
    "\r\n",
    "학습을 위한 모든 것들을 준비하기\r\n",
    "가장 먼저 해야 할 일은 각 분할(split)에 대한 DataLoader를 만드는 것입니다. PyTorch dataloaders는 텐서(tensors) 배치를 입력으로 받기 때문에 데이터셋에서 형식을 \"torch\"로 설정해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4451851d-45ea-4e35-8016-fd130f035ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d128f23c-0270-40df-87b9-dea3ee2cfa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde5470-8c30-4efc-891e-bd76d2bab791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], \n",
    "    collate_fn=data_collator, \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904effab-27d1-4e22-89d6-aacec9c17e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7531f5-0c90-4120-b9a2-98a9a2e3cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19af9a7-6699-49b6-b667-26df81424f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 10\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f16bf-89ae-4ee3-b6d2-0f81b2f91282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # ROUGE는 각 문장마다 개행문자가 들어갈 것을 요구한다.\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b85e8-534c-4af9-b25e-10956eec13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from huggingface_hub import get_full_repo_name\n",
    "\n",
    "#model_name = \"test-bert-finetuned-squad-accelerate\"\n",
    "#repo_name = get_full_repo_name(model_name)\n",
    "#repo_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63d176-27c1-4778-bcd9-251421990cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from huggingface_hub import Repository\n",
    "\n",
    "output_dir = \"results-mt5-finetuned-squad-accelerate\"\n",
    "#repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898e7b4-9970-49d9-8cb0-41467f603b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # 학습\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # 평가\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.pad_across_processes(\n",
    "                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # 만일 최대 길이로 패딩하지 않았으면 레이블도 역시 패딩해야 한다.\n",
    "            labels = accelerator.pad_across_processes(\n",
    "                batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "            labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "            # 레이블 내의 -100을 모두 교체한다.\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            if isinstance(generated_tokens, tuple):\n",
    "                generated_tokens = generated_tokens[0]\n",
    "            decoded_preds = tokenizer.batch_decode(\n",
    "                generated_tokens, skip_special_tokens=True\n",
    "            )\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            decoded_preds, decoded_labels = postprocess_text(\n",
    "                decoded_preds, decoded_labels\n",
    "            )\n",
    "\n",
    "            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # 메트릭 계산\n",
    "    result = rouge_score.compute()\n",
    "    # 중간값 ROUGE 점수를 추출\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    print(f\"Epoch {epoch}:\", result)\n",
    "\n",
    "    # 저장 및 업로드\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        #repo.push_to_hub(\n",
    "        #    commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        #)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7b48e-3f06-4686-8015-237e2faa40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "hub_model_id = \"hwang2006/mt5-small-finetuned-amazon-reviews-en-es\"\n",
    "summarizer = pipeline(\"summarization\", model=hub_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b67150-e6ac-4f18-b6a4-11f676267a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(idx):\n",
    "    review = books_dataset[\"test\"][idx][\"review_body\"]\n",
    "    title = books_dataset[\"test\"][idx][\"review_title\"]\n",
    "    summary = summarizer(books_dataset[\"test\"][idx][\"review_body\"])[0][\"summary_text\"]\n",
    "    print(f\"'>>> Review: {review}'\")\n",
    "    print(f\"\\n'>>> Title: {title}'\")\n",
    "    print(f\"\\n'>>> Summary: {summary}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae6823-20c3-4225-aa1b-9ca27e46cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_summary(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf34cd7-b29b-4993-ae77-079a4076e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_summary(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52718ad7-c6c8-40d5-b19c-fd06edbba462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"amazon_reviews-multi/train.csv.zip\",\n",
    "    \"validation\": \"amazon_reviews-multi/validation.csv.zip\",\n",
    "    \"test\": \"amazon_reviews-multi/test.csv.zip\",\n",
    "}\n",
    "\n",
    "amazon_reviews_multi_datasets = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "spanish_dataset = amazon_reviews_multi_datasets.filter(lambda x: x[\"language\"] == \"es\")\n",
    "english_dataset = amazon_reviews_multi_datasets.filter(lambda x: x[\"language\"] == \"en\")\n",
    "\n",
    "def filter_books(example):\n",
    "    return (\n",
    "        example[\"product_category\"] == \"book\"\n",
    "        or example[\"product_category\"] == \"digital_ebook_purchase\"\n",
    "    )\n",
    "\n",
    "\n",
    "spanish_books = spanish_dataset.filter(filter_books)\n",
    "english_books = english_dataset.filter(filter_books)\n",
    "\n",
    "from datasets import concatenate_datasets, DatasetDict\n",
    "\n",
    "books_dataset = DatasetDict()\n",
    "\n",
    "for split in english_books.keys():\n",
    "    books_dataset[split] = concatenate_datasets(\n",
    "        [english_books[split], spanish_books[split]]\n",
    "    )\n",
    "    books_dataset[split] = books_dataset[split].shuffle(seed=42)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 30\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"review_body\"], max_length=max_input_length, truncation=True\n",
    "    )\n",
    "    # 타겟을 위한 토크나이저 설정\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"review_title\"], max_length=max_target_length, truncation=True\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = books_dataset.map(preprocess_function, batched=True)\n",
    "#print(tokenized_datasets)\n",
    "#DatasetDict({\n",
    "#    train: Dataset({\n",
    "#        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
    "#        num_rows: 17612\n",
    "#    })\n",
    "#    validation: Dataset({\n",
    "#        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
    "#        num_rows: 424\n",
    "#    })\n",
    "#    test: Dataset({\n",
    "#        features: ['Unnamed: 0', 'review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category', 'input_ids', 'attention_mask', 'labels'],\n",
    "#        num_rows: 442\n",
    "#    })\n",
    "#})\n",
    "\n",
    "from datasets import load_metric\n",
    "\n",
    "rouge_score = load_metric(\"rouge\")\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#def three_sentence_summary(text):\n",
    "#    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "\n",
    "#def evaluate_baseline(dataset, metric):\n",
    "#    summaries = [three_sentence_summary(text) for text in dataset[\"review_body\"]]\n",
    "#    return metric.compute(predictions=summaries, references=dataset[\"review_title\"])\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "num_train_epochs = 8\n",
    "# 매 에포크마다 training loss를 보여준다.\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-amazon-en-es\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    #logging_steps=logging_steps,\n",
    "    #push_to_hub=True,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # 생성된 요약을 텍스트로 디코딩\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # 레이블 내의 -100을 교체한다.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # 레퍼런스 요약을 텍스트로 디코딩\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # ROUGE는 각 문장 다음에 개행문자를 요구한다.\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # ROUGE 점수 계산\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # 중간 점수(median scores) 추출\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n",
    "#trainer.push_to_hub(commit_message=\"Training complete\", tags=\"summarization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0b3c17-3406-42fe-89da-69c9cb6260ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388edef-a00f-4be4-9aed-e2db9ad81df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"amazon_reviews-multi/train.csv.zip\",\n",
    "    \"validation\": \"amazon_reviews-multi/validation.csv.zip\",\n",
    "    \"test\": \"amazon_reviews-multi/test.csv.zip\",\n",
    "}\n",
    "\n",
    "amazon_reviews_multi_datasets = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "spanish_dataset = amazon_reviews_multi_datasets.filter(lambda x: x[\"language\"] == \"es\")\n",
    "english_dataset = amazon_reviews_multi_datasets.filter(lambda x: x[\"language\"] == \"en\")\n",
    "\n",
    "def filter_books(example):\n",
    "    return (\n",
    "        example[\"product_category\"] == \"book\"\n",
    "        or example[\"product_category\"] == \"digital_ebook_purchase\"\n",
    "    )\n",
    "\n",
    "\n",
    "spanish_books = spanish_dataset.filter(filter_books)\n",
    "english_books = english_dataset.filter(filter_books)\n",
    "\n",
    "from datasets import concatenate_datasets, DatasetDict\n",
    "\n",
    "books_dataset = DatasetDict()\n",
    "\n",
    "for split in english_books.keys():\n",
    "    books_dataset[split] = concatenate_datasets(\n",
    "        [english_books[split], spanish_books[split]]\n",
    "    )\n",
    "    books_dataset[split] = books_dataset[split].shuffle(seed=42)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "model_checkpoint = \"google/mt5-small\"\n",
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 30\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"review_body\"], max_length=max_input_length, truncation=True\n",
    "    )\n",
    "    # 타겟을 위한 토크나이저 설정\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"review_title\"], max_length=max_target_length, truncation=True\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = books_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "from datasets import load_metric\n",
    "\n",
    "rouge_score = load_metric(\"rouge\")\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#def three_sentence_summary(text):\n",
    "#    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "\n",
    "#def evaluate_baseline(dataset, metric):\n",
    "#    summaries = [three_sentence_summary(text) for text in dataset[\"review_body\"]]\n",
    "#    return metric.compute(predictions=summaries, references=dataset[\"review_title\"])\n",
    "\n",
    "#tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "    books_dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], \n",
    "    collate_fn=data_collator, \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")\n",
    "\n",
    "from transformers import get_scheduler\n",
    "\n",
    "#num_train_epochs = 10\n",
    "num_train_epochs = 8\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # ROUGE는 각 문장마다 개행문자가 들어갈 것을 요구한다.\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "#from huggingface_hub import get_full_repo_name\n",
    "\n",
    "#model_name = \"test-bert-finetuned-squad-accelerate\"\n",
    "#repo_name = get_full_repo_name(model_name)\n",
    "#repo_name\n",
    "\n",
    "#from huggingface_hub import Repository\n",
    "\n",
    "output_dir = \"results-mt5-finetuned-squad-accelerate\"\n",
    "#repo = Repository(output_dir, clone_from=repo_name)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # 학습\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # 평가\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.pad_across_processes(\n",
    "                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # 만일 최대 길이로 패딩하지 않았으면 레이블도 역시 패딩해야 한다.\n",
    "            labels = accelerator.pad_across_processes(\n",
    "                batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "            labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "            # 레이블 내의 -100을 모두 교체한다.\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            if isinstance(generated_tokens, tuple):\n",
    "                generated_tokens = generated_tokens[0]\n",
    "            decoded_preds = tokenizer.batch_decode(\n",
    "                generated_tokens, skip_special_tokens=True\n",
    "            )\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            decoded_preds, decoded_labels = postprocess_text(\n",
    "                decoded_preds, decoded_labels\n",
    "            )\n",
    "\n",
    "            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # 메트릭 계산\n",
    "    result = rouge_score.compute()\n",
    "    # 중간값 ROUGE 점수를 추출\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    print(f\"Epoch {epoch}:\", result)\n",
    "\n",
    "    # 저장 및 업로드\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        #repo.push_to_hub(\n",
    "        #    commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199f88c-77ad-4b63-ad64-f7c5e8e2e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, get_scheduler\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"amazon_reviews-multi/train.csv.zip\",\n",
    "    \"validation\": \"amazon_reviews-multi/validation.csv.zip\",\n",
    "    \"test\": \"amazon_reviews-multi/test.csv.zip\",\n",
    "}\n",
    "\n",
    "amazon_reviews_multi_datasets = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "spanish_dataset = amazon_reviews_multi_datasets.filter(lambda x: x[\"language\"] == \"es\")\n",
    "english_dataset = amazon_reviews_multi_datasets.filter(lambda x: x[\"language\"] == \"en\")\n",
    "\n",
    "def filter_books(example):\n",
    "    return (\n",
    "        example[\"product_category\"] == \"book\"\n",
    "        or example[\"product_category\"] == \"digital_ebook_purchase\"\n",
    "    )\n",
    "\n",
    "\n",
    "spanish_books = spanish_dataset.filter(filter_books)\n",
    "english_books = english_dataset.filter(filter_books)\n",
    "\n",
    "books_dataset = DatasetDict()\n",
    "\n",
    "for split in english_books.keys():\n",
    "    books_dataset[split] = concatenate_datasets(\n",
    "        [english_books[split], spanish_books[split]]\n",
    "    )\n",
    "    books_dataset[split] = books_dataset[split].shuffle(seed=42)\n",
    "\n",
    "model_checkpoint = \"google/mt5-small\"\n",
    "\n",
    "def get_dataloaders(accelerator: Accelerator, model, batch_size: int = 32):\n",
    "\n",
    "    max_input_length = 512\n",
    "    max_target_length = 30\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        model_inputs = tokenizer(\n",
    "            examples[\"review_body\"], max_length=max_input_length, truncation=True\n",
    "        )\n",
    "        # 타겟을 위한 토크나이저 설정\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            labels = tokenizer(\n",
    "                examples[\"review_title\"], max_length=max_target_length, truncation=True\n",
    "            )\n",
    "\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "    \n",
    "    tokenized_datasets = books_dataset.map(preprocess_function, batched=True)\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "        books_dataset[\"train\"].column_names\n",
    "    )\n",
    "    #tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "    batch_size = 8\n",
    "    train_dataloader = DataLoader(\n",
    "        tokenized_datasets[\"train\"],\n",
    "        shuffle=True,\n",
    "        collate_fn=data_collator,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    eval_dataloader = DataLoader(\n",
    "        tokenized_datasets[\"validation\"], \n",
    "        collate_fn=data_collator, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_dataloader, eval_dataloader, tokenizer\n",
    "\n",
    "#def training_function(config, args):\n",
    "def training_function():\n",
    "\n",
    "    batch_size = 8\n",
    "\n",
    "    accelerator = Accelerator()\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "    train_dataloader, eval_dataloader, tokenizer = get_dataloaders(accelerator, model, \n",
    "                                                                   batch_size=batch_size)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    \n",
    "    model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, eval_dataloader\n",
    "    )\n",
    "\n",
    "    num_train_epochs = 8\n",
    "    num_update_steps_per_epoch = len(train_dataloader)\n",
    "    num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "\n",
    "    def postprocess_text(preds, labels):\n",
    "        preds = [pred.strip() for pred in preds]\n",
    "        labels = [label.strip() for label in labels]\n",
    "\n",
    "        # ROUGE는 각 문장마다 개행문자가 들어갈 것을 요구한다.\n",
    "        preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "        labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "        return preds, labels\n",
    "\n",
    "    #from huggingface_hub import get_full_repo_name\n",
    "\n",
    "    #model_name = \"test-bert-finetuned-squad-accelerate\"\n",
    "    #repo_name = get_full_repo_name(model_name)\n",
    "    #repo_name\n",
    "\n",
    "    #from huggingface_hub import Repository\n",
    "\n",
    "    output_dir = \"results-mt5-finetuned-squad-accelerate\"\n",
    "    #repo = Repository(output_dir, clone_from=repo_name)\n",
    "\n",
    "    rouge_score = load_metric(\"rouge\")\n",
    "\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    for epoch in range(num_train_epochs):\n",
    "    # 학습\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            accelerator.backward(loss)\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        # 평가\n",
    "        model.eval()\n",
    "        for step, batch in enumerate(eval_dataloader):\n",
    "            with torch.no_grad():\n",
    "                generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                    batch[\"input_ids\"],\n",
    "                    attention_mask=batch[\"attention_mask\"],\n",
    "                )\n",
    "\n",
    "            generated_tokens = accelerator.pad_across_processes(\n",
    "                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # 만일 최대 길이로 패딩하지 않았으면 레이블도 역시 패딩해야 한다.\n",
    "            labels = accelerator.pad_across_processes(\n",
    "                batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "            labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "            # 레이블 내의 -100을 모두 교체한다.\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            if isinstance(generated_tokens, tuple):\n",
    "                generated_tokens = generated_tokens[0]\n",
    "            decoded_preds = tokenizer.batch_decode(\n",
    "                generated_tokens, skip_special_tokens=True\n",
    "            )\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            decoded_preds, decoded_labels = postprocess_text(\n",
    "                decoded_preds, decoded_labels\n",
    "            )\n",
    "\n",
    "            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "        # 메트릭 계산\n",
    "        result = rouge_score.compute()\n",
    "        # 중간값 ROUGE 점수를 추출\n",
    "        result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "        result = {k: round(v, 4) for k, v in result.items()}\n",
    "        #print(f\"Epoch {epoch}:\", result)\n",
    "        Accelerator.print(f\"Epoch {epoch}:\", result)\n",
    "\n",
    "        # 저장 및 업로드\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "        if accelerator.is_main_process:\n",
    "            tokenizer.save_pretrained(output_dir)\n",
    "            #repo.push_to_hub(\n",
    "            #    commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "            #)\n",
    "\n",
    "#from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "#model_name = \"marian-finetuned-kde4-en-to-fr-accelerate\"\n",
    "#repo_name = get_full_repo_name(model_name)\n",
    "#repo_name\n",
    "#repo = Repository(output_dir, clone_from=repo_name)\n",
    "#notebook_launcher(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes)\n",
    "\n",
    "from accelerate import notebook_launcher\n",
    "\n",
    "notebook_launcher(training_function, num_processes=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba795108-243f-44c1-80b2-16ed563a9660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
