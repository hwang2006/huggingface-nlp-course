{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db39c09e-1810-4620-b6cb-25ffce80aa03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3882c0361feb4fa1b75a82292e1cf484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/966 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3dcad76179c47aeb2f154a1a64ffe9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3ae63e95424177a7cee63fdd6a3e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0310a85ffa594db693dcdf4f549f6554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f22ea32201475dbb4301882f5ead0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/658 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6349392e4043bc92b30c1aad2c41a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d88e1c08c1b47ff8034564cf8dbb46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8941a0134d2245a388d441b29260c72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f0e6b249554dc3b85a3114a14b0d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bd5dc35bc74aadb1992773f6f2bf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6d58c16a2c424b8c83a71bcfafe467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fdcee2182d4432bbb43b559a297b3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb46e2f4ea24becaf2ba12937194422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19641aea968a4f6ab34f500256d2c72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Upstage/SOLAR-10.7B-v1.0\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Upstage/SOLAR-10.7B-v1.0\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edb210e1-803c-4ce3-9307-76e6f328a7d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Hi, my name is \"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "#outputs = model.generate(**inputs, max_new_tokens=64)\n",
    "#print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3967bc32-a6ba-4504-a78e-a61fdad1c330",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 15359, 28725, 586, 1141, 349, 1500, 28723, 315, 837, 264, 20654, 3327, 28333, 304, 25986], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = \"Hi, my name is X. I am a certified personal trainer and nutrition\"\n",
    "tokenized_label = tokenizer(label)\n",
    "tokenized_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72754cb1-7912-4ef4-8605-2ad7b32f7730",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 15359, 28725,   586,  1141,   349, 28705]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "535ae168-7cab-4d6c-a111-3b48f4228e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "#inputs[\"labels\"] = torch.tensor([5359, 28725, 586, 1141, 349, 1500, 28723, 315, 837, 264,])\n",
    "inputs[\"labels\"] = torch.tensor([5359, 28725, 586, 1141, 349, 1500, 28723])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "87f68e0c-b39a-4eb5-b9ba-88c0939cddb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 15359, 28725,   586,  1141,   349, 28705]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([ 5359, 28725,   586,  1141,   349,  1500])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80ae04df-953d-4f99-a911-7d89eca855af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Hi', ',', '▁my', '▁name', '▁is', '▁']\n",
      "[15359, 28725, 586, 1141, 349, 28705]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c282cfb-9e84-440a-b2b4-c174b77930ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([[15359, 28725,   586,  1141,   349, 28705]], device='cuda:0')\n",
      "Logits: torch.Size([1, 6, 32000])\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([ids]).to(\"cuda\")\n",
    "print(\"Input IDs:\", input_ids)\n",
    "\n",
    "output = model(input_ids)\n",
    "print(\"Logits:\", output.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5624d5d2-2913-4fea-a5fd-e97750a7b311",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 15359, 28725,   586,  1141,   349, 28705]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([15359, 28725,   586,  1141,   349, 28705], device='cuda:0')}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#inputs[\"labels\"] = torch.tensor([5359, 28725, 586, 1141, 349, 1500, 28723, 315, 837, 264,])\n",
    "inputs[\"labels\"] = torch.tensor([15359, 28725,   586,  1141,   349, 28705])\n",
    "inputs = inputs.to(\"cuda\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d47933a7-29e4-4e80-8765-024689d22df2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=tensor(9.5413, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[[-12.4844, -10.0781,   0.7759,  ...,  -7.1016,  -8.3359,  -7.6133],\n",
       "         [-16.1094, -14.5781,  -2.4414,  ...,  -8.7109,  -9.0234,  -7.8281],\n",
       "         [-15.2578, -12.7188,  -1.8838,  ..., -10.0625, -10.2969,  -8.6172],\n",
       "         ...,\n",
       "         [-15.4766,  -5.7227,   0.7441,  ...,  -7.4180,  -9.2344,  -9.1875],\n",
       "         [-13.2656,  -8.0938,   1.0010,  ...,  -7.7070,  -8.8203,  -7.1836],\n",
       "         [  2.5547,  -3.7051,   4.0156,  ...,   0.4021,   4.6680,   5.1016]]],\n",
       "       device='cuda:0', grad_fn=<ToCopyBackward0>), past_key_values=None, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a23ddcdd-59ff-4a67-9872-61f519d49de1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '▁Hi', ',', '▁my', '▁name', '▁is', '▁']\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.convert_ids_to_tokens([    1, 15359, 28725,   586,  1141,   349, 28705])\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42887657-76f2-4c51-89b1-1c8083b9691d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CausalLMOutputWithPast(loss=None, logits=tensor([[[-12.4844, -10.0781,   0.7759,  ...,  -7.1016,  -8.3359,  -7.6133],\n",
      "         [-16.1094, -14.5781,  -2.4414,  ...,  -8.7109,  -9.0234,  -7.8281],\n",
      "         [-15.2578, -12.7188,  -1.8838,  ..., -10.0625, -10.2969,  -8.6172],\n",
      "         ...,\n",
      "         [-15.4766,  -5.7227,   0.7441,  ...,  -7.4180,  -9.2344,  -9.1875],\n",
      "         [-13.2656,  -8.0938,   1.0010,  ...,  -7.7070,  -8.8203,  -7.1836],\n",
      "         [  2.5547,  -3.7051,   4.0156,  ...,   0.4021,   4.6680,   5.1016]]],\n",
      "       device='cuda:0', grad_fn=<ToCopyBackward0>), past_key_values=None, hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi, my name is \"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n",
    "#print(\"Logits:\", outputs.logits.shape) #Logits: torch.Size([1, 7, 32000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c61bf760-71cb-49a0-8759-ea6133f79dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LlamaForCausalLM' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi, my name is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogits:\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputs\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/scratch/qualis/miniconda3/envs/genai/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LlamaForCausalLM' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "text = \"Hi, my name is \"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.predict(**inputs)\n",
    "print(\"Logits:\", outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce256f2b-1d19-4d81-a0e3-fa0761ac100f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 15359, 28725,   586,  1141,   349, 28705,   565, 28736, 28705,\n",
       "           565, 28736,   315,   837,   264, 20654,  3327, 28333,   304, 25986]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hi, my name is \"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs)\n",
    "#print(\"Logits:\", outputs.logits.shape)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7339c28e-0f33-4d4a-8024-4b428adb5933",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, my name is ***** ***** I am a certified personal trainer and nutrition\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24ce2bf9-6778-45b6-b338-c605d7da0f95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='Upstage/SOLAR-10.7B-v1.0', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a1b9b83-7fa6-4def-9943-35c812c86e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.eos_token)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "print(tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aae3422a-8ef6-4079-9ebb-f16d6956899a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='Upstage/SOLAR-10.7B-v1.0', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e99fd8-5df6-448c-86c1-ade8ef0243d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
